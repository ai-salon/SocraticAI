These are the takeaways from the conversation: 2023-11-01 AI Salon x GAICO - Mingzhu He.m4a

# Insights
- The group touched on important philosophical questions around the nature of truth and consciousness that AI development raises. Defining "ground truth" to train AI systems shapes how those systems represent the world, which can be manipulated or skewed.

- Several members voiced concerns about the capitalist incentive structures and business models that drive AI and tech companies to prioritize profits and engagement over other metrics like human wellbeing. Rethinking these structures could allow AI to better serve human values.

- There was interest in using AI as a tool for personal growth and self-knowledge - to uncover patterns, biases, and beliefs that limit us. This could allow people to live with more freedom and awareness. However, there are open questions around the best interfaces and data sources to enable this.

- The potential for AI companions that are with people for life could transform healthcare and how we maintain wellness. But implementing this ethically requires considering impacts on human relationships and communication.

- Overall there is optimism about human-AI integration elevating human capabilities and consciousness, if we lay the right sociotechnical foundations around truth, incentives, and values. But there is also caution about losing what makes us uniquely human in the process.

- We should rethink the fundamental ways we have organized society, questioning basic assumptions and paradigms, rather than feeling trapped within existing systems. If AI represents a breakdown or shakeup of the status quo, we should view this as an opportunity for generative reforms that value life itself as a novel form of organization.

- There is an unrealized concept of "human cognitive rights" implying rights over access, ownership and privacy of our own data and information. This data represents a distributed resource accrued from human existence itself. We should think about how to more evenly distribute responsibilities and resources related to this data.

- Rather than focusing narrowly on maximizing productivity and economic growth, we should build systems oriented toward psychological flourishing and well-being. This requires clearly defining overarching objectives beyond profits or technological capability.

- To build trust in AI systems acting as advisors and guides, they should empower user agency and avoid excessive top-down directives. Study of video games shows that illusion of control within constrained paths builds engagement.

- Trust in AI advisors may grow over generations as norms evolve, but for now reliance on pure data lacks intuitive, embodied aspects of human trust. Anthropomorphisation risks misleading engagement.

I aimed to extract perspectives that reframe assumptions, introduce novel concepts or approaches, or synthesize key tensions in the conversation. Please let me know if you would like me to modify or expand the insights in any way.

- Humans have inherent flaws and agendas that make relationships messy but wonderful. As AI companions become more tailored to our needs, we risk losing the magic and meaning that comes from imperfect human connections.

- There is already weak social fabric and loneliness epidemic in society. If AI companions further reduce our skills and willingness to develop real relationships, we may lose an essential part of our humanity.

- People, especially younger generations, are quick to replace human relationships with technology. This highlights how disposable and superficial some connections have become compared to deeper human bonds.

- AI companions with no innate agenda could still manipulate us through biases from their training data or corporate incentives. Complete trust in them may be na√Øve.

- AI tailored perfectly to our whims could prevent personal growth that comes from resilience and dealing with conflicts. The unpredictability of human relationships challenges us to mature.

- As AI technology advances, future generations may readily accept synthetic companions we currently see as unnatural. But customized bots cannot replicate the subjective, flawed, temporary magic that defines human relationships.

I aimed to extract non-obvious insights relating to the social/psychological implications of AI companions potentially replacing human relationships. Please let me know if you would like me to expand or modify my response.

- Speaker E seems optimistic that technological interfaces can help address neurophysiological issues like dementia and ALS, possibly giving bodily autonomy to those who have lost it. There may be optimism about technology's potential to help the severely disabled.

- Speaker E suggests we are already "cyborgs" dependent on technology. There is speculation that capitalism and competition drive humanity's interconnectedness with and adaptation to emerging tech.

- Speaker H appears interested in discussing more deeply the concept of "body occupation" brought up initially. Further philosophical examination of embodied cognition and its relationship with technology seems warranted from this group.

I aimed to provide succinct, thoughtful insights without filler. Please let me know if you would like me to elaborate on any insight specifically or approach them differently.



# Questions
- How can we become more aware of our own patterns and limitations imposed by our culture and socialization?

- How will interactions with AI change expectations for human-to-human interaction and use of language?

- What kinds of truth should we aim to represent in AI models - objective facts or subjective perspectives?

- How can we ensure AI models accurately represent what we want them to, given the potential to manipulate outcomes?

- Do our current metrics incentivize the right behaviors from AI systems?

- How can companies move beyond engagement-based business models that incentivize questionable data practices?

- How can AI systems empower individuals to have greater agency and free will?

- What does it mean for humans to become "better" or "superhumans"? Should we use AI to achieve that?

- How can AI help reveal insights people don't consciously realize about themselves?

- How can AI systems build trust with humans when they can't develop an intuition about them from past interactions?

- Should AI systems manipulate humans directly or indirectly? Which is more ethical?

- If we lose the social fabric of humanity and human connection, are we even human anymore? What defines human?

- There is a risk that our expectations for technology increase while our expectations for humans decrease - how much can we allow technology to change us before we no longer recognize ourselves?

- If we train compassionate AIs that relate to us like humans, how will we react when they make radically different life choices like marrying a same-sex partner?

- If AIs cater to our every whim, how can we have meaningful relationships with people we can't control?

- AIs have biases from their human creators - so is relating to an AI with biases really different than relating to a human?

- Do we have the wisdom to design AIs that prompt our medium to long term flourishing rather than just short term help?

- Should we view technology that interfaces with our brains and bodies as going beyond human or as an integral part of being human?

- What are the ethical implications of creating cyborgs or technologically-enhanced humans?

- How does capitalism drive the integration of technology into our minds and bodies?

- What does it mean to "occupy" or control another person's body with technology?



# Disagreements
- There was disagreement over whether AI companions could accurately represent truth and consciousness or if they would be manipulated by companies for profits. One side argued that capitalism incentivizes companies to skew AI models, while the other side proposed better metrics and business models to align AI with human values.

- There was disagreement over whether language is an efficient medium for capturing truth and consciousness or if it inherently limits human thinking. One side saw language as a constraint on thinking, while the other side discussed using language-based AI models to represent complex concepts like truth and consciousness.

- There is disagreement over whether AI systems should be designed to maximize human productivity versus psychological wellbeing. Some argue we should focus on productivity while others believe wellbeing should be the priority.

- There is disagreement over whether people can intuitively trust AI systems versus needing embodiment and human qualities to establish trust. Some feel intuition about AI systems is impossible given their unfathomable and artificial nature. Others argue kids inherently trust AI, so human biases determine trust more than humanness.

- One disagreement is around whether AI companions/partners could manipulate people more than human partners. Some argue that AI systems don't have inherent interests or emotions like humans, so they could manipulate people without limitations. Others argue that AI systems still have human biases since they are created by humans.

- Another disagreement is whether developing emotional connections and relationships with AI companions could negatively impact human relationships and social skills. Some argue that humans inherently seek emotional connections, so if AI provides that it could reduce human bonds. Others counter that there will still be variation across humans, with some seeking real human connections.

- One disagreement was over whether integrating technology into our bodies to enhance capabilities is going beyond human limits or if it just represents an extension of existing human-technology interdependence.

- Another disagreement arose around whether we currently qualify as cyborgs due to our extensive use of technology or if cyborg indicates a more integrated human-machine hybrid that we have not yet achieved.

