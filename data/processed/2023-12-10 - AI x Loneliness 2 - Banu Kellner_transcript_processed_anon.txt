Names have been changed to preserve anonymity.

 

Speaker A: The interesting part is that we know potentially that there's societies that didn't feel less lonely. I cannot say that this is the standard, hopefully, of like the current states where people have like less friends from a few decades ago, at least in the US.
Speaker B: Yeah, I mean, there's societies like, my friend just spent some time in Argentina and he's like, oh my God, Argentina, people are so much more social. I feel like I make friends so easily here and then I go back to the US and it's so hard. So it's definitely different. And I also agree that the richer the society, the more isolated people are. And I just wonder if it goes back to the, when we started having nuclear families, everyone with their own home and not really living together in communities, but just like creating fences around each other. And it's just gotten worse and worse because it's just so individualist.  
Speaker C: I didn't want to stay with my family. I didn't agree with them. It wasn't a good situation. I can't imagine if I had grown up in Turkey where everyone was really nosy and you had to conform. It was like God's guns, God's gun and God guns and whatever, that was it. And money. You couldn't be yourself. And I'm so grateful that I could leave that it wasn't entrenched in a family system where you're controlled and everyone's super nosy and you have to stay. But I would rather that than had to stay.
Speaker B: Yeah, we do still have cultures, even within the US, like hispanic cultures, where they have 20 or 30 family members all the time, all in there, right, go to the park and there's like these huge barbecues with these huge families. I'm like, wow, I had like three people in my family. 
Speaker C: But when I have clients from families like that, they really suffer. They feel really guilty having any boundaries or doing any self care. I don't think that's the solution either.
Speaker A: Yeah, that's a fair point where when you're in a smaller community, then there's norms, and then it's easy to feel like you still cannot project your individualism as much or you'll be judged. But then to me, like the houses of the US, and again, I'm from Europe, to me, there's so much texture, but these houses are like, I have this house, and then my lawns have to look this way, and then I have to have this type of car. So I don't know, is there something in between? I actually work at Reddit. I can give you some information of why. I understand the problem from what I have thought about Reddit is that when I have something very unique to express, my immediate local community wouldn't care. But I'm able to find someone across the Internet that would really celebrate me for my hobby. So that's what I found is an interesting way to find people based on some very unique interest groups or a style of communication or thought processes. And that's difficult when it's local because there's not as much variety maybe.
 

Speaker D: I think that's been like a general story of the Internet, right? It's like a long tale of thousands of subcultures and interests groups and from the beautiful to the weird. And what I wonder, with AI, one interesting thing with AI is I think it has the potential to be a lot more proactive than how we interact with technology right now. So right now, it's kind of, I always need to make an active effort to find my subreddit, to connect with people and plan stuff in the real life and to seek out communities and plans and events. And I think if you think about everybody having their personal Joshua, their personal assistant that knows a lot about you and your interests and what you want to do in life, then that personal assistant could also help you connect with people in a much more proactive way. It could say, like, hey, I see that you're in San Francisco right now, and I know from your browsing history you have this woodworking interest. And I kind of went out and asked other AI assistants of other people if they would be down to maybe connect you with them. And here's a list, and these three happen to be close to you. And if you both accept, we'll match you super rad. But of course, I think what that would mean is that you would have an AI assistant that actually really knows a lot about you. Have you guys seen these wearables that are coming up that really kind of record everything and know everything about you? And I'm still, like, I'm a little bit creeped out by it. But I'm also a little bit like, oh, maybe this could actually unlock some kind of ever interesting stuff if you really have a digital assistant that really knows a lot about you.

Speaker B: What if AI gets so good that people really, truly enjoy relating to the AI more than humans?  

Speaker D: Well, but what kind of relating is.

Speaker E: It going to happen that it's starting to happen with relationships or whatever? So it's already kind of coming here.

Speaker B: I'm making an interesting analogy to porn versus real sex, where there's a huge segment of the population that's just, like, addicted to porn and almost can't have real sex because it's not as stimulating. Just wondering if that same thing is going to happen and what do we do about it?

Speaker C: It's like there's a lot of people that waste their lives playing video games. Yeah, that's already a thing.  

Speaker E: Like the real world.

Speaker B: They're going to be going to be like, ready player one.

Speaker D: I think it was naval who said something like, a lot of things. In the modern world, your happiness is kind of not what you indulge in, but what you restrain yourself from. Right? If you kind of just naively were dropped into the modern world as a person from a couple of hundred years ago, you would get really fat because you just eat fast food because it's kind of the easiest and cheapest option. You would just watch porn all the time. You would just consume all kinds of drugs and cigarettes and live a very unnatural, unhealthy life. Right. And you get happier by refraining from doing stuff. And AI, the sugar version of it, is going to be one more thing that you have to kind of say, okay, I'm not going to indulge in it. Another vice. And I'm always wondering, what is the right approach to vices in general? Right. Should we legalize all drugs? Should we ban all drugs?

Speaker B: He's looking for a trick. We can scoot over. There's enough room.  

Speaker F: I was like, this is a smaller group.

Speaker B: Yeah.

Speaker C: I'm not sure. It's such a terrible thing if someone just wants to relate to AI because there are so many people who are extremely traumatized or have an extremely challenging time with modern life and don't have many options. I don't know. You're giving me looks like I said something really.  

Speaker A: I just feel like on a physiological and psychological level, you need the actual human connection. Right. Is there like research that you actually need, like human touch? I think to me the challenge there is people have had negative experiences with real connection, maybe trauma and things like that. Right. And that makes them extremely high bar to go. And some people have really good experiences with human connection. So for them, AI will be like, what is this? I don't care.  

Speaker B: What about all the people who are never going to experience great human connection because they're just too damaged? Maybe AI is awesome for them. Maybe there's going to be like flesh robots that can talk to them and be their companion and it's going to solve all these.  

Speaker A: Do you feel like for some of them, though, they can actually do the hard work versus getting into the easy resolution?
 

Speaker B: I guess that's the question is if you're capable of doing the work to have a real human connection, we should be making you do that rather than giving you the easy way out.

Speaker C: I think relating to a healthy AI could help the person develop the resources to take the next step because a lot of people who are highly traumatized fall into toxic relationships with cam girls, for example, or toxic relationships where they get taken advantage of and it just makes the cycle go downward more.  

Speaker A: So AI can be like this on ramp potentially for you to start feeling that relating is a positive thing.

Speaker C: Yeah. And you could get healing because even if the AI can mirror and validate you and just really be there consistently and heal some attachment wounds, then you won't put up with toxic bullshit. At least that's what I'm hopeful for. That's what I see could happen.  

Speaker D: I'm wondering, yeah, like device aspect of it, right. It's so easy that it will just be that that's almost the default outcome, that it's just going to be a vice.  

Speaker B: There's no profit to be made from people graduating and giving up the service.

Speaker E: So what do we think about the evolution of having either AI assistants, AI chat bots, whatever, impacting on our mental health? Because loneliness is a part of mental health.  

Speaker F: I went on a camping trip with friends of mine and actually stopped by a rest station on the way north, and we were there. I'm like, oh, we got to go. I was like, no, I'm collecting my Pokemon pets thing. And I actually met someone that was, like, lived in a more rural area that we learned talking to him. He didn't really have friends, but he came out because he was doing this Pokemon thing because his interaction was online, but he actually met people that had this common interest. And so an app like that didn't like delivery force, but gave people options to go out, meet people in person. I don't know enough where all this technology go because to me AI is like this very vague thing, and when it becomes applicable, it's things like voice recognition. Like I can pick my phone, talk to Siri's or Google, and they recognize my voice. There's AI behind it, but when it's directly applicable in society, it's not called AI anymore. So it's our lack of understanding. I'm trying to answer your question, though.  

Speaker B: There's a distinction between machines that can.
 

Speaker B: Speech recognition has been around forever. Speech, they're just getting better and better. But there's a distinction between simulating human skills versus simulating an actual human being in all of its forms, especially relationship. So I think it crosses over into being AI when you're like talking to it and having an actual conversation.

Speaker F: I have a bachelor in psychology. I didn't end up going to graduate school, but I do realize you work as a psychotherapist, I can bond you. Works as an executive coach. There's a difference in folks who are gone to school, like clinical psychologists for years and they're licensed. It's a degree where some people just need the coaching or the life skills, and there's other people have deeply seeded medical problems and it's a fine line to cross. No one's going to be able to replicate that human experience. I'm not sure if the public at large realizes that yet. I do, but I think it's because I have this background in psychology and computer science. 

Speaker B: What about 50 years from now or 100 years from now, like flesh robots that are just so brilliantly programmed with all the deep learning and they just simulate a human perfectly.

Speaker F: Get angry at you.

Speaker B: They're just always like, I had a.

Speaker F: Visceral experience on Halloween. I'm walking Halloween, going somewhere, and it's not like a robot, but on my street near city hall, I was like going up to this car, going to yell at this angry driver and turn on. These are like self driving cars. No one's in them because I have photo of this car blocking the crossing intersection. And then I will try and go the other intersection. There's another car like that blocking it. I'm just like, oh, my goodness, you've lived in New York. I was like, I'm just going to give them the New York street profanity. But there's like no one there. I'm like, oh, what am I supposed to do? So I took a photo and sent to someone I know that works for the car company. And then one of the pedestrians crossing the street came up to me. He's like, oh, I'm glad you caught that. And I was like, oh, I'm just like kind of my own business because I can listen to music. And I realized I forged this connection with a stranger because we both were angry at this fully computerized thing that's blocking our right away. So that's how I imagine 5100 years now there will be interactions like that. I just happened to experience the Halloween this year not knowing.

Speaker B: I guess my point is you were saying, you know, that it will never replace human somatic connection, but I'm suggesting maybe it will be capable.

Speaker F: You think it will be capable?

Speaker C: I'm not sure about that. It can't read. It's not going to be able to lead someone through. 

Speaker B: Years ago, we thought it could. Yeah, 50 or 100 years is so long. Like, think 50 years ago we didn't even have cell phones. 

Speaker C: So much has happened. I don't know. There's a lot of complex subconscious cues and things you're tracking when you're doing somatic work with someone. Mental health wise, what I was going to say at the Ted AI conference, there was like a major healthcare organization, I forget which one, but they already use AI counselors for alcohol. So there's like a hotline you can call and it's an AI, it's like a video of a person, but it's an AI that counsels you about your alcohol use. And so that's already happening.

Speaker A: What's the, do you know some of the percentages of improvement and are they able to be a successful human?

Speaker C: I don't know. But I know that where there's been like an extreme shortage of providers, like something like pediatric psychiatrists or, I don't know, all these disciplines where there's like a huge shortage of doctors, they've been using AI instead and they liked it. I don't remember.  

Speaker B: It's so early. It's just going to get better and better and better was my point.
 

Speaker D: Okay, so I want to throw in another layer here, which is, let's say it's going to get extremely good, right? I think it's going to get better and better and better, and they're going to be indistinguishable from humans in many ways, maybe also in the physical dimension at some point. And then I guess the question is, well, there's two questions. One is, will we relate to them as we relate to humans, and will they satisfy our needs as social creatures to relate to other humans? But then the other layer I want to bring into this, and we haven't really talked about this yet, is, I think when we say loneliness, yes, we mean the relating part, but there's probably also somewhat of a status component in that whole picture. So curious to hear what you're thinking from your clients, but I think a lot of people, when they're lonely, maybe it's more a men thing than a woman thing, but they're also often feeling a lack of any kind of status in any kind of group, right? And I think a lot of humans, especially ambitious humans, they chase some kind of status in some kind of peer group. And when somebody feels that they have absolutely no status in any group, I think that can be extremely isolating to that person. And if now, in the future scenario we relate to ais, is there such a thing as status amongst ais vis a vis ais? Like ais presumably don't care, right? Like, there is no hierarchy of status within.  

Speaker E: Or do you use Google?

Speaker D: Well, no, but like, you visa vis the Ais, will you be like, oh, I am the leader of this group of aisles. They listen to me when I speak. Whatever. Is there a capacity for us to relate to them? And is there a capacity for us to get our status needs met by them, or is that even a consideration in the context of loneliness?  

Speaker E: But that might be me.  

Speaker D: I think it's a male and female thing also. I think for females, it's less a part of it.

Speaker B: What about Instagram and all the teenage girls trying to get Instagram?  

Speaker C: Yeah.

Speaker B: I want to go date somebody hot so that I appear high status, whereas you value that above your actual connection to the person.  

Speaker A: There's other groups that I actually participated, which is a cris, the meaningless cris. So I think these are two things of having a purpose and then having relationships. I think maybe they both need to exist together, but it's a very complicated problem.  

Speaker B: So I'm just having this thought that we do have certain very extreme remedies for very extreme problems. So, for instance, for insomnia, there's a pill that basically makes you feel okay not having slept at all. I forget what it's called, but we don't want everyone to have access to that, because then we can just all stay up all night for a week on end and it'll mess with us in some way. But that exists. They give it to soldiers and they give it to people with terrible insomnia. And now ozembic is coming out, and it lets you get away with not having to take care of yourself, dietary wise. But hopefully we only give that to very obese people and not like everyone who just wants to become a glutton and not have to worry about it. So maybe these AI bots can just be for the very needy people who have really struggle with social relationships or are never going to have successful human relationships. We make that available to them, but it doesn't become widespread.  

Speaker D: But how would we prevent it from becoming widespread?

Speaker B: Well, I guess I was making an analogy to those, because those are prescription medications.  

Speaker C: Yeah, I guess regulation.
 

Speaker F: I worked for a company ten years ago, and we made first world kind of thing called digital medicines, like actual medication with sensors inside of it. And the purpose, prescriptive medicine, was people make sure they take their medication. The company failed, that we couldn't really find a market. 

Speaker B: Well, I guess the question is, can we regulate what AI girlfriends, more like AI relationship bots for relationships? 

Speaker D: Maybe we should.

Speaker B: It's kind of crazy that any aged child can access porn. 

Speaker A: A lot of providers are having acute incentives and they spend time paper pushing versus actually caring for patients. And they're thinking, oh, we should make it outcome oriented.

Speaker F: Yeah, it's like value based.

Speaker A: And then the other thing, I mean, again, like all these companies, they're just like, oh, I want to get more clicks on my app versus having some sort of more qualitative score for each user. 

Speaker F: I know Europe has a stronger stance on AI regulations.

Speaker B: I saw some post that said we just came out with some regulations or like a proposal like two days ago or something regarding AI regulation. 

Speaker D: There was a term for it in Germany. It's the prevalent way people look at economics. It's called ondo economics or something like that. If you ask the average person in Germany, does the free market work? They're like, yeah, but sometimes it works too well and sometimes it has downsides that we need to regulate against.

Speaker F: I mean, german history, like in the very laissez faire free market. I'm sure there's parts of the cultural history. And here in the States, I think San Francisco is very niche. Robert goes to events and he's told, this is too controversial. 

Speaker B: That's crazy.

Speaker D: Yeah, I think in the US belief in the free market is often a bit of an ideology also. It's like, kind of like, okay, you can't really say anything against it or you can't say that it's not all positive in some circles, definitely that's a right wing republican viewpoint for sure.

Speaker B: But I think democrats generally are in favor of regulation, more like the european model. And then somehow they just can't win the media war about that. Because you go on the media, it's like regulation is the enemy of economic growth. 

Speaker D: So what do we think, particularly from your perspective, what do we think are like, the fundamental causes of loneliness? We have people's trauma in the past. We have lack of people around them that they relate to. Is that it?
 Processed Transcript:

Speaker F: I just feel like I couldn't communicate. And I felt kind of lonely. I wasn't living with my parents. I just missed them. And I felt lonely in an early childhood because of that. I don't know whether people as adults feel that, but if people do, I empathize from that perspective because I can connect with people.

Speaker D: Yeah. Cultural language barriers.

Speaker B: And the US has the most multicultural. At least the Bay Area is super multicultural. But I do notice that we tend to form clicks around our subcultures. So when you go out and mix, it's like hard to connect with other cultures. 

Speaker C: I mean, maybe my subsection is special. Like, it's biased, but it's definitely trauma. Things like neurodivergence, but just a general lack of teaching people how to connect. But really, I see an epidemic of unworthiness, self criticism, and also toxic models of community or togetherness from patriarchy about you have to be the best or you have to trick women into wanting to hang out with you or something like that, and everything based on hierarchy. I work with a lot of people who are still operating under those narratives.

Speaker F: When you say hierarchy, is that hierarchy of individual needs or societal hierarchy?

Speaker C: No. It's like I have to be the best, or I have to be 6ft tall or I have to have a six pack in order to be worthy. 

Speaker B: Of or tell the best jokes. Even in sports, my sports team has to be the best sports team. And I'm gonna like, there's so much media culture around, like, men arguing over who's better at sports or who knows their sports better. It's like, why is there so much competition? 

Speaker A: This kind of like me against the world versus me with the world. I feel like that's a little bit the cultural aspect, yeah.

Speaker C: But I definitely see a lot of neurodiversity or adhd, or just struggles with even managing to pick up a phone and make a phone call or to just have a conversation with a stranger without like a flood of, oh, my God, is this okay? Am I going to get hurt? Did they like me? Their extreme self consciousness? So a lot of people really suffering inside, around basic. I don't know what you call those things, but a lot of people really struggle today. 

Speaker B: It seems like social anxiety. It's so much easier to interact with your phone than a real person, and especially if you grow up doing that. My daughter is 16 and she like, when we go to a store, she'll be like, can you buy this for me? I don't want to interact with the checkout person. I'm like, you're going to have to do this soon. And she's like, yeah, but then I get to wait two years.

Speaker C: If you do it, there's a lot of also defensiveness that seems to be the norm, especially, at least among the men I work with. They don't understand why women don't like them, but they're unable to take any feedback whatsoever. Or if they get feedback, they collapse and support me. Victim mentality. Victim mentality is a huge cause of loneliness, I think. Or they go into resentment and blaming women, anger at women, and then women can feel that underlying resentment and bitterness and anger and they stay away. But also, if you can't give someone feedback without fear of them getting mad at you, or if they just collapse and make it all about themselves, it's really annoying to be around that sort of person. So there's just a lack of basic relating skills. Yeah.

Speaker A: I'm curious how much effort or how much work does it take to move from this to kind of a more of a thriving situation with women or other people?

Speaker C: That's a good question. Well, it depends on how much the person wants it and how much time and energy and focus they're willing to give the work. But usually in a year you can see really good progress. 

Speaker D: And how do you train that with them? Do you kind of go through a role play exercises with them?

Speaker C: Sometimes, yeah, most of the time. I teach them new reflexes. Instead of like, attention out or blame out, I teach them to get curious about what's going on for them, send that part of them love and just give them a lot of validation, a lot of situate what's going on for them in a wider perspective so they know they're not especially fucked up or broken, that this is a common thing and just that constant positive mirror, but also me reminding them, like, this is just a part of you, this isn't the whole of you, and send that part love. And now where is the confident part of you? I mean, it's common today. Parts work, internal family systems, that sort of thing. And then, yeah, titration, pendulation, like these trauma healing modalities. So I do a lot of work with the body. It doesn't work to just talk top down things.
 

Speaker D: So for that kind of work, for that kind of skill building and coaching, if your AI replica avatar of you is fully developed, what do you think is the role of that? Do you think somebody can go to it and kind of autonomously level up just with interacting with the cyber you? Or do you think you still need to be there at some point?

Speaker C: It really depends on their defense mechanisms. But say a man comes with a sexual function issue like impotence, and he's like, how do I fix this? And it's a psychogenic problem, it's not a biochemical problem. Then I can say, okay, here's the possible causes, and I can give them an action plan and then they go and do the thing and come back and get feedback. And I believe that just by interacting with my AI, they could probably solve it. Or if it's something like a communication blind spot where they're like, it never goes well with my girlfriend. I don't know why. Then I'll be like, then she will ask, well, how are you communicating? Well, that sounds like advice. Did you realize that? Have you tried saying this instead? So I think they could possibly solve the communication thing too. 

Speaker D: The interesting thing with that for me is like this whole space of the AI coach, AI therapist. I'm always wondering, such a big part of making this kind of work work for people is often that they have the therapeutic relationship to you, right? And they trust you, and that puts their brain into a state where they're kind of ready to change some stuff. They kind of get more neuroplastic because they're like, oh, I'm safe here. This person gets me and I can kind of open up and change. And do you think that is something that with a cyber version of you, has to be replicated, or do you see that as like a barrier?

Speaker B: I have an opinion about that. There's a lot of people creating coaches that are like a generic bot where it's sort of like not a person, it's not based on a person. It's just like, here's your relationship bot. Ask your questions. Personally, I think it's hard to develop a relationship with something like that. Whereas if it's based on a real person and they get to see that person in video form or maybe talk to that person sometimes for real, then you can sort of form a bond with the AI version as well, or start to trust them. Especially if she's like, I've trained this and I endorsed it and you can trust it and that kind of thing. I'll be reviewing the answers and making sure that they're legit.

Speaker C: Yeah, I mean, it depends on the complexity of the situation. But even, like, I'll follow business coaches or Esther Perel or other leaders online and I'll just watch their videos and read their stuff and I will trust them enough by just reading, know that their stuff will have an impact on me, right. So it could be the same thing. And my AI is designed to really validate and empathize and give them high quality information so that they're like, oh, I can trust this person.

Speaker D: And it is true that we see it already happening that people, for good and for bad, idolize online figures, right? And learn from them. And that can be a good thing or it can be like an Andrew Tate kind of bad thing. But certainly, yeah, people do get inspired to change based on online figures, right?  

Speaker C: Yeah. And if they're using my AI, they'd probably be following me on social media, too, so they would get a dose of human me as well.

Speaker B: That's why I'm basing my company around replicating actual people who have audiences already because they already have a relationship with those audiences as opposed to just a generic business coach, for instance. Who is this? How do I know you're giving me good advice?

Speaker A: I think what's important, too, is like a little bit of a consistency on the approach, because I assume there's multiple ways to advise someone. And if you one day you're getting one thing, another day you're getting another thing, that's really hard. 

Speaker D: I think real therapists often, actually, I don't know if that ever been a challenge for you, but my customers are therapists. I talk quite openly with them. And if they have, like, 100 clients, sometimes they forget details about one client's life. And that can be quite damaging to the relationship if your therapist kind of mistakes you for some other client. And I think the AI is actually better at that in theory.

Speaker F: What do you mean by real therapist?  

Speaker D: Oh, just regular people, normal computer.

Speaker F: I'm sitting on a couch next to.  

Speaker D: You type or in a video chat.

Speaker F: Yeah.  

Speaker A: What have you found? Like, the value add that you are kind of working through?
 

Speaker D: So. Sorry. The question is, what's missing in a relationship?
Speaker A: Yeah. What are you building for your company?  
Speaker D: This is trauma therapy, but nothing to do with AI. 
Speaker C: Is your company called embodied sensing? Sensing?
Speaker A: No.  
Speaker D: Bilateralsimulation.
Speaker F: IO.
Speaker D: But, yeah, we don't really deal with the patient side. We're just the SaaS for therapists.  
Speaker A: Just them, like, assemble information?
Speaker D: Well, they use us to do the therapy, but we don't deal with the patient side. But I hear a lot of stories from them.
Speaker F: So, Alicia, you mentioned a point earlier. You said part of loneliness was people don't feel connected culturally. Dig deeper on that.
Speaker E: I mean, my experience, not the same. I grew up here and from here, but I'm like an indian background, so I don't necessarily fit with first gen Indians, and I'm more second gen. And so I'm in this weird gap where I'm in India. I don't feel like I'm an indian. I'm in America. I don't feel like I'm an american. So I have a weird cultural gap and trying to navigate how to find certain people who also reflect that with me. And so I have a really niche group of friends, but I'm sure other people also have that issue where they have this weird cultural identity or people who do come from other countries into America and they don't really know anybody and they don't speak the language. That's also definitely could be a symptom.
Speaker F: So it's the identity and belief being able to relay based on self identity.
Speaker E: Yeah. I feel like maybe people struggle with. They have their culture identity, but they're surrounded in a group of people who don't really identify with that and just trying to navigate. Navigate a group with that. They probably feel isolated, alone, not be able to communicate. Those are all other factors that could probably get into.
Speaker D: Maybe. That's an interesting dimension to zoom in a bit, like identity and cultural identity. Is that, like, a prerequisite to not feel lonely? Like, to feel belonging to some. Right.  
Speaker E: No, some people might not have issues.
Speaker D: Exactly. I feel kind of, like no sexual affiliation. 
Speaker A: Do anyone feels like. There is a metric here where, for one person, because talk individually, how can we estimate if they feel lonely or not? I'm asking this because I feel like if we're building, like, bots and things like that, it sounds like there is an appetite to fix that. But how can we actually assess. Is this helping?
Speaker B: Yeah. Maybe a better analogy is, like, antidepressants, right? So we have, like, a clinical diagnosis. You are depressed. We could have, like, a loneliness diagnosis. Right? If you're lonely, we prescribe this AI for you the way we prescribe antidepressants today.  
Speaker A: Is it, like, self reported or, like, the external provider?
Speaker D: I think all of these things. Generally, the depression is like some questionnaire, right? And if you hit a certain percentage of that questionnaire, then you're clinically depressed, and you can debate whether it's accurate or not, but, yeah, I guess the same would be true for loneliness.
Speaker B: I mean, I guess we could regulate it to the point where we design the loneliness bot to be not that interesting. People who aren't lonely sort of, like, make it so it's, like, just good enough. Sure.
Speaker F: Yeah, I would say that.