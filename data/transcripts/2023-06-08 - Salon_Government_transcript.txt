Speaker A: All about the struggles that government has in adopting new technology. Previously I worked at an organization called Change, which is more on the. It's a petition platform, it's more on the kind of legislative side of influencing policy priorities. Yeah, those are the kind of areas that I'm interested in all everyone. I'm Matt. Yeah, I have a background in a few different things. And yeah, I was a history and political science major, did TV productions, political polling, software engineering, and now I'm a mess, but I'm an okay mess. And I've gotten into this AI stuff, but it excites and scares. I don't know, it confuses me. And I hope you guys have the answers today. I don't know if someone told me my brain would be emulated in five years on Friday. And if that's now, LK 99 might speed everything up, right? So please answer everything for me. Nice, can do. I'm Mitchell, I have a background in economics. I've been in startups starting as an analyst and then a data scientist, and then data science manager, did major consulting, and then now I'm on sabbatical, pursuing the path of going to an MS in computer science within governance. I facilitate a program through Blue Dot impact, which spun out of OpenAI and Cambridge. I've been facilitating, helping facilitate that program for the past couple years. And the newest one is about AI governance in particular. So really excited to talk today. Particular questions have been thinking about recently is like, how do you create or avoid race dynamics in which we're like, oh, the US should be number one, let's do this, because there's all these gains, but in my view, the gains are so large that you can share it with everyone. And so how do you communicate that effectively in this very messy gains theoretic scenario that we're in, and various coordination problems that spent from that? I think the best analogy is like racing through a minefield. So it's like how do you then maybe have sub detection out of things? In particular, I'm quite concerned with catastrophic risks. I have a pretty low probability, but still high enough where I think it should be taken seriously. I think there are nuts in the tourist sphere, so I'm not like one of those. But it's reasonably likely that things go poorly and those catastrophic or existential risks should be taken into account in general, like the alignment problem. And I've been interested in this since 2012, reading Irving Good, John Irving Good about Seed AI and taking off and then got really into it in 2018 reading Superintelligence by Nick Foster and Human Compatible by Stuart Russell and so on. And really excited to chat. Hi, my name is Colin Mohamed. I'm from France initially and I'm creating an advanced AI agency. Basically what I'm trying to do is to make it very easy for any organization, especially like small to medium organizations, to kind of be super effective by using the latest productivity tools followed by AI. So before we had like quote and local tools, and now we can supercharge this by AI just to give you another magnitude. Like whatever we would have been able to do three years ago, we are able to do it like 100 times faster. So I did an entire kind of marketing and web development for free. Projects like within 1 hour can show you guys later, but so powerful when you have the right stuff that I'm sure that all the old organizations will disappear and work only. Cool. Let me just rephrase the prompt here. Just so let's keep a succinct kind of a couple of sentences on what your background is and then really what the point is. What are you interested in talking about today? I think that's the real maybe I missed. I might have. So I'm an engineer, I graduated from, I was a startup, so I did like 20 countries, Dubai, Singapore. I wanted to know what kind of project I started in blockchain. I'm starting to reach to AI. I had no code agency before and I want now to combine this with AI because I think the scale at which we can have higher productivity and much something that we have never seen before. Huge, huge scale. Like Definitely something that is unbelievably powerful. When we have the white tools and white method, we can do things very in a very powerful question. Okay, let's keep. So my name is Bernard, I'm also from France and I'm currently reading Recoding America by Joseph Polka on basically how to turn government into a digital powerhouse, which it isn't at the moment. So this is actually one of my areas of interest as well, which is how government can be more efficient. So to your point, if you can get rid of the digital baggage, the technical debt with AI, that'd be fantastic. Totally. A little bit about me. So I've been here for over 20 years. I am a business development professional, worked with many startups. I've been working corporate VC. I'm currently talking to a number of startups about joining them. And one of the companies I'm talking to is actually in this realm of digital governments, or actually making government services more accessible, especially in the realm of accessing grants, which startups are struggling to get access to easily. So they're adding a layer of AI and ingesting government data to make things more accessible. So among the topics, the other topics of interest are cybersecurity, government, I'm sorry, election interference, and other AI themes about doomsday scenarios that keep me interested and engaged in the topic in broader terms. My name is Al and I have a background in architecture and construction. We've become a technologist. So I have a sort of a bad architecture named Luprins AI. And also for three years I've been a planning commissioner and recently became a vice chair for Planning commission. This is the most I've done in government and seen the democracy and how slow everything is, and I'm here to learn. So I don't think I'm going to talk much. I want to hear which planning commission America. Okay, so my business is over there. I live here in island from Shaker. You need to live there for five years. Yeah. That's how you reckon. Got it. I represent the business. The businesS. Got it. Cool. So yeah, my name is Patricio, go by Pat or Patrick. I started abstract at us, so about three years ago now. So we essentially built a project management tool to track and monitor state legislation. So we have all these scrapers that are scraping California policy twice a day. We have over a million records, about 85 customers, mostly lobbyists, trade association, state and local government, which why I asked about planning commissions because we also scraping local policy. And next up we're going to be expanding to corporate side of things. We're going to be selling to government fairs and legal teams at corporations and essentially using models to understand the impact of legislation as it impacts a corporation or a nonprofit. So anyways, we do a lot of stuff in both the government and AI space was actually a thesis project at Loyal Marymount University. It was my AI project in 2019 before LLM sort of thing. And now I laugh because fucking overhyped 90% of people don't know what they're talking about. But anyways, I'm really excited to see it proliferate and see the industry applications now. And yeah, I guess my main questions are around how other people are taking a look at data in this space because we're focused on legislation, regulations, but there's a lot of other, just a lot of unstructured data in the space as it pertains to specific agencies or localities held. The DMV itself has millions and millions of lost PDFs, so that's where I take it from and excited to enjoy the conversation. So the prompt was a little quick couple sentences on your background and kind of where you're coming to this conversation from, and then also really what you're interested in talking about in the context of government and AI.
Speaker B: Hi everyone, I'm Esma. Sorry for being late and intro from the slide. I'm a new grad at university did in economics there. I'm working with my university, AI Lafunirva, and I think I'm just very interested about the triple down economics of AI employment. Who decides which public data sets are going to be available and which aren't? What's the role of government? Learning and regulating, and especially not regulating. There's a lot of entry points there. So yeah, just very curious about those perspectives. Hi, my name is Ruthea and I'm interested in learning how AI can help governments to maybe do some work. So I started a nonprofit in mental health space, and we use AI to provide low income people and things like that. So I think that's one of the examples that AI can help government and their work. And I also am member of some other nonprofits focused on human rights and for Asian Americans.
Speaker A: Would you like to see here? That's okay.
Speaker B: Yeah, that's okay.
Speaker A: Okay. Because you're just right behind someone, maybe. Yeah, I'll go. Better come here. Great. Just so we can all kind of see each other. Awesome. The face alignment connection. Cool. I guess it was you.
Speaker B: Yes. I'm Yashasbi. I'm currently at McKinsey. Have done work across but focusing on government. The past couple of months, the way I've been thinking about AI and governance is basically twofold. Right? Like everyone's talking about regulating the space, which I think is important, and it's the way to go. However, the bigger question for me in my mind is, how do you really help governments get to where they want to be? Right. There's always been a question around the government lacking behind, right. And with AI that's going to get accentuated further. A lot of countries are already working on this. There's a lot of work around linguistic like countries just building their own LLM models, like in UK, China. Second thing is around questions around language barriers, right? Like we've already heard multiple examples of if you ask AI like a question in any other language that's not English, it gives odd responses. So the bigger question for me is like, sure, there are people who are going to make AI great, but how do you help the government really keep track? Because there's so much work that can be done in this space. There's so much money and impact there as well, right? That's pretty much behind. Like, you don't have to be at the frontier of innovation to only make impact. You can also help people with whatever knowledge or information you have on the side. So the bigger question for me, and I think would be great to get everyone's thoughts on that, right? How do we make that change, and how do we make it happen? So I'll leave my intro with that thought.
Speaker A: Hi, everyone. My name is Michael. I am an engineer. I worked in the space industry for about four years, and then I realized that Earth is really cool, and it's, like, way better than space. And so we should probably make sure that Earth is cool. I'm simplifying a bit, but basically that's a contentious opinion right there. I love the stuff I was doing in space. Engineering is very cool, but my brain would always drift toward Earth problems. And so eventually I left to work on that, worked on a new city project for a little while, which helped me think about how to make civilization better more clearly. And in the process of that, I came to realize that some demons need to be exercised at the source. And so I've turned my attention to San Francisco. For the time being, I'm working on building a systems model of the city government. The idea is to make government more legible so that it is easier for citizens to understand and interact with, because I believe that good government is downstream of good citizenship. And a lot of citizens, even like a lot of our most talented, well resourced citizens, don't really know what's going on. And if you can't build institutions, like, you can't expect your government, which is an institution, to work well. So this is the idea of the project. It's quite difficult. I realize how hard it is additionally how hard it is every day. It's very stressful, and I'm having a ton of fun. And so this very naturally hooks into technologies like AI. And that is why I'm here.
Speaker B: Hi, everyone. My name is Sam, and I'm originally from India, and my background is in engineering, economics, and policy. So I worked with one of the state governments in India for about five and a half years before coming here for my master's. And, I mean, during my time there, primarily, I worked on policy implementation, but I also had the opportunity to work for the national elections in 2019. And during that experience, I got the opportunity to work with Meta WhatsApp, Twitter for their election campaign, and basically representing the government to kind of control misinformation? And how do we ensure that political information is spread equitably without any biases? So that experience kind of sparked my interest in online interest in safety, misinformation, and all things tech policy. And then during the last two years, I have worked with some tech startups, also big traditional tech companies like SAP, to kind of understand how do we help companies navigate the regulatory, legislative ecosystem so that they are not just reactive to cut down on fines and costs, but kind of incorporate that ethics and that mechanism into their product lifecycle. My interest, I would say my background, is just to help companies navigate this ecosystem while keeping that spark alive. That citizen and people are at the core of all technologies and all ecosystems we build and scale. So, yeah, very excited to be here.
Speaker A: Hey, everyone, my name is Mohammed. I have worked in digital health mobility. My last role was at Meta. I was leading product strategy go to market, the team that deals with this information across our platforms. I've been sued by Donald Trump. I was involved in several elections. Actually, I was laid off the day after the US midterms. And my concerns are that this technology is made available globally. And it has. I feel like it hurts, though. It pushes society further in countries outside the west, it also has the ability to cause more severe harm in those countries, and that companies are only influenced by a few governments in the west and the rest of the world is neglected. And secondly, I feel that neither governments nor the corporations that build these systems have the ability to protect us. I think we ourselves should become more literate and blaming governments, Facebook, Google, et cetera, for what's spread on their platforms. Nice. They cut you off. Okay, cool. Okay, so I think there's a few themes that are kind of, like, recurring here, right? There's definitely the misinformation and elections, like the threat to democracy. That's a big one. And there's also this idea of where do governments want to get to? And the services they provide. Right? Another big one is regulation. And how do governments kind of protect people from emerging new technologies that might be threats. Right? Was there other ones that I missed? Anyone suggesting more themes?
Speaker B: I think to the second one, I just add, it should be a preparing force for governments. Right? They shouldn't just follow. So what are key themes? For example, chat GBD in the US, right, versus Chad GBD in all other countries. It's very different right now. We'll need different LLM models, etc. So how does it become an economic force? Like an equitable economic force, right?
Speaker A: That's a good point. Yes, totally. So then also as a driver of.
Speaker B: Prosperity, primarily not just regulation.
Speaker A: Okay. I'm hoping my role here is to just direct traffic. And it really is a conversation between everyone else here. But I thought I might just kick off with a very simple question. Maybe we can start with the regulatory side if people are interested. But what do we expect governments to do when it comes to regulating new technology? Is their responsibility to tell us what can and cannot be done before we even get to those potential possibilities? Or is it instead, in retrospect, where they say, this has evolved towards a dangerous direction? Now we're going to come out with rules? I mean, a way of thinking about this might be looking at the FAA, right? The Federal Aviation association, where it's like we've always known planes are dangerous and plane crashes come up. But over time we learn from that and get better and institute more and more strict guidelines for manufacturers and for operators to limit the threats to the public. That's the after the fact kind of case. Whereas on the other hand, the FDA is trying to make sure the only things that come to market have already been vetted as solutions and proposals. Does anyone have strong thoughts on what the right version of those approaches might be in terms of this kind of AI technology?
Speaker B: Just one question to that. One question that's always been in my mind is we always blame the government, right? We've got this independent authority. If people can't solve a problem, it's the government's problem. I disagree. Right. Why should the government solve it? Right. Governments have come into being recently. Right? Blockchain kind of went against that theory as well. So one question. Because first principle thinking, right? Do we need governments within AI? Because they've always been lacking. They're not going to be at the forefront of it. Right. Or do you want someone else to come in and, I don't know, sort of leave the revolution? Because AI is like a central theme, right? And governments are not like, they're decentralized. So you want decentralized authorities to come in and solve a problem that's centralized. So in my head, it doesn't go hand in hand. Right. It's also why we have the United Nations. Right. Because you needed a central body to solve a problem that wasn't limited to one geography. So when we're thinking government, do we mean like governments of different countries, or do we want a different body to come in and sort.
Speaker A: So most of my work is with the California State legislature. So just looking at it from the most I guess you can say progressive state government in the country. Yeah, I would say more so than New York. It comes down to committees. Right. So if you look at governance like our actual government, there's two main governing bodies and that's the legislature, which is your assembly and the Senate. And then you have agencies that focus on specific themes and the agencies are under the governor's office. Right. And so at least as it pertains to things around AI and data, that's a specific committee in the legislature that focuses on that. Right. And we have to at least, my realization of the last two years working in the space is that we vote in politicians that don't have industry expertise. And so who do they rely on to draft legislation? They rely on consultants and industry experts in the committee. How are those people hired and who are they listening to? Lobbyists. Who hires lobbyists? Corporations that have a lot of money and want to benefit their bottom line, which we happen to sell our software to. Right. So what I've realized at the end of the day, the corporate America is still controlling most of what's going on. That's still where the power is. And then regulatory agencies, the same thing, except it's even more imbalanced in that we don't vote for the people who work at regulatory agencies. They're appointed by the government. So at least at the state level that's what's going on. I feel like at the local level there's even less sort of transparency going on. It's just like Joe, who used to be a plumber, is now talking about AI like the fuck. So those are my two cent. I think what we need to look, I mean, obviously I'm biased. I think part of what we're working on is trying to solve that through our platform. But I think more generally speaking, there needs to be a more decentralized sort of committee process where actual industry experts that are not paid by lobbyists are contributing towards policy. And I'm optimistic. I think there's a lot more of that going on now just because of the last ten years. People are starting to realize like, holy shit, government does have a lot of impact on our lives. But I'm going to stop ranting. But that's just like a couple of observations I've seen.
Speaker B: That's pretty interesting, right? Because my hypothesis on this is like having a centralized body that takes care of how you propel AI forward, brings in together like a couple of centralized guidelines for different countries, and then countries can decide how they want to implement it. They focus on implementation. But that's their role. You don't give them the power to also think of what to do because there's a lot of latency. Like AI is moving really fast, right? Like it's changing by the day. The difference between 3.4 and four is insane. And honestly, I'm not a tech person, right. So I barely get it. You guys would know a lot better. But my sense is the way, the pace at which it's moving, you need a body that can move just as fast for there to be real impact. Otherwise people are going to fuck up. Right. And this is the technology of the next two decades. You need to lay down the foundation. Now we need a body like the United nations to come in and then all governments decide at their own level, right? Okay. This is what we want to take and this is how we adapt to it, because the governments which do not adapt today or within the next five years are just going to fall behind.
Speaker A: So in May of this year, the Office of Science and Technology Policy requested for information, the Biden Harris administration, to have people submit individuals and organizations to submit comments by July of this year just about artificial intelligence and priorities of that. And I felt like that was pretty, I don't know how widespread that was. I'm just curious, from a quick raise of hand, if people were even familiar with that in the past few months in the room. Yeah. So like two and what would be 14? Yeah. And this is high interest. So this is like best case scenario. So at best we're at probably half. So maybe call it like 5% of the population, maybe actually submit that maybe 1%, which is kind of unfortunate, but yeah, it seemed that there's, I mean, there is at least attempts are made for people to request that, but it's like difficult to actually get your input. It might make sense to do stuff at the state level. I'm a little skeptical of that. I think it makes sense more at the federal level for like. But I think that those actors are connected. But yeah, I just thought that was like, I was just curious. I have a suggestion, which is that AI is indeed moving extremely fast. And it's not clear that a governed body would be able to, even dedicated one would be able to catch up. And so maybe an alternative would be to have principles. Right. So the body is actually not reviewing any kind of novel application, but it's just establishing principles. And the principles are about governance and maybe export controls and things like that. And rather than submit your LLM. So I'll check in two years. And get back to you if it's appropriate. And I think the other challenge is that in many ways AI is like nuclear power. It has extremely powerful implications, good and potentially very bad, except that it's more easily distributed. Anybody in North Korea, California, Canada can use AI for either purpose or for a purpose that in the end ends up being, have favorable and unfavorable consequences. And so I don't know that a single body would be able to cover everything and indeed corporations today. And I think government agencies too must look at AI across everything from hiring to security to HR policies. And so this is actually a massive problem. And I don't know that a single body can actually cover everything. And at the speed supposing it could, at the speed that we talked about, which is. Are you folks just 1 second, I'll get to you. Just familiar with this concept of positive versus negative definitions of liberty, right. One of them is trying to say the things you're not allowed to do, right. Which I think is usually how the laws in the government, United States mostly work, whereas the other one is trying to list all the things you are allowed to do. Right. And I think that might be an interesting, just to keep back your mind. But yes, I think when it comes to government, a lot of times they are slow to keep up with this government are slow to keep up with this new way, new kind of, because they are not the first who are using them. They don't use them. So I think AI should be used in the government, into their system, into everything that is related to government, to kind of increase efficiency for the people. So I think it's part of the government, they are familiar with it. Then the regulation will be very, I think a lot of times what happens is that they are using tools that they are not familiar, they see from afar. And this is what creates this connection. If there's AI space for one day, at least, they will, they will. Regulations or like regulations is not only and sometimes they can finance subsidize. So yeah, I think it should be used now, but at full agencies or other, whoever can help in this regard. And yeah, I think that we should bridge the gap between this. I would like to just kind of set this thing into the conversation, just to refresh and keep track of like, we are the government, the government is us. You and I, we are the government. So we're very used to thinking of it as a separate other thing. And in a lot of ways it feels that way now, but it is just us. We do choose who goes and bes the government as their job. And so everybody knows that. But I think there's some very significant difference between truly feeling that and I'm kind of talking my bag here, but I think genuinely, if we had a more tangible, engaged connection to our government, we would feel that more generally because of all of the very smart people in here who are probably in the top like ten is very being generous, but probably like 5% of AI knowledge people just because not that many people know about it. And you're here in San Francisco, what are we doing about it? Are we working with legislatures to tell them what's going on? It is us. The government will be as good as the smartest AI people make it. And if you are the smartest AI people and you are not helping your government do it, which is you, because it's your fellow citizens, it's not going to be that good. So when we'Re talking about government, in my head, it's like this is our people who we chose. Did we choose the right folks? Are we helping them do what we want? Because it is very easy to sit and criticize because they're doing terrible pretty much all the time. But we're all very smart and we could have helped them do better. And in many cases, from what I've seen so far and in my own life, I was doing a lot of complaining and not a lot of helping. And I think if all of our best people are doing that, we're not going to get good government. So when we're talking about government, we're talking about ourselves. I have a question there for you, but also for anyone else to answer.
Speaker B: I have a point to answer that, too.
Speaker A: Excellent. And maybe it's the same when you're thinking of. So Representative democracy is supposed to be how to enact the will of the people in policies that affect everyone. Right. To the best of our ability. But the real thing is how much do we trust the government to accurately capture what is in our best interest and then pursue it versus how much do we think there is kind of captured interests by lobbyists and so forth. So I don't know if that was. Yeah, I was going to say, like concrete example. Right. So again, going back to California as an example, there's only like literally two people in the entire legislature right now that are working on AI legislation, and those two, quote unquote, experts do not have technical backgrounds. Right. And so I agree. Right. And this goes back to another issue where I think there is a lack of rich talent working in these committees. Because the pay is so low. So my hot take is that one of the core issues here comes down to the fact that it used to be really prestigious to work for government, used to have really good pay, really good benefits, and that has declined drastically over the last 2030 years where now it's like, oh, you work for government. So are you like poor sort of thing or you're complacent? Right. It's not prestigious. And I think part of it is we need to almost rekindle that prestige to work for the government so we can attract better talent that works in these committees to create better policy. And so I think that's honestly one of the biggest issues right now. And until we fix that, answer your question, we're going to be lagging behind on. I think we're going to fail to create proper regulations and policy for AI. It's going to be like ten years minimum lag.
Speaker B: One way to also think about this.
Speaker A: Sorry, I think you have, yeah, I.
Speaker B: Just want to build up on that. I think there are ways you can make a prestigious, by the way. Like, I have friends that work for DARPA, for example. And it's like a big deal. Even if you come from the world of, yeah, there are ways that you can channel in the talent that has a technical background and instead of coming from a place of distrust, just like ideally that's the perfect. Or private sector also helps knowledge lack. I do think that a lot of politicians are willing and want to have people to come to them. Like, I was talking with Ana show. She represents the 16th District, I think. And she's like, you guys are not coming. Like, exactly your point. You're not coming to my town halls. I have town halls. You're worried about AI. You say that I don't know enough about AI. Might be very true. I think you all are very right. Like, there was a bunch of engineers that she was talking to. Why are you not coming to me to my town halls and talk about this? Give me where I'm lacking. And obviously it's hard to make time to go to town hall. It's unclear to what extent you can bring in points because she was always like, whenever we would bring in a point, she's like, oh, but national safety, right? Like, we prioritize national safety over all these other things. That was kind of her main angle. But yeah, I agree that maybe it's actually easier to fix attending these type of government, normal people mixtures like events. If you fix that, you can probably get a pretty long way to at least make it more of a priority on their plate. Like IF a thousand people go to Ana show and say we are really worried about AI safety, or we're really worried about the regulatory capture or whatever, at some point she has to do something with it, right? Yeah, I think there are ways that in the short term, individuals that care and do things agree with them.
Speaker A: I agree.
Speaker B: I agree with that point.
Speaker A: Finish your thought.
Speaker B: My very small point that I think you need people who have the right expertise within the government to some extent, but I don't think that's largely true. Right. Like you need more independent bodies. For example, if the government wants to build construction projects, you don't need the best construction experts sitting inside the government, right. You just need to know the people who will get it done for you. Or if you're going to build hospitals, right. Or if you're going to build whatever, right? Even if for policy making as well, they always hire independent consultants to help them give the right input. Point of the government is to deploy resources and then to get the job done and to ensure it's getting done in the right way. My point is that maybe we don't have enough independent bodies, right, to take on this job of thinking about policy making, or maybe thinking about the right tools to deploy to actually catch on to maybe things like fraud, GPD. Right. The question is, how do you tackle all of that? And then maybe the government can come into the picture and say, okay, I'm going to hire these five startups, right, to help me solve the problem. Maybe that's what we're missing. Maybe we don't need the best people sitting inside. Maybe we just need to build the right tools so that the government can have the right connection.
Speaker A: Yeah, I would disagree with that. I work on profit, that works on improving the way that government uses technology. And actually, from my observation, one of the big barriers to government doing a better job with the technology that they currently deploy is actually the lack of internal expertise. They do deploy this network of vendors, but there's a lot of regulatory capture. It's basically a duopoly. There's two large vendors that have like 90% of the market. And one of the reasons I see tech projects deployed by government failing all the time is that there is no expertise within government to actually evaluate whether their vendors are doing a good job or not. They don't have the expertise in systems architecture or even UX design to be able to tell whether what they're being delivered is actually good or not. So I don't think that necessarily government needs to be doing all of this in house. But the fact that there is no expertise within government on some of these key areas means that they're not even going to do a good job with the best vendors in the world. My understanding of the flow of talent is it goes from, if you're in government, it's like a triangle. So if you're in government, you're going to consult with some company and then you're like, later you're going to be like, hey, you should hire me. And then vice versa. And then you're at the consulting and maybe there's other vendor and then you can also move over there. And so you just kind of move this triangle and so you end up never actually gaining expertise, but yet you can always have the scapegoat of like, oh well, this consultancy or this vendor said this was a good idea. I'm just like a staffer or whatever. I think a possible mechanism to solve for this problem would be, I heard some cryptocurrency and blockchain this idea of Quadratic voting, where you say it again, quadratic voting. Quadratic voting. The simple explanation is like you have some number of points and you can vote for a number of measures. When you vote for one, it's like one vote, one point, you put two in, but it is now four. And then you put three in and it's like then in order to have castle votes, it then takes nine of your points so you can add more for it to show your importance. This has a couple of failure modes of collusion. It's pretty common, but it's pretty robust overall. If you have enough people, it's very hard to get collusion even. It has to be like very widespread collusion amongst population. But I think it is one possible mechanism because then for me I'm not going to care about, although I like my health, but I don't know a lot about organic farming. I'm going to be like, no, I'm going to let people that know a lot about that vote in that direction. But I care a lot about AI. I know a lot about AI. I want to put all my chance in that basically and vote in accordance with that. So I think that's like a potential solution to kind of like, no, forget policymakers on the special. Wait, so you're saying like, okay, let's say you have ten chips. Sorry. Yeah, I just wanted to elaborate on what Carl said about the way government functions. And this is actually, I highly recommend this book. I'm reading Recoding America by Jeffrey Polka, which explains the dysfunction of government. And actually, a lot of things we're talking about here are illustrated by cases where things actually fail. So you influence the, the legislator says, okay, here are the new regulations, and they're very good, but the bureaucracy, so the executive branch, if you will, the agencies actually have a different playbook. There's a stratification of regulations, codes and processes that they have to adhere to. And even though the policy might be great, they're actually not able to implement it in an effective way, in a rapid way. And so they're stuck. And so every person down the line from there is actually stuck and paralyzed by that stratification of playbooks and procedures. And there's actually a very interesting parallel, which I think AI sort of magnifies, which is that in the book, the author says that software operates with agile development these days, and that is actually a real counter to how the bureaucracy operates, which is waterfall. And what that means, in simple terms is that while AI is evolving every day and agile development may evolve every week. Right. Waterfall development operates with a completely different cycle, which is much longer. And so I think AI could actually, in some ways, help sort of, what do you call it, leapfrog the issues of the past. But it could also just magnify the issues that are illustrated in the book. That's really interesting. And some examples of the book include the VA and the California EDD, Education and Development departments, employment Development Department. And those were critical situations for those departments during the pandemic where there was an influx of applicants. And what do you do? You throw more bodies. If you throw more bodies, you have to train them with the existing experts, so you actually slow down the process. It's a nightmare. And so I think AI could solve that potentially. And I haven't finished the book, so I don't know if there are any solutions in the book, maybe, you know, but I think there's more than meets the eye. When we think about how we could go to the town halls and influence the legislator and thinking that we'll solve the issue, there's actually a need to change the whole way that the bureaucracy operates. I wonder if that's a good dovetail into this idea generally, of how could these tools actually help the functions of government, too. Right? So we kind of talked a little bit about the regulatory oversight and what the best body might be if it's decentralized or if we need more experts internally. Do people have strong thoughts on, like, yeah, if only we could get these tools within the bureaucracy, could this untangle a mess? Could this. So the California State Library, Lieutenant Governor's office, and then we have like three cities are our customers now. So we do sell them and to establish procurement, all that fun stuff with them. But essentially our take on it is that we're focused on legislation at the state level, tracking what the state is doing with legislation. And so our opinion on this is if we can help every city and state agency better understand what the state is doing, which I know sounds crazy, but the actual cities and agencies need to know what the state is doing in order for them to operate more efficiently. At least that's like step one, because the government has to know what the government itself is doing first. So the way we're approaching it is take the Planning Commission, right? So that's like a local government, and the Planning Commission is looking for grant opportunities from the state. They're looking for any sort of frameworks that the state has implemented before, and they have a very small staff to actually take the time to read through all the state legislation. So the way we're tackling is we're saying, hey, planning commission, or hey, city, pay us whatever, ten K a month, and we will essentially take all of your internal data, train our model with that. And our model is already trained on how legislation works. And now I hate saying this, but it's like chat GPT for policy, right? I hate that I just said that, but that's essentially what we're iterating on. So it's a model that's fine tuned on California state legislation, and it's also fine tuned on the organization's interests, in this case the Planning commission of the city. And so now instead of the city having to hire a lobbyist or having to hire a lawyer to understand what the state is doing, they can use our model to do that. Internally. We're doing the same thing for corporations. Adobe pays up the butt to legal fees and external and internal layers to know how is the latest legislation going to impact my product roadmap, right? Like Photoshop. We're going to have to do some new sort of compliance or privacy thing for that. So instead of paying all those people, we're training this model on Adobe's product roadmap, Adobe's P L whatever it is, and then train it on the policy that's coming out so that they can then ask you questions on how it's going to impact them. So I think that's one part of it. But there's so many more layers I wanted to ask if you could talk a little bit about the fund procurement process you went through, because I think that's really important. Yeah. With cities. So we sold City, San Diego, Pica Rivera and San Diego Housing Commission, and Pica Rivera and Housing Commission took under a month to procure because we charged under 10,000. City of San Diego took longer because once you're like over ten or twenty K of software expenditure, then they have to bring it to city council where the council members have to vote, do we pay for this or not? With tax dollars? So that's where that took longer. So we're supposed to have sold to the California State University system for them to track legislation, but we're still waiting on that. We're at month four now because we have to be SoC two compliant, which makes no sense why we have to be Soc two compliant for the Cal State University system. So I think there's also like a misunderstanding of how compliant software needs to be in order to the government. But I'm going to stop ranting for a seC, and I'll just say on that. I think there's a risk here that because of the compliance requirements, the government ends up buying. Buying solutions that they buy in from the companies that are best at doing government procurement. Not necessarily the companies that have the best solutions for them are actually going to solve problems for government and citizens. Yeah. And as a startup, we've been at a disadvantage multiple times because we have a better product, but we're just not as compliant because we don't have the money to pay for all that compliance or we haven't gotten there yet. And then to add a layer to that, there's companies like Carousel, which are government resellers, and they will essentially verify that you're compliant to their standards, but then you sell through them, and so then they get a cut of the revenue and they're like this unnecessary middlemen that we're almost forced to sell through. So, yeah, I could talk about procurement for a while. Currently, the House of Representatives is only allowed to use Chat GBT plus, and they have to have specific, they have specific rules of how they can use it. One of them is like, you can't store history and of course, you can't put personally identifiable information into it, but that's currently the only tool that's used anthropic and whatever the other language tool is not allowed to be used. So I think the government's already starting to embrace it. I think that will continue to happen. The part where this gets interesting for me is like thinking about this idea that I heard in a very small seminar of unemployment, where you have a language model or some other tooling that then has layers built on top of it. So maybe like some of your tooling where there's these additional kind of fine tuning or other kind of processes on top of it, but if you learn that maybe the underlying model, or maybe the process itself is unsafe or discriminatory or something else that's unfavorable, how do you then roll it back, especially when government's using it? Because they're slower to react. And so, yeah, I think in my view, yeah, they'll continue to have tools, but it'll be really interesting if they've gone through and approved things, voted on it. Yeah, we're paying money, but yet you're saying it's unsafe in these edge cases, or maybe it's unfavorable in these ways. It's very unclear how they would then go about the undeployment scenario. And I don't know if they have an agile approach to make it happen quickly, or even waterfall. It seems like maybe waterfall would actually be better in that sense because it's like a swift change and they can pivot right away. What's that?
Speaker B: I had a couple of thoughts. One, I'm just curious because previously during my engagements, I worked and studied a lot on the regulations that were coming from European Union. And I was just curious that why is it that all the fines and all the implications that we see on these major tech companies that are at the forefront of AI, but also previously with the products they launch, come from EU? And I think it's a lot to do with, one, incentives, and second, being preventative, then being reactive or proactive. So I think the idea is to have like an SOP of what is not at all accepted.
Speaker A: What's the acronym? What's SOP?
Speaker B: Standard operating Procedure. So basically, the idea is once you know that these ten coins are something that will just not absolutely be tolerated, and then anything beyond this is under the scope of discussion. But I think what essentially happens, at least within the US, is that the focus is on profits and not necessarily on violations and what the implications are. And that brings me to my next point, that they are currently trying to come up with the EU AI Data Act, Digital Services act is going to be implemented by 2025. So I'm just curious, because I'm an outsider here, I probably don't understand the local politics and governance issues that well. Why do you think? Is it that US waits for Europe or like an external agency to take that lead and explain what that process would look like. Even if that's like a broader hypothesis and wait for so long. I mean, they don't have an equivalent of GDPR, something that is as strict as GDPR, right.
Speaker A: Well, we have the CCPA in just one adopted federally.
Speaker B: Exactly. But I mean, in general, I'm just curious to know your thoughts, because a lot of AI governance, again, would be dictated by the gold standard of what is being projected as the EU AI Data act or something similar.
Speaker A: One, lack of state capacity and two, a general ethos that is less inclined to regulate things, especially on the forefront. That's my. Yeah, and I was going to say look at any of the upcoming, even federal legislation when it comes to what's one of the main sort of sources of truth or looking at Technet, right. Techn is supposedly the most brilliant association when it comes to understanding this. Who's behind technical meta. Right. And so the associations that are drafting the policy with the politicians are controlled by the corporations themselves for the most part. You had a point. I was going to say I'm quite cynical about US politics, but I think dysfunctional government, but regulation from the EU, just because you have regulation doesn't mean necessarily mean it's going to have good outcomes. I was involved with the EU Disinformation act when Meta Google, and I forget who else was involved with negotiating with the EU. I was kind of excited. Oh, this is really cool. The EU is really ahead of this stuff. But going into it, I was quite disappointed. It was overly prescriptive in terms of what they were doing, and they pretty much put the company in a straitjacket. I don't think it necessarily leads to good outcomes. So GDPR, the outcomes of that are then. But I would prefer if governments did think ahead. So China, for example, the three hour or two or three hour rule they had for children on online games or social media that would never work here or be allowed here, but at least they're thinking ahead and that they care. And places like Singapore and probably China do have probably their best talent in the government, as opposed to here where people are waiting to retire or insider trading, etc. If I may ask a question that's a bit more, it's like still within tooling, but it's also more SCi-Fi but you sometimes dip into it. And I think it's somewhat realistic. I'm curious if others like how other people view, especially as these models, I think get more intelligent and they're able to replicate one's beliefs and in particular, policymakers who have a lot of information where they've said a lot of things and it's all recorded, it's all public record, like on C SPAN or typed out or whatever, and you can transcribe all that information on various policymakers, and then you could condense that down and have a representation of them through an LLM and then have those versions debate and get to optimal policy. And then you just review it and you'd be like, yeah, that's probably what I'd say. Eventually. Simulate Congress. Yeah, simulate Congress to speed up progress and legislation. And hopefully it's robust. There's still human oversight and you can improve the process and you still have a human in the loop. Granted, reinforcement learning from human feedback is a shock if you've seen those weird animations, but it's like, yeah, I'm curious people what they think about that process. So funny. She mentioned that I went to the RSA conference, which is a cybersecurity conference a few months ago, and there was a meeting of chief information security officers that talked about what sort of information security policies they should have in their company. So it's not government. Right. But there's an analog, if I can use it to create their white paper or their guidelines. They actually used chat GPT, and obviously they tweaked it to their needs. But AI was indeed an assistant, if you will, in the creation of the policy, so could work. It's worth trying. Yeah.
Speaker B: Just to clarify, do you mean like entropic constitutional AI idea? The idea that you have prescriptive principles set by humans and then the model itself decides kind of like how to reinforce them. I feel like I'm not fully understanding your.
Speaker A: Yeah, maybe that'd be more robust. I was just thinking, at first, you just try to enter what a particular policymaker's beliefs are by just all the things they've said and voted on, and then maybe you can add in some sort of underlying principles underneath it to try to help it be steerable in some way. Yeah. Quorum and fiscal note are two companies that are doing that, but they took the history for policymakers or for people, for elected officials, and the way they're deploying it is to actually predict how ex senators going to vote on a specific piece of policy. So that whole other game theory dynamic. Yeah. And they sell to lobbyists so we don't compete with them, but they're at the federal level and they sell to lobbyists so that they know if Senator X is likely to oppose that legislation. That lobbyist needs to try a little bit harder to convince that senator to vote yes instead. If not, they're not going to be paid by their corporate client anymore. So that's how that works. And it's quorum. Quorum and fiscal note. Yeah, they do legislation tracking too, but at the federal level.
Speaker B: And I'm just curious, so how do they track information asymmetry, assuming, like, I mean, if I have sentence in the parks, but it's not like I stick to my guns.
Speaker A: There's so much going on. What they did is it's all publicly available data in terms of how every politician votes at the local, state, and federal level. What's really hard is to scrape all that data because it's in PDFs and HTML. So that's what a lot of us companies in the GovTech space have spent. A lot of our technical time is actually most of our tech is scrapers like crawlers and data processing pipelines, because all the data is shit comes out from government. So what they did is they scraped all the history of how these senators voted, and every day, I mean, there's hearings every week, right? So they scrape that on a weekly basis and then they're able to look historic and there's different models, right, that you can then apply to say, okay, there's an X percent chance that they're going to vote yes on this policy, because historically they voted no on saving trees. On the topic of shit data, I think that's an apt observation. And one of the areas I think, going back to your question about how AI could be used by government where there's the most potential, there's all these states that have passed clean slate laws where you can basically have your criminal convictions wiped from the record. But the problem is that if you want to get your record wiped, you have to go through these onerous processes to actually get all your records. They're often held at the county level. There's no systematic, the records are all stored differently in different databases, county by county. So there's no data standards. It's really hard for people to get access to it. The state could, if they could organize all that data, just programmatically wipe records for everybody who's eligible. And there's all kinds of examples like that where currently people have to jump through hoops, get a whole bunch of records, pull the data together themselves. You could be programmatically identifying the people who are eligible for food stamps, and just like giving them money, you could be wiping people's records prospectively. I think if you could solve a bunch of that data stuff and apply some good predictive analytics and stuff, this should be like solvable problems. That's the Holy Grail. I'm biased. It was three years ago. The defender's office of LA, they have a warehouse with forklifts because of all the paper records of criminal records. So it was all on like on Prem servers and then a paper backup that was in a fucking warehouse. They have a dedicated forklift driver because so much paper. Is that where they keep the lost arc too? Maybe, yeah. As of two years ago, they switched everything over to AWS and they spent $50 million to do that. Some crazy amount like that. And Amazon made a lot of money, but, yeah, great example also. Sorry, budy. Yeah, no, like these last couple points, I think, bring up an unfortunately unpopular take, which is just that all of these problems we're talking about, like, yes, it's crazy that we have warehouses full of data and stuff. Physical warehouses. Yeah, physical warehouse. I have a picture of it. But in almost all cases, the solution, it's basically never a technical problem. In this case as well, the technology exists. AWS has been around for a long time without innovation. You're saying like, we have. Yeah, exactly. We either have the technology or could have it. It's actually a social problem. Can you get reasonable people to coordinate together and implement the technology that already exists or coordinates to create it? And so all of these technologies are great and we should build them for sure, and they could help a lot. But you cannot use technology to make good people, right? You do at some point need to coordinate with decent people and actually implement this stuff. If you actually want to make the world a better placE, you can't simply write up a program that will make your legislature, not make horrible decisions. You can definitely help on the margins for sure, but we can't abdicate a lot of the social and personal responsibility and just give that all to technology and hope that it takes care of us, because it doesn't now. And I don't think it ever can fully replace a lot of the human elements that we sort of act like we can just digitize somehow and forget about. So in my view, I think that AI, broadly, as a tool, will probably ascent various levels of human cognition. Most likely there might be some weird leapfrogging that might happen. But I think if you think of how long it takes for a person to be trained up to make these connections across data warehouses or paper files and such, yeah, you probably only need like tens of hours to train someone to do that, versus if you want to write up the system that does all that, you need like thousands because you need to be able to be an engineer most likely to dump all that. So if you can allow the AI tooling to be the glue to connect it, I think it's not that far off. I have this hope and also bias of I'm just tired of bureaucracy. I hate it so much. And it'd be really nice if they just coordinated all that information rather than fill up the same form for multiple things. Like when you change your address, it's like a simple thing, VHL change it everywhere. Can I add something to. Yes. So what's your name? Anthony. Hello everyone. Anthony. So we are organizing a project we are going to launch today to bring together people in the government in San Francisco, across local organizations, to talk to them and scope problems, the right problems for LM use cases. And we will also bring together the best engineers in the valley at the hackathon so that they can hack on those projects. And our hope is that people will hack on projects that actually get implemented after the hackathon. And so that's what we are going to launch today. It's called accelerates.org. Do you know AI? Ifi Like AI.
Speaker B: I went with us.
Speaker A: We are really in touch with a few organizations. We also reached out to a few government departments. We just had a discussion with the Department of Homelessness. We also have a discussion with SFO on Monday to scope some use cases, maybe with the airport, also some use cases with SFMPA. But yeah, most importantly, we want to focus on housing, then on homelessness, and then on public infrastructure. It will be awesome to build some LLM use cases in these domains because everyone in the valley is building in the private sector. There are so many LM sales agents, LM knowledge apps, but no public use cases. And so there are a bunch of low hanging fruits that we want to pick. I need to talk to this guy.
Speaker B: Me too. As a working on nonprofit doing AI therapy, because I think a lot of issues like homeless, because I think the health care, the Medicare, I think they cover the physical health.
Speaker A: That's very exciting. Hopefully make an impact here on your points earlier about we are the government and that AI was so I don't think we need actual good people inside government for this to have. I guess I agree on both points and regards to we are the government, we kind of are, but lobbyists that are involved. But for good people to be placed in government, we have to take our responsibility seriously, hold people accountable, and demand something drastic to recode or redesign the system so that we can have those people in place. And then in terms of what AI can do for government, I think it's basic services like going DMV shouldn't be a headache. Old people shouldn't have to call tens of hospitals to get basic services. And government's large V reactive, right? We wait for a bridge to collapse before we start thinking or caring about bridges. It's impossible to hire enough people to monitor, implement every law, make sure every bridge works. So maybe AI is just something that helps scale the services of government and provide it to them. I have a question. Do you guys think it would be better for our elected officials to be part time, which I know on the outset seems like not as great, if you think about it, that would kind of, I mean, if done right, it would incentivize people that are working full time at, say, a Google or whatever other job, dentist, whatever, to also be an elected official. Because I think it's like a lot to ask working professionals making good money to say, hey, put that on pause and work full time for an elected position. So if you think about the actual structure of how these elected positions are created, who are the people that are attracted to? Either they're retired or they're not working full time. I have a Facebook friend who's a state legislator and he sometimes will post meeting with the head of the UC system. What questions should I ask? So this actually is a good way to get input from his social graph, which admittedly is biased, but at least it's input from people who have a potentially professional view but are not elected officials.
Speaker B: Okay, on the part time question, it's quite interesting, but I think there's a lot of friction in the process, right? Like to solve a problem, we're going to create a lot of friction in the process of getting people to actually solve the problem. And then there are questions around always having someone part time, right? They're not fully dedicated. Their mind space is going to be in two places, which I don't think is ideal if you're solving a problem that's so critical. So my point being, yes, we absolutely need smarter people in the government. You guys make valid points, but I don't know how to solve that. And I don't think the solution is to have part time people. And I don't think the solution is to get people to the government because there's a lot of friction, right? You have to change how people think about the government. You have to increase salaries, which will raise so many questions. It's like a trickle down effect. Like how do you increase salaries, say people within AI, without increasing salaries for government employees? So My sense is maybe that's not the right path altogether. If you want things to move faster, you do need a different body to help. The question goes back to money. Right. It does trickle down to money. If you've got people earning so much, they're not going to be happy giving that away. And you can't attract the best talent without money, and you can't do it within the government setup without it being equitable.
Speaker A: Don't commissions kind of do part time work? There are oversight bodies, but most people aren't full time employees at the local level. But I don't know. I'm just at a local level, which has a lot of impact, right? 100%. Yeah. I'm wondering, I was trying to think if that is supporting or against your point. And I'm not sure most of them are part time, but would we say that they are doing well or not effective? And is it because they're part time? I'm not sure. It is like, more than a job. Yeah. The way I do it, I go there and invest my time and just serve. You're serving. You're not hired as a planning commissioner or any kind of commissioner. Comment on that concept with not an answer but a couple of ideas that people might play with. So on the one hand, I get it, because they're supposed to be representatives, right? But they don't represent any one section of society because almost no one's a politician. Right. So being a career politician, I think, has some issues with that. Maybe it should be something you do after having had a career in some area of the world that now informs your. I mean, the Roman Republic had this right where you basically couldn't even enter the art of daycraft until you had achieved certain things in your private life. Right. I get that. I think also age limits, and that's a different conversation also makes sense. I get the jury of your peers thing where you want to pick people from society that are represented in that kind of sense. I get the part time thing. There's a book by Joseph Schumpeter called Capitalism, Socialism and democracy that I read years and years ago. But he has a lot of genius ideas in there. And one of them was this. Right. It's very difficult to anticipate the second and third order impacts of a particular bill or policy measure. And statecraft is itself a vocation and a profession and understanding how to effectively wield that power in the formation of effective policy. I think otherwise what you get is people who are coming up to draft bills and so forth that have never really seen the process before. Right. Can I rebuttal real quick? Please do. Because at the state level, 90% of our elected senators and some members do not know how to write policy. Legal counsel, which is a fancy word for Legislative Council, which is a fancy word of saying lawyers that work for the state of California. It's like a group of what, 20 lawyers? They write every single bill every year. There's about 5000 bills at the state level. And this is the same for every state, right? Also the same at the federal level. So what I'm saying is even these policy professionals that studied polystyrene knew they wanted to be an elected official. A lot of them are still like, they're not writing the policy. The policy is written by the lawyers that are contracted by the state and our state employees. Interesting. Maybe we need a graduate school of state craft. Yeah, I mean, I'm a big fan of that.
Speaker B: I actually strongly disagree with it. I think it should be more accessible. Right. It feels very biased to people with a white collar background. I think I really want more direct democracy. Right. My mom is a cleaner. I want her to be able to have, to some extent, have her interests represented because she's going to be affected by AI policy even if she doesn't know what AI is at any fundamental level. Right. I think that leads to some level of exclusion. Like how do you think about making sure that you actually represent everyone and not the most vocal people or most educated people? Yeah. I'm curious how none of these solutions seem to do full democratic or direct representation.
Speaker A: Because right now, restaurants, right. They're all part of, for example, the restaurant association. So associations were supposedly the answer to that. And labor unions, right. Where everyday people would be part of this union or this association, the association has a lobbyist that then consults the politicians that they're drafting legislation. And that still works. Okay. Right. Those are usually the opposing force to the association, from the lobbyists, from corporate. So if you look at like Senate Bill Three in California right now, you have opposition and support from labor union versus corporate backed association. We see this every day. Right. They're always at ODS. But yeah, I envision a future where the everyday person beyond the association has even a stronger voice. Because at the end of the day, this is my one thing I still hold on to, which is we still have a true democracy to the extent that the politician that's elected is elected by their constituents. So their constituents, given if they vote, which is a whole nother conversation, given their voting power, the politician has to do things that will align with their constituents. And if they don't, constituents won't vote for them again, they lose their job. So I guess that was the premise of how we set everything up. But then if people aren't voting, then that system doesn't work, and then who's the politician going to listen to? Not their constituents. They're going to listen to the associations and the lobbyists. Yeah, I was going to say that the issue may not be about who the politicians are only or who the employees are in the government bureaucracy, because they're all well meaning. I mean, they're there to serve whatever the purpose of the organization is. But I think it may, again, be an issue of process. And as you were describing the topic, I thought this is actually probably just a design thinking topic. Right. So it's not about, sorry, assistance. Yeah. And so it's not about, again, people or legislators or the people in the bureaucracy or the agency. It's more about how are they operating and if they use a design thinking approach. Actually, you would not need, necessarily the lobbyists or the committees, or you could still use them, but they would be informed by a process which actually takes into account the people that you're supposed to serve, which is, I think, one of the tenets of the Democratic framework.
Speaker B: Contrary to an opinion, I think everyone wants to be involved in the decision making process, but the average person does not have the right decision. Right. I think my hot take is that you need. I don't think inclusion sounds good on paper, but if you really want to move fast, you have to listen to like 20% of the population and just move fast. You cannot have inclusion and innovation together. I don't think where we are today, it's questionable.
Speaker A: I'll jump in there. Don't want to include everyone in decision making because they're too slow. I mean, that's certainly a novel perspective I haven't come across before. I would suggest, though, looking at the construction of our modern democracy has a lot of vestigial structures, meaning things that were adaptive to a certain time and place which are no longer adaptive. I think of one example is the electoral College, right. Where in the past it was just impossible to tabulate all these votes at once. So you kind of got to make it simpler and kind of group the votes in a smaller number of whatever, right? You can't fit all the votes on the wagon cart and take them to Washington DC, right? So you just send a few delegates. I think also if you look at, like when the. I'm not Americans, I might get this wrong, but I think it's the first Continental Congress or whatever, when they drafted the Declaration of Independence. So there they sent state delegates to Philadelphia because you can't just phone in, you've got to send the person there. And my crazy different hot take is going to be that. At what point do we realize that having representatives that are supposed to speak on behalf of the people but are liable to corruption through personal interests and captured interest is itself a vestigial thing? I have a hot take. If our transformer model, right, is the synthesis of a mass number of unique perspectives and of blending together a choir of voices, is that not the best, incorruptible, most high fidelity representation of the general will? I love that I'm with you. I totally hear what you're saying. And I think vestigial structures, first of all, I have a biology background, so that's awesome. That's an awesome comparison. I love that a lot. And I definitely think there are things that do not suit the modern world. However, I am pretty strongly against direct democracy because I think it has a lot of failure modes. And my concern is that there are no mechanisms that can fully compensate for bad citizenry. You just cannot design a system that can fully compensate for people who don't show up at the polls and don't know anything about the ballot propositions they're voting on. There is no system that can account for that aside from monarchy. And if you want to go that route, fine, but I'm not going with you. And so the reason I wanted to have this take is because in my opinion, there really does need to be some kind of representative model, just because you do need citizens to be much more engaged than they are now, I think. But you can't have every citizen reasonably put in the work to be an expert on everything that needs to be voted on. And ultimately this comes down to a systems level design problem with the way you allocate authority. If everything is just like a direct vote, then that mechanism, I'm not sure is really any better than just getting citizens more engaged and choosing better representatives. Perhaps a mixture of experts model, something like. Yeah, something like that would be really. But I'm interested how AI could help synthesize these points and maybe make it more legible to representatives. But it's hard for me to imagine ever just firing up my phone and voting on a defense authorization biLl.
Speaker B: In Taiwan, though, like some referendum voting, I don't have it clear as a case study in my mind. I remember that they use phone voting.
Speaker A: Oh, I'm not against phone voting necessarily, but I mean, like direct propositions. Yeah. Like ballot props in California is a good example. I'm not sure I loved ballot props. That's a whole. But it's interesting. It's a cool thing to tinker with, but. Yeah. Because of problems with abstraction and having relevant context, I'm a little bit skeptical of direct democracy approaches. They've also done work. This is the thing that I thought you were going to refer to, but in Taiwan, about using large population surveys and then using LLMs to synthesize the results to find the points of consensus across people's viewpoints.
Speaker B: Which platform was that?
Speaker A: I would need to look it up. That's kind of what I was thinking. Yeah. But anyway, I don't know. One thing I would argue, even with that approach, is that one thing that representative democracy does well is account for a process of deliberation in decision making, which I think you need, which mostly most forms of direct democracy, including those I could imagine facilitated by AI, don't actually have that step where you consider other viewpoints and synthesize things and change your viewpoint, maybe based on arguments. What Andrew is suggesting to me sounds like AI is a benevolent dictator. But I have principles, right? I think I vote based on my principles, not what two options are prescribing and maybe not saying democracy doesn't matter, but it isn't always the best solution. The best system is a system that works. So if they had a democracy in China, they would not have taken all those people out of poverty. I'm from Sudan, which as of a few months ago, my entire extended family are refugees. Now I've lived in Saudi, worked in China, Singapore, and a lot of those countries, they're happy with their dictator. They laugh at this country for being so proud. When you have a joke on TV every day on the news. Yeah. I guess the point is just that the best system is the system that works. Democracy isn't the only way. Yeah, because I was going to say the consensus piece from Taiwan. When you're saying, like, okay, the LM took the highest point of consensus across the population. That's not always the right thing. But it's interesting. I want to look into that. I think the example I always give is this ridiculous ballot proposition that I had to vote on and probably other people did in San Francisco of whether they should fund this better sea wall. I'm like, ask an engineer. I don't know. Don't ask me. I'm not qualified. Yeah. The point about authoritarian governance is very interesting because, and this is something we're scared to admit sometimes, but yeah, they're way more efficient. You don't need to ask as many people what they want, so you can just do what you think is right. And a good dictator will probably outperform an average democracy all the time because they can just build whatever the hell and do whatever they want very quickly. It's not like we are choosing the less optimal side of a trade off on purpose because we think it's important for other reasons. Right? Like everybody has agency and freedom and the ability to contribute. So it's like the best system is the system that works asterisk, which is also like, we might purposely choose not to use some systems because they're very good on some domains. But I feel like a more complete look at what is a system that works would have to include does that system enfranchise the full population? And if not, even if it's better at building subways, I would set it aside automatically just because in the way I evaluate what works, freedom is like a super important part. So it is less optimal. Right? But we're smart. I think we can figure it out, actually. What makes you think that they are better at certain things? What makes you think that states are better at building? Oh, like if you want to build a highway and you don't have to ask the people before you close their home, it's much qUicker. Not sure about that. I think it's like states that are essentially closed states, right? Like Russia or China. If you look at entrepreneurship in Russia, for instance, there aren't that many companies building roads, right? And I think it's like they actually suck at building roads because there's no competition. There's like one enterprise building roads. And that's not gets all the state subsidies. There's zero innovation. So I don't actually know about Russia, but this is like my understanding of there are some crony companies that are working with Indian or these politicians and they got other subsidies and they have zero incentive to innovate. But take China, right? That's a popular example of a functioning authoritarian government. They sure have built a lot of infrastructure. I can add an example to that which I was reading about recently. So there's this high speed rail project in California who proposed from SF to LA for more than a decade. And I think they spent some tens of billions of dollars. And now it's like the cost projection has exploded, and they think there's not enough money to finish it in the world. Pretty much in that time, China has connected like a hundred cities with high speed rail. Like, if you look at the map and it's a total spider web of high speed rail, it's in the time that not a single mile of track has been laid in California. It's an accelerator of economic development. So going back to the authoritarian and dictatorship, there's a recent paper by Dan Hendricks and others that talk about how AI can enable and strengthen authoritarian regimes. Because a weakness point is when you have a transfer of power, you can kind of lock that in with AI. So it's kind of scary because AI will likely stay around, it'll continue to progress in some direction and be better. And so then if one country goes to an authoritarian regime at any point, then it will have a lock in, or it will have a higher likelihood of being locked in and staying authoritarian. And so democracy will probably decrease in a long run scale if we don't have Agi in the next, whatever, hundred years. But if you imagine this happening for the next few hundreds of years, it'll be very unlikely that there'd be democracies. Actually, my question is, what are we optimizing for? So, like a boot on your face and you'll be happy about it. Yeah, I think it comes down to what, at the end of day, was the system optimized for? Right? Like that example you brought up about the high speed rail. With any project like that, you're going to have eminent domain. Right. A lot of the hold up there is because the people who own land are like, fuck you, we don't want a train going through our land. And so in a country like ours, it's going to take a lot more time to get through those issues. Whereas China, fuck you, the government says, we're going to build a train through your land. So what's better or worse? What's right or wrong? I don't know, but what are you optimizing for? What is government optimizing for? And I think in that case, America is beautiful and incredible to this day for a lot of key things. And it's a trade off. It's a trade off for us innovating a little bit slower in other. I mean, I'm always thinking, like, how we can get all of the pots to find one place, but at the.
Speaker B: End of day, the.
Speaker A: I think there's a lot of trade offs that people.
Speaker B: Just from my perspective, from China, I think it's also because China has cheaper labors and more efficient labor. When us passed a lot about abortion, it also feels pretty fast. Didn't feel like it takes a long time. But I think if we focus on AI, I think it's really about kind of the different process for the legislation. I think it needs to be dynamic.
Speaker A: Right.
Speaker B: For example, for AI kind of law, we probably need to improve people way to understand a lot of things, Right. When I listen to TikTok, their hearing, I remember I heard senators saying, oh, they don't understand how Wi Fi works. And I wouldn't probably trust this. I would write law about AI and would definitely encourage listen to other people in tech. So that's my feeling. And I hope just by focusing on AI, we can make it more simple.
Speaker A: Do you have a point you wanted to bring up? Yeah, I was going to say, I guess I'm not clear why the discussion about the structure of government, I guess it doesn't feel especially practical, like, I guess, until maybe transformative AI, the CCP seems stable and at least at the US, I don't see any major democratic reforms when it comes to how Congress works or how voting works. Yeah. So I guess, I don't know, is anyone more optimistic? What is the point you're making exactly? Why would we talk about these things if they're unrealistic? Yeah, I guess I'm asking if you think they are more realistic, because otherwise it seems not especially totally practical to me. Let's zoom out to the context of what a salon is and the history of salons in the history of intellectual discussion. Right. So salons first emerged in the 17 hundreds in Enlightenment era France and Paris. Right. At the time, it was a place for people to discuss radical new conceptions of how the future might look. And through those discussions, through conversations with people like Montesquieu and Rousseau and so forth, they drafted principles that ended up becoming the foundational concepts that informed the formation of America and the Constitution, as well as the French Revolution. So I think the purpose of these discussions is never to limit our thoughts by what we think is pragmatic according to today's norms and standards, but really to actually enable people to think, how could we radically reimagine the future and to inspire some optimism that we are the government and that we can change it if we are committed and interested. And so I don't want to tie us too much. I mean, it's good to be grounded in reality and what's feasible and realistic. But I don't want anyone to feel like, oh, maybe this idea is too outlandish or anything like that. So this is the context, I think. Yeah, I don't want anyone to be unwilling to say anything. I guess In 1750, do you think it was a reasonable proposition that within 50 years, most of the major monarchies of Europe would be overthrown and replaced with constitutional republics? I was not around then and haven't thought about it. It would have seemed impossible. It would have seemed impossible. It would have seemed insane. It would have seemed. But we might only have five years until transformative AI or something. Oh, no, I just want to talk about the still to your point about the infrastructure like China versus. Because I really CES, I know people like CES, like the major trade show of your. So a big part of CES is getting a lot of the congressmen elected officials in Vegas to see what's the latest going on in TAC. And a big part of that is how we're going to compete against China. And one of the big discussions there is China obviously wants their control. A lot of what they have still is based off of controlling their people. And so I think we're in a race in terms of using AI to figure out at the government level how we're going to let innovation prosper here before China gets it. I think that's one of the key things, not to pit ourselves against China, but it is a key thing that the elected are thinking about, just because that's what a lot of those conversations were around. And going back to that infrastructure piece. Yeah, I think it's embarrassing that we still haven't built a single high speed rail. But I think it's interesting when you look at it, a lot of it comes down to individual voices and freedom versus authoritarian control of the government. And I'm not saying one's right or wrong, it's just something to think about. I'm curious on how people think about better systems or mechanisms to create better cooperation with AI development, because the race dynamics really scares me. I think that is a sure way to catastrophe of like, oh, we should deploy this thing because we don't want China to do it. And then it is like, yeah, it can have various catastrophic events because it's unsafe in a fundamental way. The short argument for why I'm like an existential risk, or why I'm concerned about existential risk for AI, I think it's important. So if there's like two axes of intelligence and human goals. There's a space of possibilities of where it is super intelligent but not aligned with human goals. This, in my view, is kind of the default because you're training systems on various points of data and trying to bake in your human values into the system is a pretty big challenge, especially trying to do it in a machine learnable way. There's a lot of examples of current reinforcement learning systems that will optimize for the reward amount, but not have a human goal. So there's this distinction between human goals and values and the reward that is sought by the system. The second point is there's various goals that we can assign an AI. So let's say we like to sign, make the best government or make the most profitable company, whatever it might be. The thing in between getting to that goal is power. And so it's always an instrumental goal to its final goal. And so it can be like, oh, well, I need more power. So therefore I'm going to take over the stock market and I'm going to make sure that people can't shut me off, and I'm going to make it where everyone is like, the best government is maybe like a horrible. Everyone's basically enslaved to an AI that's like an extreme. It's cartoonish, I think it's actually. But it still is in the realm of possibilities. And I kind of mentioned human values. So, yeah, I'm really concerned with race dynamics because I think we could deploy a system in which that kind of happens where it's like the US is number one, but it's like at the expense of maybe only making Americans well off. And then does race dynamics mean arms race dynamics? Yes. Not like ethnicity or ethnicity so much. While I was asking which were we optimizing? Like, if we're trained a model that were to actually draft policy and we wanted to do better, I guess, what are we optimizing for? I also find it. I'M always like, when people talk about human goals in this space, I'm also like, which humans are we talking about? Because at the moment we're talking about engineers at a small number of companies that are incentivized by making money through advertising. I don't know. There are currently roughly around 300 AI safety researchers, and there's probably like tens of thousands or thousands at least, AI capabilities researchers. So there's only a few hundred people actually thinking about for goals, human goals aspects. An intractable solution is coherent, extrapolated volition, where it's like, if I was the type of person that had enough time to think about this particular thing. And I was like my idealized version. And I also was able to think about from other people's perspectives, and they were their idealized version as well. And you shuffle like this out. What would be the optimal thing I would do? Yeah, it's intractable. You can't compute it with the amount of resources in the universe. But if we had infinite resources, we could solve the alignment problem. Done. But yeah, we have to have another solution that's probably in that direction. I was going to say, on the topic of the geopolitical race, a lot of these AI technologies are actually open source. Well, not the forefront. GP Four isn't. GP Four isn't, but Orca llama in some areas, equivalency or are superior to open AI technology. And anybody in North Korea can download it. You know, the number one export of United States is historically to every other country in the world, intellectual property. It's the form of government. Yeah, right. It's the three branches with the checks and balances and all this kind of stuff. So I wonder, to what extent does open sourcing these models create both this arms race perspective, but also this potential for flourishing elsewhere? Well, I mean, to your point, when four G, I think it was, or maybe it was 3G, came out, it was seen as a way for developing countries to leapfrog the telephony infrastructure gaps they had and deployed. More mean, if Singapore, Taiwan are good mean, you could potentially help developing countries have more effective digital governments than OECD democracies.
Speaker B: Yeah, I just wanted to add to your point, I think India is a really good example because having worked with the government for a couple of years, the payment systems and the banking, I mean, they have really redefined so much of what you can do in terms of efficient public service, last mile service delivery by incorporating all these different technologies. So it would be very interesting to see if they can kind of retain that same core ethic towards AI. Because when I was working with one of the state governments, what we did was we created this tool where you could answer, say, ten questions and see if you're eligible for some of the government schemes or programs that exist. There was no AI component to that, but I have recently heard there are discussions that they want to introduce those filters and those screening criteria. And my biggest concern is, when someone is answering those questions themselves, there is always an element of trust and authenticity, because someone wouldn't lie, and if they would, they would be punished, because then they would just not be eligible. But once you start creating superficial screeners based on how a certain population answers a set of questions, it gets tricky. So my assumption is that a lot of those countries like Estonia, India, that took lead with digital services transformation back in the last decade, would probably set the tone and example for incorporating AI within the digital service.
Speaker A: I think that's very cool. I think it also requires some amount of institutional capacity, because again, technology does not build institutions, people do. And so if you don't have the social technology in place to support an institution, whether it's a government or any other kind of NGO or private or the legal system, then any amount of cool AI technology is still not going to help your extremely corrupt and underresourced government develop into some perfect model of the future, I think. And actually the US has exported a lot of very good and valuable things about governments. But one thing that we also did that did not go well in a lot of cases was try to just airdrop democracy into a place that did not have the institutions to support it. And so you can adopt a constitution and it can be great. But if you don't have the implicit and explicit knowledge, traditions and the people who are used to piloting the bureaucracy, and then we're just like, okay, good luck, you got it, have fun. It's not going to work. And so I do think technology can help with that, maybe make it easier to pilot these bureaucracies. But I don't think just saying like, hey, chat, GPT is now in your language, go at it. I don't think that can ever get there. And so I think any solution about exporting goodness to the world and helping it cannot be purely technological or any country like us. Influence has high. Who wants to take that step? Can't just say like, well, we have AI now, so let's develop, right? You need to do the hard work of institutions. And I think to your earlier point, I think India is actually doing that, right? So just like the US exported the principles of democracy, I think India is actually exporting this digital government concept to developing countries. And in that case, it's not just the blueprint, but it's also assistance, isn't it?
Speaker B: Yeah, it's very interesting. So I interned with the UN last summer, and we were working on an India project, and India apparently has outsourced pretty much all of their vaccine knowledge in terms of how do you store the transportation, the know how of how do you open bank accounts and connect so many people with the financial infrastructure that's already been existing in the country for decades to a lot of African countries, interestingly. And now we are trying to kind of condense this knowledge into like a format for anyone as an open source model who just wants to incorporate or start from scratch. But I still am little cautious because it sounds little paternalistic in a way. You don't want it to be prescriptive. You have to be a little cautious of the ethos of the country or the population that's planning to. But I think as a principal, it's good that they believe in knowledge sharing and they are trying to promote it to see if they can also get some course corrective measures to improve it for their population as. Yeah, I think that is true.
Speaker A: Exporting of bombs and dropping bombs did not do much help the US or the world, but tools from meta, Google, Wikipedia have done a lot. I believe when I used to visit my cousins 20 years ago, they'd be studying under candlelight. And until recently they had the same tools that we did have now. Access to information, entertainment, ways to express themselves, learn, create businesses. And because they're more exposed to the rest of the world, they don't have to rely on the traditional gatekeepers of information. They're more exposed to different ideas, different lifestyles, different ways of governance, and they demand more. So I don't think know, if it wasn't for the internet, I don't think women in Saudi Arabia would be able to drive today, for example, or the Arab Spring. Debatable whether or not it was successful, but that would never have happened without the tools that came out of this place.
Speaker B: I also think this whole thought know, using AI, to your point, using AI as a tool to lead frogs for one country, the US for example, to be head of China is just like at the end of the day, even if some countries build some innovation, you give other countries like a couple of years, right? Everyone gets to the same place. What's the point? I think it's true noise. There are a lot of areas where we should focus our energies on and just leapfrogging, in my view, is very stupid.
Speaker A: What does leapfrogging mean? Does it mean like set your head in the arms race?
Speaker B: Yeah. So it's somewhat like I'm going to use this tool against you. I've got the upper arm, right? Like I've got the edge and I think it's good for a couple of years. But if you look at all other technologies in the past as well, right? It's a democratic world, it's a globalized, interconnected world. At the end of the day, capital and technology will flow.
Speaker A: I disagree. I think when it comes to these discussions, it's how can we devote more of our tax dollars to promote more of that innovation so that America is ahead. That is how they're thinking. That's how a lot of these elected officials and people in Department of Defense are thinking. And whether or not you agree with that or not, but that's part of how America still sees the armed force on the technological front is how can we take the tax dollars that we have and give more of that to Stanford, give more of that to loyal America, whatever universities and departments that we can develop technology faster in China or Russia. I'm just saying that's how it is right now. Not that I agree or not agree or not with it, but what I do think should happen is less regulation around AI. I think it's like fire, semiconductors, electricity. The second you start regulating things more early on, I don't think it's healthy. I think at first it needs to be less regulation for us to even figure out what are the beautiful, innovative, creative things we can do with it. And yes, there will be harm done throughout the journey, but that's, I think, part of the human path.
Speaker B: I just want to add some, although I'm not involving any party or. But I feel like Chinese government, they don't think that way, that we're blockchain. It's also a new technology. And then what happened in China is they completely banned it and then us has been allowing it for a couple of years. And I feel like the reason why they banned it is because they think, oh, it can cause borrows, people may lose a lot of money. And yeah, I think that was the reason. And for AI, the thinking was, oh, it doesn't seem like it will cause people to lose money, although, I don't know, but it seems like it can actually help peOple. So I think that's why in China right now, the regulation is more strict in terms of.
Speaker A: I think it's interesting just sitting in because there's literally like those elected congressmen at CES and it happens once a year. I was surprised because that was the main conversation point, right. It was like, how can we spend more money so that our tech leave frogs every other country in addition to our military? That's all like at the federal level, it's most of what they're focused on.
Speaker B: Even with the state governments that we've been working with. I've been on two different projects. Right. And this is the governing thought, right. Like how can we be the best state? How can we have the best stats, right? And I'm like, sure, all of that is good, right? It's good to set an example. It's good. But you have to have the right motivation in place, right? And what's your motivation? Is it to do good by people or is it truly to deep frog? Sure, that's a good motivation to have, right? But I think we're the kind of people, if we're making up the government, we can also make up the aspiration. And our aspiration should be to do good by people. And as a result, of course, the US will do well, I have no doubt. Right? But your primary motivation being that the US has to leave Prague is, in my opinion, not the right one. Because then the governing thought is like, how can us be the best? You're in a competition. But if you're thinking of, okay, what's best for our people, the thought is slightly different. And I think that makes a world of a difference when you're trying to build the best product or the best.
Speaker A: Software or the best, what does it mean to.
Speaker B: One example, right? So if I take healthcare, if your governing statistic is I want to be the country that has the best healthcare, it has to be better than China, right? So what happens? What's the process, right? I look at what are the top metrics, right? Death, for example, or how fast is my response rate, right? And then I'm going to compare everything against China, right? I'm saying this is bad, and I'll tell you why this is bad, right? But if the problem in my country is like a different pandemic, that's not even a problem in China. I should be solving that first instead of looking, comparing my statistics to China.
Speaker A: Oh, so you're saying that we're hurrying ourselves in again, broad strokes application here, that America is hurting itself by pitting a lot of its innovation and money and focus on things that are competitive to other countries where instead they should be focusing on country specific issues, growth, right?
Speaker B: For example, for SFOs, also going back to our debate around democracy or any other form of government, homelessness is a big issue in India, right? Like we're a country that has had a massive homelessness population. And the solution to it is very simple, right? Not in essence, but in general, if you look at the problem independently, right? You know what has to be done. Everyone knows what has to be done, right? What makes it tricky is the governance. Like we've made it tricky, right? Because everyone knows what the solution is no one's willing to say it, no one's willing to do it. But if you had like a large governing body, right, you could get rid of the homelessness issue in like a couple of months. And I'm not saying it's the right solution because it's maybe not. And that's debatable.
Speaker A: Can I shred? It's building, right? I was wondering. It's building. I just want to build on the comment you brought up with this competition with being the best versus providing the best quality of life for its citizens. And I think my perspective is that governments compete with one another in their ability to provide a good life for their citizens. And if you look at the Cold War, the Cold War wasn't won with tanks and bombs. It was one with full grocery markets and superstores. And know the Berlin Wall didn't fall because it was bulldozed by military. It fell because people tore it down because they wanted blue jeans and Michael Jackson a tracks. Okay, so it's sort of like thinking about this is know, ensuring the best quality of life for your citizens by ensuring the conditions for prosperity are enshrined in the institutions and in the regulatory frameworks, I think is the best way to be the best. And I think those things are very much the same. I just want to, because coming from France, it's also a lot about practicality. I think everybody, by one large, they are trying to do good. But I think America is succeeding because maybe it is more grounded into the reality. And I feel that competition is at its core. But competition is not always bad. People want to be better, even better than their own self. This is the best competition. So it's not always bad because it pushes every. And socialism is about to say, well, we need to be. But it's not about equality. It's like how to aspire to something that is more than yourself or more than the society itself. And then when you give yourself this opportunity to be better than you, even self, which is the highest for me, level of competition, it's like, well, this is how we output this amazing product. I think it's a really important point. I'm going to yield the floor after this. But totally, it's about providing and improving quality of life for the people within your country. Historically, the number one predictor of revolutions is the price of bread. Price of bread? Oh, price of bread. Yes. If your food price skyrockets, the people are unhappy and it depose the authority. This is why I really want to understand what elite means, how the principle translates into edit, because sometimes this is where the things are not efficient.
Speaker B: Even regarding this principle, a lot about this question.
Speaker A: Well, I think to pick up on that, one of the things that I'm interested in and concerned about is I think that actually maybe the biggest impact from AI will come from the second order effects rather than the direct impact in government. Right. So if you look at social media, government didn't have much to do with social media, but social media ended up changing a heck of a lot about our politics and then government as a consequence of that. I see the likeliest course for AI is for this to lead to greater concentration of wealth actually in a few small companies, given the limited availability of chips and the high expense of training these models, I think that that's likely to have a destabilizing effect over time. And that's something I'm quite concerned about because I think that could undermine democracies, destabilize a whole lot of countries. Do you think there's parallels with railroad back in the day? Similar. Right. There's AWS, GCP. I think about this a lot too.
Speaker B: Right.
Speaker A: Google Cloud, Azure, there's like four. Right, big monsters back then. There's only X amount of St. Like Carnegie had his fuel factory and a couple others. Are we going to go back to, I mean, not go back in time for that, but I feel like, I'm curious what aspects of, like the Carnegie Rockefeller era we're going to see come up again in the next 20 years.
Speaker B: And I just wanted to add one thing, and in addition to everything you said, I'm also deeply concerned that if two or three, four large corporations control the narrative, it will essentially just end up become an eco chamber. And then it might end up in a situation where people are just struggling to get their voices heard, where the assumption was that the representatives would do that, would do that thing on behalf of us. But now they are also part of the same ecochamber. Because over a period of time, you have people who think they are experts now because they have been working on this one problem for a longer period of time, and then there is no new perspective. And then I don't know. But ending up in a situation where it becomes an ecosumor is something that I often think about.
Speaker A: I would be a little bit careful with the railroad comparisons. I like it a lot and I do think there are things to learn there. But I also think it could lead to conclusions that I'm not sure still hold presently. Because the foundation model AI companies are going to make huge amounts of money. And I actually think that's great, because when you make a world changing technology, I like that our system produces world changing technologies, and I don't mind if they make a ton of money in the process of it. I think with a lot of the railroad stuff, one, it's a little different because it was like atoms in the world, right? And so the way you deal with physical stuff is a little bit different than digital. But we also allowed a lot of things to happen that we would never allow to happen today. And I think just conflict of interest did not really exist at the time. In the Continental railroad days, Leland Stanford was the governor of California and also the principal of the railroad company. Right. And so we allowed a lot of things back then because it was like there were just no rules. Fuck it, do what you want. It's all good. And I think we've learned a lot of all the bad stuff that can happen when you do that. And so even the context of the AI debate, I think, currently is much more careful about a lot of those harms that could come out of that, where you have basically companies unaccountable to the people, really significantly shaping the social sphere. And I actually think social media probably helped us out here by not being maybe as powerful as AI could be and doing a lot of good, and then kind of allowing bad stuff to happen, too. So now everybody is like, whoa, we need to be really careful about AI. And I'm actually kind of, like, optimistic that our hesitancy is going to prevent some of the crazy centralizations of power that happen with the railroads and some of the accidental harms that bubbled up out of social media, because we weren't used to thinking about how these kinds of technologies can do that stuff. So, yeah, the railroad thing is good and useful, but I also think we're just ever so slightly wiser than we were at that time. I want to say something about the collision, especially when it comes to tech. This is what I generally think, and I see whenever there's regulation in tech, it's always very slow. And look what's happening now. They started regulating in us, which is what matters, because, let's be honest, follow only us guidelines, and people will care. As much as coming from France, I can relate. The things are going so quickly. I don't see the regulation of AI will come at mean, and now it's even so because this is what happened, but now it's happening too fast. So I think there is no way around. Either way, you will use AI, because of the China, you need to use it, even in the government. And there are a lot of points, like, for example, having huge kinds of data and being able to use them to kind of having efficiency in the dark or even in the cameras, like having low in the quiet. There are seven or eight direct applications that you can use it for, and you can use them, and there is no way around. So either way, we need to use it. I think we should look the minimum amount into the bad size because it's practical, it's not ideological. It's the time by which we understand all the bad sides and we put regulations. There will be another innovation. So why all of this? Google and Facebook and meta, I think I mean meta. And I don't think they will be able to keep building that thought. And then we got to come to our final conclusions. Let's get a quick point to. Yeah, quick. So history, for sure, repeats itself with variations. And if you look at, Congressman Tony Koala told me one of the most insane things that I will never forget, which was, look at what happened with Abraham Lincoln and the end of slavery. We went from an agrarian, farm based economy to an industrialized economy. And so all the farmers are like, we don't want to change, right? We want to keep our ways. And so that was the south and the north was the industrial New Age coming. And there was a war, there was a civil war, and then there's a bunch of other things around, human rights, et cetera, that happened again with Trump. Okay? We went from a industrial based economy to now a service based, blue chip, more focused economy. And so we have had this huge fight between both now the agrarian south and Midwest and all of the old industrial right side, which are all with Trump, versus the blue Coasts, that are more on the service based side of the economy. Right? And so we had predicted in 2018 that there was going to be a revolt. And look at what happened with insurrection. Right? History repeats itself with variations. We didn't have a full op civil war yet. So what I always ask myself is, where are we now in parallel to the past? So what was, like, the last, at least with artificial intelligence, which is, again, a very broad word, right? I don't know if we're looking at computer vision applications, language models, there's many applications to it. But what was, like, the last large technological sort of innovation that's very similar to it? And look at what happened there. I'm not sure if it's the semiconductor, I'm not sure if the introduction of electricity, but that's one of my questions I would pose to everyone is to the degree that this is going to change society, which other technological innovation should we pitt it against? I don't know if it's electricity or semiconductor. Do you have a quick point? We got to move towards the conclusion. Quick point? Yeah. It's not like the railroads with a variation, kind of like you said, I think maybe worse. I think people should get rich for creating great things, but there's no limit to it because the market, I think, controls everything. So market has enabled these companies, and they're more influential than ever before because they have global presence. Okay, I want to wrap things up a little bit, which is a great segue to both your points. There's a great book I want to recommend on this topic by Carlotta Perez called Technological Revolutions and Financial Capital. And the primary thesis of this book is that with every new technological innovation, you have some period where this technology captures what you call excess market returns. I mean, it's highly profitable, but over time, new entrants come into that market over investment, speculative frenzy over building the railroads, the canal mania, whatever. It leads to a commodification of those goods. And when those goods become commodified, they enable the next cycle of revolution. And so from railroads and the commodification of freight went to the chemical industry and the commodification of input chemicals. And then more recently, like, if you look at the birth of semiconductors, really it was the telecoms industry and at T and electrification and the Telegraph, and then that led to electronic switchboards and all this kind of stuff. And so really good book. What's the title again? It's called Technological Revolutions and Financial Capital by Carlotta Perez. And it's a really good book and it's really great to think about. I think one thing is that these foundation models have been commodified in record time and what they enable as a platform to build on top of in terms of not just new products and goods and services, but new models of governance, new models of representative democracy, I think is really exciting. So I really appreciate everyone for coming here today and your time. It's been really awesome. I want to make space just in the last 2030 minutes. If people have new ideas that really stuck out to them today, that was like, wow, I didn't thought of that before. Feel free to volunteer them right now. Not everyone has to go or whatever, but I will take a couple of quick notes just on what were the standard ideas or the developments of thinking that you felt occurred just within. I've known about the high level complexities and intricacies of government, and I feel like I have gained a further, deeper understanding, mainly from your points and other people that have worked directly in government and how it's not yet just one thing, it's us, and it's also these various institutions employed by people that are quite opaque. And so hopefully your company will solve some of that for at least SF and get more housing. What one thought I think you brought up really well was this idea of having a supranational governing body that could really be really oriented and adapted towards anticipating the changes that are coming about and could be able to respond a lot faster than normal national government. I thought that was really cool. What should government optimize for? Right? Yeah, I still don't know. Utils, I guess. Like historical parallels to the current emergence of AI. I would love people's thoughts on what was it again? Sorry. Like historical parallel, kind of building off the last point, which is like, what is the most similar historical transition? I don't know. Like the Internet is another one. I think you got to go bigger. I think industrial revolution is really the only thing that I think it's industrial. Comparable magnitude in terms of reorganization of society from 95% agrarian to 5% agrarian. And look at a knowledge economy. Shit, you're right, because it's going to change a lot of these service based jobs. So the quote from my sociology prompt that always stuck with me is, be very grateful the industrial revolution happened, and even more grateful you weren't the one to live through it. Yes, but we are living through this next AI revolution. Yes, that's what I'm curious. Should have been born in 1946. What's the year that like Bezos and or not Bezos, but like Gates, jobs, et cetera, were all born in. They're all born like in the same year. That's right. Yeah, totally. Any other? Well, I think you talked about exporting democracy. I think the conversation about is there a framework that can be built for digital government that could be imported or exported? We talked about Taiwan, Singapore, China, and other countries that have different models, other patterns or blueprints that could be borrowed or exported. I don't think we dug into this a huge amount, but one thing that was really interesting for me was hearing different international perspectives on this and for me thinking through how AI is going to have different impacts in wildly different impacts in different parts of the world based on systems of governance or the competition. Also how the government can use AI so that the public sector will be efficient because a lot of I was in Dubai not so long ago, and Dubai, for example, is 0% taxes. So the government can make money actually. And with these powerful tools, I think the private sector can bridge also the gap between the private and the public. If they use it efficiently, they can not only have high performance, but make money, which is, I think, further out doing it. So on.
Speaker B: Also, on a lighter note, not related to AI or government, but how the Earth is cool. I used to think Mars is cool and I want to do a trip to Mars. I think Earth is cool.
Speaker A: Mars is cool, but Earth is just look at all this stuff. Mars and the moon do not have all this stuff. And it's pretty hard to make it have all that stuff. So like, man, Earth is just so cool. What a great place. Earth is better than Mars. Earth is pretty sweet. Don't see any waterfalls on Mars. Yeah, exactly. Zero water. Also, think about us going to the Moon was spurred out of competition. That's true. And how much did NASA inspire a new generation of scientists and engineers that built the world today? I really like the way you phrase the purpose of these, that we have these ideas, we have discussions, and then in maybe a few years we're just like, something spins out of it. Jordan and I were actually busy taking notes, and in the next few weeks we're going to talk with government department and try to find some problems that we can actually solve. At this event later this month, will you be sharing like emails or LinkedIn or something so we can all connect? Yeah, I'll just leave my laptop and if you want to be put into a group email, I'll just send the summarized notes and then I just group, like send it to everyone so you can all interconnect, I guess. Also I've always asked people, but should there be a slack channel or something that people want to join? Because I think one thing we want to make sure we can enable is other people to organize their own salons in the future. And part of this crazy scheme is to record all these ideas, synthesize them using AI, and to develop some way of interacting with this body of knowledge and this collected works and ideas, sort of AI accelerated discussion. I think this is actually close to my heart because I feel like this is a way of producing more what I'd call civil discourse and civic society, which is people that have vested interests in responsible thinking about how to shape our self government. So if anyone has like, yeah, we should sort of slide. Just let me know and email is hard. If I want to connect with totally Mohammed here, I don't know which email is going to be his. All right, I think we've hit critical mass on the snake of Slack. So I'll do that and I'll just invite everyone via email that showed up today. And once you write your email down, I'll just invite everyone there too. It'd be interesting how we can get other diverse voices in here because obviously it's heavily tech focused group of people, I assume. So it'd be interesting to get people in healthcare. Totally. Well, we have just use word. We've had sort of rotating themes. I am a human and I am rate limited to one salon a week. So that's why I encourage other people are interested in hosting too, at your own apartments or public gathering places, like for.
Speaker B: Going back to India like two months. And I'm totally stealing this idea.
Speaker A: Do it, do it. We can give you the software infrastructure if you want to automatically transcribe and summarize the stuff as well. And then if you want those conversations to be incorporated into our growing body of work, then you could also have that. That'd be cool. Salon is a service. Salon is a service. Salon is a service. There's one concept you mentioned, which is that the original salons end up generating radical ideas. And I think that could be an interesting topic as well. What are the Radical ideas that we could come up with? Right? You don't know what monarchies are going to get deposed by the next Napoleon. A radical idea. Swan in San Francisco. What could go wrong? Yeah, very good.
Speaker B: Sorry we came late, but I'm just wondering if there were discussions about the negative side of how government may use AI. Has that been discussed? For example, government can use the. Has that been discussed? Fake news is one. And then ideologies, let's say authoritarian. Okay. It's based on training the data, the set of data, and the certain ideology. And everybody using that kind of technology is going to get into that kind of ideology. Kind of like a brainwash. I don't know if that is something need to be discussed.
Speaker A: That's really funny, actually. And it occurs to me that because so much of this was in an American context, we were actually talking about how we can help the government get better at using technology. Not like worrying about what the government might do with it, because we just assumed they can't even use it. That was like the context. But you're right, there's like a whole other direction you could approach it from. I feel that's a whole nother slot. Yeah. What if government could use AI? I mean, we have to stay grounded in what's possible. I'm just joking. No, it's not. Yeah, for sure.
Speaker B: I think with any technology there is always a good side and the bad side. And if we are still not too late to think about also the bad side and try to avoid bad things.
Speaker A: Yeah. Things were a bit more level when the best weapon in the world was a. I mean, if you read Edward Snowden's accounts, the government is actually pretty good in certain areas. One part of the government that works. Cool. Any other ideas, takeaways that questions you'd want to have discussed next time too? That came up like that one? You can fill that with that essay. Yes. All right. If anyone's interested, I think a really good resource to stay up to date on this, and he does a great job summarizing a lot of AI developments is import AI by Jack Clark, who's an anthropic, formerly at OpenAI. He does a wonderful job of summarizing various research and what it will mean for you. Type in your emails. We can just kind of chit chat.
Speaker B: Article you mentioned about how AI can be used to strengthen authoritarianism. You mentioned it.
Speaker A: Authoritarianism, yeah. Dan Hendrix. I forget the title of it, but. Dan Hendrix. And that's like a recent paper that he wrote. Super intelligence, lots of book. That's the book. That's Nick Bosch. Import.
Speaker B: So cool. If you get interesting ideas out of this and then it becomes into like a whole movement around the world.
Speaker A: I know, right?
Speaker B: You're the innovator, right?
Speaker A: Totally, yes. And if anyone is interested in the implementation of this technology. I like the acceleration. Totally. We got to fight the. What's the Berkeley movement? It's all about like tourism and stuff. Yeah, there we go. Have you guys worked with neighbors? For better, because we're helping them rewrite the code on police reform for SS. Going to sing tweet. So I must say. LK 99, what it was called. That's right. Are we back? I'm an LK 99 influencer as of last week. I know what that means anymore. Are we back? We might be incredibly back. Harder than ever before. We all of us collectively are back because. LK 99. Room temperature superductors. What was that? Oh, my God. This guy has social media discipline right here. We might have.