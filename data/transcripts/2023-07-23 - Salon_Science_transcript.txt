Speaker A: Difficult. If they could get some improvement in their life somehow from that, would that necessarily be bad?
Speaker B: Good point. Yeah, it would be, I guess, therapeutic in that sense. Right? Yeah. Right. That'd be huge. Yeah. Um, welcome.
Speaker C: Hi.
Speaker B: So we've all we can go around again. I'm Andrew.
Speaker C: You don't have to go around.
Speaker B: Okay. Do you want to introduce yourself and a little bit about your interest in.
Speaker C: AI and kind of apologies for the late prize. My name is Chris.
Speaker A: I live in Oakland.
Speaker C: Bart. I have been in the tech world for a long time. I started out in 2004. Startups and small companies. I've been at Google. I've been at Uber. I've been on. It was actually predicated on the idea of using question answer to learn more about people so they learn more about themselves and they could show up better relationship.
Speaker B: Very fun. Right? Cool. So cool. Yeah. Well, I kind of gave a little preface here. So this AI salon isn't something that. It's just casual conversations that we kind of host every other week. There's occasional figure events that has as many people as we can and different venues and more conversations there. But the topic today was, yeah, relationships and dating. Right. And so not just like romantic relationships, but also just like, personal relationships, like artificial friends. I don't know. When I was a kid, I had a little Tamagotchi.
Speaker D: Right?
Speaker B: It was like a really lame little pet with, like, three buttons. And now you can have conversations that could be actually very therapeutic. Yeah. I was just kind of asking people, have you tried, I'm curious, in your perspective, having done this conversational a company in the past, what's your take on the state of affairs here with conversational agents? And what are maybe some upsides, you see, and if there's some risks as well? I guess that's the question, right?
Speaker C: One of the thoughts is, how are the ways in which culture is brittle or fragmented or challenging, especially in community age, where the things that we see to read, you may assume are generalizable and that everyoNe's always filter bubbles. And so the degree to which you can build resilience within yourself, that then allows you to encounter people of other persuasions or experiences or ideas, and then to use, whether it's LMS or conversational agents, to broker kind of like a mutual conversational space in between to foster better understanding. Almost like a kind of relational or empathetic translation service, you can imagine, that creates sort of a mutual ground, almost like a therapist that kind of holds each other, that may get fixated on certain ideas or things that people say, or the way they're said, when the intent or meeting might actually underline, it might be okay. And so, as a palliative essentially, to conversation space, I think there's some really interesting opportunities there. However, the way in which a lot of these things get built out is usually like single player mode, and whether it's replica, like Snap AI or anything along those lines that exist in the chat box experience, those seem to be addressing kind of like loneliness or context in which you can remove shame as a cultural corrective for ideas that are outside of assumed norms, or your common culture or family or wherever. But then you become somewhat isolated in the shared experience of overcoming the challenge of having difficult thoughts or ideas about the world. That's one abstract when I think about the way in which these things could go actually promising and challenging. So one is how can you use conversational intelligence, artificial intelligence, to support humans having conversations, versus how can you use the same type of technologies to remedy loan noise within a single individual? And then what does that do over time?
Speaker A: You mentioned single player. Can you speak more about how move away from that seems like partly limitation of the technology. It's expensive to use it, sure, but what's your thinking on getting beyond that?
Speaker C: I think just from a product development perspective, one of the challenges is finding enough moments or rituals where those conversations can occur. And single player mode is much easier from a distribution perspective. You get someone to download or use messenger or Telegram or any other conversational platform. And if the first friend that they have on the platform is an AI, then that needs to be a good experience. And so the context in which you might invite a friend like Wavelength, is another app that's out now. It's kind of like a chat based version of Reddit ish, kind of strange, not super great, but yeah, it's called wavelength. It's sort of similar, yes. Whereas like Ho is kind of like a browser for chat bots. And again, that's also sort of single player modes. What wavelength does is it allows you or anybody who's in a certain channel to talk to a chat, GPD style kind of presence, and therefore everyone can see the conversation that's happening, and then everyone can sort of talk to the chat bot in the same. So what's the latest going on in Ukraine or something? And presuming the bots trained on something recent could actually give you some information about that that then allows the conversation to unfold. Or you can be like, oh, what is this weird trivia thing that we're getting hung up on. And so then the bot can provide maybe some way unsticking the composition.
Speaker A: Sounds like you have a notion of the role of the bot that's more than just yet another participant. It's a sort of facilitator, explainer, translation of imagination.
Speaker C: What do we want it to do for us? Is it funny? The other night I was at a dinner, and I've read some. This is probably hallucination, but I think I've read some study at some point that there's like silence that happens, that takes over, and everyone kind of pauses. Some people go to the bathroom, like, whatever it is, and then it resumes, and then another 20. It's sort of like this weird frequency modulation point is in this case, we could imagine, like a bot, again, holding space and creating containment of a conversation, and also observing when a certain threshold of participation drops below a certain period and sort of checks in with everyone and says, hey, it seems like we're getting tired. Do we want to eat different calories? Like, these are human needs that need to be attended to. Some people just like, go, go. And so that can also be, I don't know, as a conversational coach, in terms of what we're schooled in, we're not really. I don't want to over generalize, but generally speaking, education as it's been in the industrial era, is much less about creativity and conversation and understanding and empathy. It's changing a little bit, maybe in thoughts, but for the most part, it's like there's going to be a test. So let's train on the information. We'll put the information in your head, and then you report to us that you receive that information and you recall it, at least until the test. But the ability to be dynamic and resilient in conversation and to also be self aware is something that can probably use more support. And so I guess that's how I think about how some of these tools that exist in the conversation runtime could be useful.
Speaker B: Kind of like socializing people, helping them train empathy.
Speaker C: I think a lot of people just kind of lack that sense of self awareness.
Speaker D: It's interesting to mention that we were just at this conference where, like, AI alignment. And then there's a couple of graphs that came out of that was interesting. Like yesterday's morning session, it was on flourishing, and this lady was mentioning, she's a coach, a EQ coach for people in tech.
Speaker E: Very needed, huge market there.
Speaker D: She has a lot of business. And it's not, I don't really need her job, but her point is, she's wondering about what would AI do, right, adding this layer of translation, or even for politicians who might be renting off really good coins but didn't say it in a politically correct way, can that be translated? People texting each other, maybe just talking across each other, where all fights break out? And how do you translate that? So we had a whole discussion about that. I thought it was really interesting to modulate human conversations. And then there's also a threat about. One of the biggest feedback for the whole conference was people's facilitation levels really varied. Some people just rented out, some people were really good facilitators. And one person brought up the really interesting sentence of everything that we don't have a tool for. We hire humans. So everything from back in the day enslaving humans to work on a farm to doing motion labor today, or even facilitating conversations, could that become offloaded to AI?
Speaker B: There's an interesting thing there where. So I've had this idea for a similar concept of a salon bot, which I want for these events, which I think of as just. And I met a guy at the thing over the weekend who's hacking the Google home thing, and just sit it there, and it'll just transcribe, synthesize different perspectives, like real time. Right? And then can parrot back and opinion. What do you think about this? Or whatever, right? It's this real life compare contrast kind of thing. But then also for longer term, can we actually turn this into some cumulative discussion and not just going back over itself, but there's an interesting thing where for a person to stand up, and I had this moment, too, where it's like if you're in the room in a conversation and someone is acting out of line, and you try to pause the conversation to call them out on that, you just now is like political, and you're embarrassed, or it creates some tension. But this AI thing, it's just like a neutral third party, right? It's like you're going to get mad at the robot because you were talking too much. You know what I mean? The robot's like, hey, let's not use, I don't know, splurs or let's not, whatever, right? I'm wondering if would you want such a neutral third party in your.
Speaker F: Well, will it be neutral for this to work, which in principle I love? Trust is important. If you don't trust the referee or the facilitator, then you won't get buy in from people. And achieving credible neutrality, I think, is going to be extremely difficult, because at the same time that these tools are probably powerful enough to actually be very good facilitators, they can say all sorts of things. And so how are you going to constrain what the response space is? And you can already see OpenaI has done a lot of stuff. All of these models, they put in some kind of training to steer away from what we right now currently think is stuff that the bot shouldn't respond to or shouldn't really engage with. And people are always trying to jailbreak it out of that. But I think to a lot of conversations, especially the interesting ones, you're probably going to need to go into those places that are socially sensitive and navigate deftly around there. And so the facilitator needs to be able to wade into topics where humans get testy, but also somehow intermediate that in a fair way that allows people to be heard. And I think technically, yes, of course it can be done, but again, this is for humans, and humans are like the thing you're trying to solve for here. So how can you convince a group of humans that this is truly a neutral, non biased entity? Referring the conversation, I think along those lines.
Speaker G: I was just thinking, you're talking about how to improve conversational ability, how to improve facilitation. I think all that is great, except I realize the reason we have conversation with humans is still, humans are interesting, right? Humans aren't so calculating with every word, right? So I think there's an ideal way to facilitate something, but then there's also like, maybe you inject your own personality into it. You get really passionate about a particular topic, whereas maybe right now I think it's still like when I talk to GPT, it's more or less, you kind of know its personality, right? You know, this is a really reliable.
Speaker B: Yeah, it's very bland, right?
Speaker G: Yes, it's pretty bland. I mean, if you use bard, it's even more bland. At least GPT is a little bit more verbose, it tries to talk a little bit more, but still, like, it says the right things, right? It qualifies everything and it's very thoughtful and it's great. And it's great for a lot of, like, if you want to ask it questions where you don't want emotion and you want it to be super efficient and you want it to understand what you're asking for. But sometimes we talk to friends just so that they say crap that you know is bullshit and then you call them out on it, right? Isn't that part of what's fun to talk to somebody that isn't. So I guess what I'm saying is there's a time and place, maybe, for moderating, I don't know, a certain type of discussion, have AI do it because you want these rules, right?
Speaker B: Right.
Speaker G: Like, I don't know, maybe judging a debate, you want a neutral judge to understand and score. But then there are other things where, as you were saying, you want people to wade into the more controversial topics. Because I think eventually, if we're all trained by this GPT, we'll all end up speaking like GPT.
Speaker B: Yeah, well, I think that would be a really important perspective. I'd like us to consider some. Yeah.
Speaker A: You'Re talking about refereeing and moderating and facilitating. We have already thousands of years old paradigms for this, and maybe a good approach might be to take what already works well, a referee in a game, a judge wearing the rope, give it that role, and people will automatically act.
Speaker H: Yes.
Speaker A: And behave nicely.
Speaker C: Right.
Speaker A: Or something.
Speaker C: Yeah.
Speaker H: I'm curious whether you can, like. It's a technical problem that you can add randomness depending on the topics, right?
Speaker G: Yeah, I think you do. And again, correct me, the more technical people, there's something called a temperature, and my understanding is that if you ask GPT the same question repeatedly, it will give you different answers because its starting point is different, so it's probabilistic. So if you turn the randomness up or down, however you think about it, it ends up becoming a bit more creative. I think that's my understanding, but I'm not sure if that's enough.
Speaker C: The point of it's also about having background and experiencE, which is what leads to you to have credibility. When you introduce randomness, you can be very random, but you actually have a real weird life and it actually is interesting, as opposed to scouting off, like, oh, making shit up like a habitual liar or something feels different. I mean, you might have the same experience over an hour, but then over time the credibility is lost.
Speaker D: Yeah. That brings back to the fact that comes back to the same with AI doesn't have a body, so it doesn't have actualistic experience to go by. So the best it can be is to be a pressure liar.
Speaker C: The memory is also like. It'll be interesting to see what some of the characters that come out of the MCU, the albums are where there is a backstory and there were things that happened, and then you can talk to it from that perspective. There's all sorts of different techniques now for talking to PDFs and YouTube. Videos and things like that. And so when you apply that to characters that actually have backstory people all the way back and they have things that happen, if there's a logic of their emotional development, then they can perhaps set the context of a certain time of their life and then report back from that context window and lose memory in a similar way that we do.
Speaker D: That'll be so helpful for ifs therapy. Like what is your twelve year old exactly?
Speaker B: Talk to your super ego or your it or something.
Speaker C: Are you familiar with IFS?
Speaker B: Not that much.
Speaker C: So internal family systems is understanding how and having sort of a framework for understanding how we are not modeled essentially like we know the super ego. That's just binary. Whereas ifs you may have many parts of yourself that kind of are almost like shadow shells that were created over your whole life with the smallest of traumas, especially starting from a very young age, because you have no concept of what is terrible. Like your mom might have just forgotten the aisle at the grocery store and something super traumatic or something. And so you end up producing in response to that trauma, what was called the protector. And the protector sort of stands in front of that hurt or wounded part. And so when you become an adult, you end up in a relationship, let's say. And that little wounded part sort of gets angry at your partner because they left in the grocery store. And you have no idea why you're so upset about it and why you're angry, why you're throwing a tantrum. And it's because that little part never got to heal. And so IfS is all about revisiting those parts of yourself, talking to those protectors, asking those protectors essentially, to step aside to then reparent the part of you that was wounded so that then that part can come back into your presence for yourself and you can move on from that. And so this idea of being able to shift your context back to those moments, which is a lot of what some therapy is about, allows you to then have a conversation that allows it to unfold in your current understanding of the world.
Speaker F: You.
Speaker C: Have theory of mind. And so knowing that, but I do.
Speaker A: I know that now.
Speaker C: And you are actually me. And so therefore, that part.
Speaker D: Yeah. Or give them an update, like now you are like 30 something years old now, not twelve.
Speaker C: Updating the model.
Speaker D: Yeah. That protective response will be effective then. Stuff like that.
Speaker B: I'm curious if people here would be. If there's, and not asking you to say these things out loud, but are there things you would be more comfortable talking to? Like a chat bot versus a human therapist. Just because a human therapist has, like, it's embarrassing or it's judgmental in some way?
Speaker C: Yeah.
Speaker F: If I had some guarantee of privacy, right, then I would probably feel more comfortable saying whatever comes to mind. But if I know that some tech dude somewhere is holding the keys history, then I'm probably not going to talk about my sad little lost in the aisle self.
Speaker B: Right?
Speaker F: A lot of that stuff, like a lot of the most interesting stuff, probably is very sensitive. And so I think this is a pretty solvable technology problem. But the question is, the tools that are interesting enough to do that and powerful enough, could they be created under a model that would allow somebody to keep their data private? Or like we have now with Web 2.0, do you have to hand over all of that data to be used in whatever training algorithms? In which case, then I don't know. Personally, I probably wouldn't be as comfortable.
Speaker A: Tell us even the anonymized version of that.
Speaker F: Maybe. But how anonymized is it? Can you guarantee me that all of these things are happening the way you say they are?
Speaker A: Just imagine it was all solid to his question.
Speaker C: Would you like.
Speaker F: Oh, yeah, for sure.
Speaker B: Let's say it's local.
Speaker F: Only I know it's trained on data that stays local to me, and all of our conversations stay local. And let's assume it's also effective because it doesn't have access to all of this other training data. Yeah, of course. Because what can go wrong? I'm just talking to digital me and he'll be fine for sure. I don't know. But I assume it would actually be easier than talking to a therapist who, even though culturally we kind of trust that. That whatever happens in therapy stays there, they are still a person, and they are going to say, like, oh, man, I had this crazy conversation today.
Speaker B: One thing therapists often say is that I have a legal obligation to act on information you give me if it suggests you're at risk of hurting someone or yourself. Right. And so now it's a hypothetical scenario. Imagine a psychopath who's aware they're a psychopath and has this violent urges and all this kind of stuff. How could they ever talk to a therapist? They would get reported, right? There's no safe space for them to talk whether. And work through their inner dialogue and sort of these thoughts and like this. Yeah.
Speaker A: Even something less dire. I wanted to know something about machine learning that I didn't know, and I was embarrassed because I should know it by now.
Speaker G: Chat GBT.
Speaker A: I still don't get it. Explain it like a five over and over.
Speaker C: And I think, oh, I got it.
Speaker A: So, well it's like a blue car.
Speaker D: And a red car.
Speaker A: And I go anyway, then this sneaking suspicion comes over me, like what if it was wrong and I have no way to verify anyway, but the trust.
Speaker C: Is there too, just like, oh, I'm.
Speaker A: Not going to judge that thing. I can go the full distance with my ignorance.
Speaker B: And on the flip side, you could even do this kind of adversarial training where it's like most people don't encounter psychopaths in their life or manipulative people or pathological liars. Like that's a rare occurrence and people can get really messed up when they do. And so imagine we intentionally train a chat bot that is an evil character. And this is like, what's it like to be an abusive relationship simulator? I mean, is it terrible, right? It's terrible.
Speaker C: Yes, exactly.
Speaker B: This interrogation training.
Speaker D: Exactly.
Speaker G: So in that case it's like the chatting with a girlfriend. Purposely create a girlfriend. That's psycho, right? Try to brace yourself and learn from.
Speaker B: Yeah, and that's part of this socializing people thread too, which is like people who haven't had the chance for relationships in their early periods of life, like high school or adolescence or in their twenty s and stuff like that. And then now they don't maybe have as strong understanding of what are healthy boundaries and what's fair and reasonable and are much more able to get taken advantage of and abused and that kind of thing too, right? So it's like a way of training. Like even if, say, I've been living in only all boys schools and I haven't had a chance to date, but I know what healthy relationships look like, even if I had not a good family home or something.
Speaker D: Wow.
Speaker A: I mean, that sort of happened in the pandemic. There was this generation of kids who were in kindergarten, first grade and missed all the socialization and now they're in third grade and I'm hearing from teachers, I'm sure you heard about it too, they're like wild animals. And you could have predicted with the Zoom school that's what's going to happen. And I wonder how many other little seeds there are that we're planting where we don't know if this is going to be an oak tree or a weed. Let's just plant them and see what happens.
Speaker D: If I have kids, I don't want my kids to use AI to form relationships because they'll be using and be like they don't judge me. So I feel like they might get used to that. But to form a relationship with people, you kind of have them be vulnerable. You have to share all these things. But what if they get scared of sharing that because they'll be hurt more because they're not used to being judged. So I don't want that for my kids. They're visiting town. She teaches in college with 18 to 21 year olds, perpetually, and she keeps seeing different cohorts. And she talks about how all professors get together and talk about how less and less risk taking they have become over the years. And because, yes, this is not politically correct, but there's a lot of everything from peace room to excessive support have gotten to the point where people don't take social risks to make friends or apply jobs anymore. And they're super concerned that these kids are going to graduate and don't know how to deal with the world.
Speaker B: Have you seen these charts that are just like, number of teenagers that have gone on a date or had an alcoholic? It's just plummeting. Like, no one's going outside and doing stuff anymore.
Speaker D: Quoted yesterday, Japan's case is already, like, far gone, right? And then America, apparently, like, male population by 30 who's never had a sexual relationship with 133 percent.
Speaker B: Is the solution to this AI girlfriend. Now, the original topic is that where we're coming?
Speaker F: I actually have a very strong opinion about this, and I want to say it, and I'm looking for people to disagree and change my. This is not, like, a crazy hot take. I think AI girlfriends absolutely cannot work at all, because humans are embodied creatures, and physicality is important and way beyond just, like, sexual stuff. Embodied beings being in a physical space together and all of the things that go along with that, I think are super important. And so technology has kind of, like you mentioned earlier with Netflix, Technology has sort of diverted from human human interaction, and in some cases, with your tomagotchi or whatever, it tries to replace it by giving you something to interact with. But I think socially, we could take a snapshot of our cultural moment and say they can work in the sense that people will spend time on it, but ultimately, it is not fulfilling some critical human needs, which is why we have all of this nihilistic detachment and just rage and pain and all of this sort of thing. So I think so long as any of our digital tools are not embodied, they can never be an actual substitute. Even if people do get lured in in some sense, because it is like, an interesting and stimulating interaction, it will always be missing some very critical domain and leave people, I would say, actually, even more hurt and unfulfilled in even more subtle but extremely damaging ways.
Speaker B: Two questions. Unless someone else has a comment, they want to jump in.
Speaker D: Yeah, I kind of want to challenge.
Speaker C: On that a little bit.
Speaker I: Just like in today, not in the future. In today, there are lots of people who are in gaming communities, for example, who will meet somebody online and be in a relationship with them, never having seen them for years and years, and in some cases get married, for example, in VR games, this has actually happened. So I think it does exist already. I don't know, maybe it's hard to compare how fulfilled they are versus a couple that is physical and always together. But people report feeling fulfilled and feeling like that relationship is enough for them. So that's not necessarily with an AI. But there are examples today, I think, where people are fulfilled in a purely non physical relationship.
Speaker E: I think it's possible that an AI relationship will be much more fulfilling and nourishing than a real one. If the AI is very empathetic, it knows you really well. It knows exactly how to make you feel good and heard. I think it could be superhuman.
Speaker B: Would there be a risk there of this kind of coddling of the youth? And because the AI, its entire worldview is around you. Right. And so you'll never learn to compromise. You'll never learn to make space for other people's experience of the world and consider their perspective. You'll become a narcissist by accident.
Speaker E: I'm not sure. I think it's a function of what you're optimizing for. You can obviously build AI in such a way that it will put boundaries and it will challenge you. And maybe that's more fulfilling. Maybe that will sell more than AI. That is just a pushover. Who knows? I think it's possible.
Speaker G: What I think about this issue is that I just feel in my exposure to different types of people, everybody runs the spectrum, right? So there's some people who really need a lot of relational, emotional, physical. And then there's some people, their needs on this is bowed down a bit. There are some people who find a material life very empty. Maybe people like us, we love to, on a Sunday to have these kinds of discussions, right? But then there are some people who honestly are just. They prefer a decent job. They got their nice Sunday brunch, Call of Duty.
Speaker C: Yeah.
Speaker G: Or it's like something comfortable. So everyone's different. And so I guess what I'm saying is that if we're trying to prevent people, prevent society from going a certain direction, people will just find another way. Some people find comfort in video games, right? A lot of people do, but some people don't, right? So those are people who choose to not be extract themselves from that ecosystem, but Epidemio games there for a reason. And things do develop out of it, like creativity does develop out of it. Web three. These concepts of the metaverse develops out of there. Communities do get formed, but it's just not the kind of communities that maybe people like you and I identify with because we like to hang out on a Sunday in person to talk about things. So I'm just saying, like, instead of trying to regulate AI, if people find it useful and there's enough people, to me it's kind of a little bit off to have an AI girlfriend, but some people kind of tooth their horn.
Speaker B: And is the alternative just them being.
Speaker G: Lonely or going out and doing other worse things?
Speaker H: No, I was just going to add, like, AI girlfriend can be a start, and then you can learn with her to move on to the real.
Speaker G: Oh, it's time to move on to a real thing.
Speaker B: When your AI girlfriend dumps you, so.
Speaker G: Brutal, it's hard to recover from.
Speaker C: One.
Speaker H: Way I look at it, and actually a topic for a discussion, that technology is like supplements or like drugs in a way. You can use them or abuse them, right? Ideally, product managers and people who create technology, they want to be as addictive as possible. And that's where it comes to any of these products. And special AI is super addictive. And I feel like the role of knowing yourself and your boundaries and self awareness of what works for you and what doesn't is super important now because everything becomes even more addictive in the relationship. The technology can play this escapism role where you can, instead of dealing with real problems, you kind of escape to technology. The same with AI kind of girlfriends. You can find the easier way. And maybe it's fine for you, you don't need to date like a real human. But it's a question how well you know yourself if you accept that it works for you, whether you want to go under that path. Because supplements are this, well, they can give you superpowers, but they can also harm you. So I think being self aware is now becoming super important.
Speaker B: Kind of like this. Humans, we're wired to want fat, salt and sugar, right?
Speaker D: Yes.
Speaker B: And if you just let that rip, you get obese to the epidemics.
Speaker H: And if you look at the evolution of technology, television, radio, and all these technologies they play the addiction role in their time. Internet. Now and then AI will be even more addictive. With VR and AR, it's going to be even more immersive. The question is, where do you put boundaries? Like, what do you enjoy and what makes you happy? And you can play the question, how do we develop this self awareness of society where we can put boundaries and we kind of know how to handle that rather than giving the power? So, like, all right, I'm like, just the silly human. Handle me.
Speaker D: I do want to say it was interesting backing a couple of decades ago. It's about big food, fast food, fighting over stomach share. Right now, it's like, attention share. Great. And then they invested heavily in research. Like, anyone that's not American is like, whoa, this is crazy. What do you mean? Like, sugar? Fat is bad sugar. It doesn't make any sense, right? But anyway, now we're in this attention situation, and deep into it, I feel like there's one argument for people need to take more ownership of awareness and things. But it's also like, our brains are really ancient. We're wired to want these things. And it's not quite fair for humans to say it's all on us to fight our brains and our wirings when there's machines built to take advantage of the shortcuts in our brains. I don't know. That's more of a system perspective. I'm like, okay, how do we disassemble that rather than feeling guilty that we can't stop scrolling or something?
Speaker E: And there is precedent. Our legal system and government tightly regulates things that are way too fun, like gambling, heroin. It's just too fun. We can't resist it. I don't know if we fail. I mean, people used to use a lot of opium. Almost everyone was on opium, and that's not a thing anymore. There are some people who still use it. They're on the street, but I don't think any of us. I mean, if this conversation happened 150 years ago, we would be smoking OPM or drink cocaine on the table.
Speaker B: Are people here familiar with Plato's Republic? In Plato's Republic, he tries to design a society that removes the chance to engage in vice, like an engineered society. And I think it's know, one of the things was, like, banning poetry, okay? Because poetry riles people up too much, which is, like, kind of insane, right? This is like, okay, all right. And you're like, why don't we have legal heroin? I mean, it's a kind of poetry for the soul, maybe, but no, I'm just kidding. The big criticism to that worldview is that virtue is a muscle you have to train in response to temptation, right? And so if we think we can control the world in a way to prevent people from having access to these fat, salt, sugar of social connections, then they don't actually have any built up resistance to situations that are tempting, right? It's like they don't have that discipline or that willpower.
Speaker G: I know what you're talking about. There was a book about how fat, sugar, and salt it creates, in a way, food is genetically engineered, right? So should we be banning genetically engineered, that kind of engineering of food to taste good? I mean, I'm sure you guys have read studies on this, like, cereal, for example, right? It costs, like, ten cents to make cereal, but it costs like, $4 to do the marketing on it. And that's why it costs whatever it costs at whole foods, because it's genetically engineered to taste a certain way, right? So it is kind of short circuiting our wires and our taste buds. But then if we start regulating that, there's so much stuff. We should just all be eating broccoli. We should all be eating boiled broccoli, right? Because sometimes we do want that double chocolate fudge ice cream, right? And yes, in moderation, it's actually good for you. On some levels, you feel better. It facilitates conversation, but then in excessive amounts, it's bad for you. So I'm just saying, where do we draw the line in terms of regulating this wiring, right? And part of I think, what makes society interesting is our flaws. So I'm going to kind of move into my observations. I've lived in Asia for a good number of years, so I'm ethnically Chinese, and so I speak Mandarin, I read and write. So when I'm in China, I definitely sense that there is so much control over our thoughts, okay? And so that's why it used to be like, oh, you know what, America? We're too free. Everybody has their own thoughts, and that's the typical Chinese response to American culture, right? They see the freedom hEre, and they're like, that's why we have a bunch of weirdos out there. That's why we have. And they'll point to certain segments of the population that is traumatized and be like, oh, it's too much freedom. But then when you're in China, and I think to your point, because everyone's thoughts are pretty regular, you just never think about things that the government deems as not worthy to think about when you let them go free to think about whatever, actually, the consequences are worse, right? Because they've never been tested and tempted. So now all of a sudden, you do have that temptation. Go, whoa. I do think that. I'm not sure if I jury's out on this. Like, I'm not sure what is the right balance. But I also. I'm just hesitant to say that we want to create a chat bot that only encourages proper conversation. We want to create a society that prevents bad vice or the drugs. Because in China, you have a culture nowadays much more than, let's say, ten years ago, where it's just group thinking for a while. Everyone thinks this is the right way to do this movie is the best movie ever because it teaches these principles and about parental relations. And then all of a sudden, that person becomes a role model because that.
Speaker C: Person embodies certain spirits.
Speaker G: But then society shifts, and then all of a sudden it becomes, oh, this is a really that person. Oh, you know, that idea, that company, Alibaba, used to be such a great company, and now it's evil, right? Tencent used to be a great company, but now it's evil because they have gaining, and now we need to limit it. And I'm just like, wow. I mean, we end up not knowing where to think. So anyways, just saying that corporate slow.
Speaker B: Totally.
Speaker F: I think this is like, you guys have been pointing at this very fundamental, perhaps to human existence idea, which is like, humans are fallible, right? And we'll always mess up. And the common approach is to try to treat all these symptoms, like, well, when people do this thing, like, bad stuff happens, so we get rid of that thing. And obviously that doesn't work because there's other things that people can do that are also bad, or they'll come up with a new bad thing to do. And so it's like the actual, this meta question is kind of like this discipline, right? To understand the human, understand all of the flaws and embrace that until we get to transhumanism, this is what we're working with, and that's fine. Humans are great. You have some of these vulnerabilities. Make peace with that. And I think in our cultural moment, currently in the US and a lot of the west, we have taken a very negative view of discipline in general, because from my perspective, a lot of the apparatus and stuff had felt like very stifling and controlling. And so in the cultural move, to throw off these shackles, we kind of associated discipline as such, as part of that, because we'rebelling against this, we're pushing back against these things that were stifling and oppressive in some way. And it's not to say that any of that was unfair. When you get rid of the need to have some kind of discipline for whatever that means, then you lose something important and you end up without this kind of. This upper level understanding that, yes, I'm a human, I have these vulnerabilities, but I'm going to try and live according to this, whatever principle doesn't really matter, but train that muscle of virtue or whatever, go up against those vices. The alternative is you have to get rid of all the vices. And like, that's going to be tough.
Speaker D: Like this duality that we created between vice and virtue. Or even in modern Western terms, like mental health, then what's the opposite of that stillness, right? DSM Five was created by a bunch of men sitting in a room. A lot of it's not foundation.
Speaker F: Found it on like, here's five things. If you have three of them, exactly.
Speaker D: What the diagnostic Bible for mental health. And it's created a lot of emotions that people have. I don't meet these standards. I'm not healthy. It's super pathologizing, right? When maybe what you're having, instead of labeling dEpression, anxiety, all things in Eastern philosophy, you're having spiritual awakening, welcome to the world, right? Indians are like, yes, you're 30 now. You realize life is not perfect. You're mortal and all these things. And then you go through rite of passage and you emerge the other side of new person. We don't have the equivalent of that. We create a whole industry to medicate people to mental health acts. All these things just become this whole industry that is predicated on this pathologizing view of our different states. To your point, they might just be different states of your existence. And we're vulnerable people and flawed. And if we don't accept that, then more things will become problems. Right? To add to that point, I guess.
Speaker C: To add to this, I think that there are two thoughts that are happening. There's usually like eight or nine, but I'll try it anyway. One is just like the fruits of industrialization. And industrialism is what allows for the abundance in calories that then have a hard time adopting or using the metaphor of wiring because there are no wires in our brains. There is sort of the response that grew up over generations and millennia to find and seek certain resources that would allow us to persist in times where we didn't have a lot of calories. And then eventually we figured out by growing a brain over many millennia, that if we organized plants in a certain way and developed agriculture, then we wouldn't feel the pain of starvation. And so then we could persist ourselves. And then we create systems to propagate to now. And sort of this reinforcing mechanism got us where we are now, where eventually we invented machines to do these things for us to then give us the abundance of calories, in which case, now we're in a world of manipulating people into desiring one form of calorie or another, because we have so many of them. And so whether it's cereal that's designed to create a certain type of experience, that's a luxury that actually means that we've succeeded. So, as we're talking about this, you talked about the culture of medication, where someone has an acute experience and they would like it to go away. We've developed a certain set of ingestibles or injectables or other types of things that we can put inside of ourselves to change the functioning of our bodies for some period of time, sometimes for a long period, sometimes for short. But what will be interesting, I think, in the context of conversation, is to think about things like the long term effects, like whether we think on a 30 year generational cycle or three generations, like 100 years. What the pros con benefits, detriments of the abundance of these types of tools and technologies will be for human connection and relating and self and mutual understanding, because that's ultimately going to happen. So this question about whether there's going to be AI boyfriend girlfriends or just AI friends that have any number of dials or intimacy levels, I think it's a fate of conflict. And any kid growing up today who's five is going to have any number of AI friends. And some of those relationships may become romantic and there may be a desire to meet with them, because that's what you're going to do as an animal. And whether we choose to assert chain functions on those feelings, I think it doesn't automatic. And so the same way in which we've kind of, as you were saying, rebelled against whether it's a type of conformity or needing to do certain things, it sort of makes sense, as abundance grew, that we would fight back and would want more freedom because we don't need to be toiling the fields anymore because they're toiling themselves. So as we have this extra abundance and time, we don't need discipline in the same way that we used to. Because if we didn't get up at 05:00 a.m. And we have enough food by the time winter comes around. And so therefore we have so many choices now available to us. And so if the purpose from this relationship lens is to experience all the subtlety and variation and nuance of all the types of relationships that could exist, whether human or artificial, then that creates a different design opportunity to then create the opportunities for those types of experiences. And then you could have a three year period where you have a relationship with an artificial intelligence that's highly romantic, and you have a family and you have four kids and a dog and whatever else. And then the simulation ends and you move on to another type of relationship. Because as humans, you only have one life to live that you can imagine actually having many different lives by virtue of not necessarily becoming emotionally entangled with another human that's depending on you for livelihood or for anything else. So that's even more generous concept, but.
Speaker B: Pose a question or, sorry, you go.
Speaker G: Ahead if you want. Can you have multiple relationship? Did you have to wait for three years?
Speaker B: This is where I was going. The question here is, how would you feel about someone else having a relationship with an AI who was an embodiment of you and your personality?
Speaker C: Let me answer your question in a totally different way. As a person who's been non monogamous, I've had to deal with these types of questions and all the various things that come with that, whether it's jealousy, or whether it's getting my mind around the ideas of my partner having intimacy with other people, or having intimacy with many people, or having multiple. I mean, it is crazy making, in a way, because you're like, this partner wants these things, this person likes these things. I suppose it's a roundabout way of getting to the answer to your question, which is, I don't know if it's about sovereignty over my me ness and the phenomenology of me, and whether other people could rent or have the experience of me in a relationship that I'm not actually in. And that gets very metaphysical. So I don't have a good answer for that. But what I will say is that non monogamy taught me a lot of things about how to sort of think about relationships from a more rational perspective. And then to imagine when people that come up with a certain idea of whether it's a heteronormative or monogamous lifestyle as being the answer to the question of what type of relationship should you pursue? And that no longer being the only answer. That seems to sort of shed light on how these types of AI relationships will be pursued whether in the light within a relationship or in the darkness. And I think it's more likely that in the short term, in our generation, many people will pursue them in the darkness and not have affairs with these AIs, because who's going to know? There's no babies that can be produced.
Speaker D: There's that scene from her where he finds out. Right. He's like, how many?
Speaker C: I saw that when I was anonymous and I saw a very different experience.
Speaker D: Can you describe the scene without ruining the movie? Yeah.
Speaker E: The scene was, you can ruin the.
Speaker D: Real life when the OS continued to develop. Samantha. And at one point he's like, how many relationships are you in besides me? She's like 670 something. Millions. Yeah. And he just like falls down the stairs.
Speaker G: Right.
Speaker D: Because he couldn't comprehend he was the only one. Yeah.
Speaker B: So where I was going with that question, though, was in a little bit of a weirder tangent, which we can also shell. This has been very grounded in our day to day lives, which I like. But AI as matchmaking.
Speaker C: Sure.
Speaker B: Right. And matchmaking is usually socially facilitated between. I have an understanding. I have a mental model of this person. I have a mental model of this person. I think these mental models are compatible in some way. And how comprehensive of a mental model can a person contain about someone versus some 135,000,000,000 parameter large language model. And if such a model was trained on your personality, your tastes and your likes and so forth, and could embody you quite accurately and someone else could have a similar model. And these things can communicate a million times faster than people. Right.
Speaker F: We're back to arranged marriages, optimized marriages. We just found your.
Speaker C: For sure.
Speaker D: It's going to be like your digital twin talking to each other.
Speaker B: That's right. There was homework for the session. Did anyone do it? It was to listen to the song I posted. I'll post it later. It's fine. It's about a love bot. Yeah. And the optimal solution is to make it.
Speaker G: You're not saying use the AI as a matchmaker. You're just saying the digital equivalents would kind of date in like a speed dating thing. So my digital equivalent would date, I don't know, millions of thousands.
Speaker C: Millions.
Speaker B: That's right.
Speaker G: And ultimately be like, oh, well, I found. I found the ideal soulmate right here. And that person agrees, wants to be soulmates with you. Is that what it is?
Speaker B: And your jitter twins have like a ten year relationship and they give you a summary at the end. And I have now millions of years worth of human lives being lived on my behalf, finding the optimal partner for myself.
Speaker D: Well, that ruined all the surprise for the entire lifetime.
Speaker G: How does it have ten years already?
Speaker B: Because it can communicate like Megahertz, the.
Speaker C: Speed of GPU.
Speaker B: Because these are AIS communicating, and the conversation is in milliseconds.
Speaker G: So it's not even just speed dating, it's actually literally living, let's say, the next ten years of your life. Is that what you're saying?
Speaker F: The next ten would you need to simulate it. Like, if you have a good enough model, then you would be able to just do, like, an analysis on how well they fit.
Speaker G: It's like playing chess, but you can think like, 100 moves ahead, you know?
Speaker D: Exactly.
Speaker G: Okay, we're going to go date, and we're going to do this first day, and then, boom, ten years later, success.
Speaker B: There we go.
Speaker A: Live happily ever after. Or they say, actually, that's true.
Speaker D: This is the first assumption that people don't change.
Speaker G: Yeah, that's true.
Speaker D: But people grow, people change each other.
Speaker G: It's a probabilistic, right, 70% chance it's going to.
Speaker E: No, you don't necessarily have fuel constant.
Speaker B: But that's true of any relationship. And people change and the world changes and all that.
Speaker D: So therefore you can't simulate that holding entire world constant, just.
Speaker G: But it gives you a better chance. So you'll be like, running with this. It's like, let's say. Let's say I have ten whatever options, right? And they'll be like, okay, this girl, 70% chance ten years from now, you'll be together. Okay, this girl, 65% chance this girl.
Speaker F: Probably 4% expected value of this.
Speaker D: Yeah, expected value not to be together forever. Right, true.
Speaker G: So I can optimize for that. So then you'll be like, okay, in five years, 90% chances they'll be together in 30 years. Actually, the 4% girl, you'll be. I don't know.
Speaker C: Not to reduce it so much, but the question is the fitness function. What is the purpose of human romantic relationship and exclusivity? If it's going to have exclusivity, you could decide to raise offspring, which takes a certain amount of time. And during that time, you do want to have a partner to be able to share those duties and burdens. During that time, you may have a partner that's really, like a great parent that sucks in bed or just is not that interesting. And so you could bring in, whether it's a third or an AI, for both of you to get the things that you need so that you're collaborating on not to turn it into startup land, but it is kind of like doing a startup.
Speaker D: It's running a small enterprise.
Speaker C: It really is. And so this question of, like, are we going to be together in X number of years?
Speaker B: What's the percentage?
Speaker C: Doesn't seem like the right way to think about it.
Speaker B: Sure.
Speaker C: Will this relationship continue to both meet my needs and my partner's needs? And how do we continue to encourage each other to grow?
Speaker D: There's also a spiritual component of, like, human connections are meant to have certain functions, right? We have constructive society where it's binary, but there's so much of, like, the connection, its course. Let it run its course. We will grow into humans that we're supposed to be learning to become in this lifetime. There's that theory too, in which case we don't have the agency to actually say how long this connection lasts.
Speaker C: Also true.
Speaker D: Yeah. Interesting.
Speaker I: Even if it didn't have like, oh, in ten years, 4% likelihood.
Speaker D: I think it'd be interesting even if.
Speaker I: It could identify what are the things that I really care about in a relationship and what are the things you really care about in a relationship and then match, make that in the current state, it doesn't have to be like this whole future.
Speaker D: But there's another assumption we're making. Modern dating that I find troublesome is like, we're thinking about what we can take, what our needs can be met from this relationship, rather than, I think, for a long time. Right. We talked to our parents generation, whatnot. It's about what you get into a container. That's why modern dating can be weird. It's like you show up, you're like, okay, do you need my checklist? Do I have a checklist? No, it's a negotiation of, like, am I shopping for something?
Speaker B: So there's this thing I was trying to get at, which is just compatibility or perhaps chemistry, which I think is something that two people cannot have chemistry with each other and have huge chemistry with someone else. And that's the kind of the fit function I was going for. Not to have relationships on your behalf, but I'm curious on people's gut reaction. So very negative on that. But like, other people's gut reaction on, like, would you delegate this compatibility thing? Would you trust their recommendations more than, say, mutual friend?
Speaker C: There's an app that just launched teaser AI people that made disco or local camera app or something, but you started by having a conversation with a bot and gradually learned more about you, and I believe it. You're either dating a bot or it's connecting to other people. I forget. It sort of like fills the gap. I don't know if you're familiar with replica, but replica was around sort of in the era when I was conversational AI, and recently they turned off all the sexy photos or whatever the AI was sending. And to the point, I think, that someone made about getting broken up with by an AI, this happened to a lot of people. Very problematic for many of them. Of course, it's a lot of advice stories, so take it as you will. But the point is those things are happening, so there will be more and more advanced ways. I mean, Okcuber sort of started this by using lots of large data modeling and machine learning to put people together based on self assessments. But to your point, as people change and evolve, one of the problems with dating apps is that data gets stale. So you kind of need to be in touch with whether it's a data coach or a life coach or sort of AI that Google learns through your search queries. But a conversational check in quarterly could actually help you find the people.
Speaker B: I did want to ask this side of the room, because we've had lots of conversation on one side of the room, but how would your gut reaction feel to this matchmaking app that you just. Apparently we can sign up for it. You want to sign up for it?
Speaker C: I mean, any takers?
Speaker A: I was just thinking about an article soon AI. Let's not meet online. Let's just do a perfunctory check and you have to go meet in person. But to your point about the question, would I delegate? Yeah, I mean, I think I would, but to the extent I delegate, the automatic braking and when I step on the pedal there, I know it's going to work. Have to get to a point where.
Speaker C: It was under the hood, right?
Speaker B: Yeah.
Speaker H: I'd give it a try. But the challenge here is maybe like a technical question is like, we're all dynamic species, so what we care about now changes. What are we going to care about in five years? So the model can predict our assessment, can accurately assess us now, but how accurately can assess us in five years and match it with a person who will move in the same speed? I think this is the hardest challenge. Like, what I cared five years ago is different, and I moved so fast, my girlfriend didn't, so we had to.
Speaker A: Break up kind of.
Speaker H: Our priorities change and so on and so forth. This is the biggest one because when you match, you get even, like, the chemistry. But then in six months the chemistry disappears for various reasons. So, yeah, I think it can become better in matching, but then still the journey isn't used.
Speaker B: It's a snapshot, right? It's not the whole journey. Yeah, totally. Yeah.
Speaker F: I think it could be useful, for sure, because it's like, human search scale is not that good. It's hard to meet a ton of people, and I think it probably could improve the chance of finding a match that is more likely to succeed. But your points were very interesting on bringing in other elements to fulfill a relationship. And some part of that feels right. But then it also felt like it might be speaking to something we were talking about earlier, which is like, and I'll hook one more point into this afterwards, but when you have some kind.
Speaker B: Of.
Speaker F: Discontinuity in the relationship, I think this is a value judgment I'm placing on it, but I think it's often good that you and your partner are forced to kind of coevolve in this way, and it forces you to take a look at yourself and at the relationship and maybe improve. And I certainly feel like in my own relationships I've had a lot of tensions where I realized, like, wow, I really suck at this. And rather than branching out to an AI who would put up with my bullshit, I should probably just be better as a person. And so I do worry a little bit that if it is so easy to just fill in the gaps, then again, humans never have to fill in their own gaps. And this is where it hooks into the second part, which is in a lot of this discussion here, which is totally fair, we end up fixating a lot on the individual and what you need as a person. But I am increasingly interested, actually. Now I'm obsessed with governance and organizations and stuff, and so long as humans are social creatures, there must be some significant attention paid to the whole. And I worry that if we allow humans to indulge all of these flaws just because we have the tools to do that, it could work individual by individual. But then you lose something at the collective level. And so long as we need to get shit done at the collective level, I think we also need to keep in mind how these individual decisions will aggregate into something that ends up being culturally important.
Speaker C: Can I respond to that? Just two examples. In one, I think that the bigger picture is an important thing to keep in mind, because if people are able to have healthier interpersonal relationships, especially at the core of the kind of like, nucleus of themselves and people that are closest around them, and then to repair when there's wounding or trauma or any of those things, then when they do go out to the rest of the world, then they're more fit for resilience in interactions where there's even less existing correlation or humiliation or relationship. And so it feels like because of some of the fragility and lack of stability within some interpersonal relationships and relationships at home, that when they go into the world, they're actually more fraught and have a harder time in encountering and giving other people benefits of doubt or showing up in good faith because they're coming from a lack array. I'll give you an example, though, just to be clear about the way in which when these AIs could intervene in a relationship, it's not so much as a decoy or as a resource that you return to when there's conflict. Like quite the opposite, it's actually meant to keep you engaged in the container. So maybe two different ways. One is, like I said, you could have a certain set of ideas of things that you want to achieve in your interpersonal relationships, family, rearing, business, I don't know, whatever, and that other people may not provide the full gamut of all the things you're looking for in relationship. That's why we have friends and so on. And so these ais, you could again turn up or turn down the romantic kind of aspect to it. And as long as there's a way to understand where either jealousy or what's called conversion, where you're sort of excited about your friend's experience or your partner's experience with someone else, is factored into the culture, then whether that's an AI or whether it's a person matters less. So I'll give you a concrete example, which is a very surprising example for me, but when I was a secondary in my current partner's marriage, so she was married, they had two kids, and we were seeing each other, there were many moments when they'd been married for 1617 years where they would have just different fights. And those fights were sort of a known dance that they would get into as couples who were together for a very long time and finding a way of just kind of like getting at each other. And so as the third, I found that I had both impassioned for both of their perspectives and was able to hold them together longer to a point where they could see the other side's perspective by creating more of a neutral kind of reflection. So on one hand, I would take one person's complaints in, listen to it, and then I would turn to the other person and translate it for them. They could hear it in a way that wasn't as assaulting, and then take the other person's perspective and then turn it back the other way. Now, you could replace me in theory with a decent AI that could do the same thing. But my point is that it can actually be a way to keep people in relationship longer than simply being an escape.
Speaker D: People to submit their photos, because appearance, I feel like it better.
Speaker B: Do you think so? Yeah, I think. I'm curious if you were raising another point, though, beyond just, I liked what you said there. That was really interesting about the keeping people together longer and acting as like a mediator that's very much involved in the events as they unfold. But maybe you were touching on another thing, which is that this really popular phrase, which is kind of like, good times create weak men and weak men create hard times. Right. Which there is this thing about, I.
Speaker F: Do actually really feel that that is at least somewhat correct. Now, hard times also do tons of damage that we are still dealing with. But I think to me, I see that at some points in history we have had to flex our virtuous muscles where we were called to do things that were not like the path of least resistance and ended up accomplishing feats that we now look back on are like, wow, that was amazing.
Speaker B: Totally.
Speaker F: So, yes, it's easy then to romanticize, like, oh, man, the World War II effort. The country came together to do whatever, and that's very much true. It also did unbelievable damage in apparent and much more subtle ways. So is there a way to ride this line where it's challenging, but you still have the chance of succeeding and growing without just being destroying people's lives and futures and cities and world.
Speaker A: Yeah, it feels like you're right on the cusp of the matter here. The tension between the structures and the individual freedom is something we've grappled with since the beginning. And we're really bad at seeing around the corners, like, think about climate change, right? We were busy giving everyone cars and freedom drive, Sunday drive.
Speaker C: That's the thing.
Speaker A: We didn't predict climate change would be the result. So who knows what we're missing now. So to say, therefore, you're going to have the right guardrails in place. Now, see, I don't know what I'm saying, but other than if you come out from both sides, like, well, there's going to be unanticipated problems, but there's also going to be a need for structure now and freedom on a personal level. It's very easy to get stuck in that.
Speaker B: Totally. So something I'm curious, tying it to the relationships, I'll use like an example from Web Two that everyone likes to talk about, but it's like Web two is this amazing thing about connecting people together. And this super, maybe ironic but dark second Order, third order effect is that you just create echo chambers and democracy falls apart because we no longer agree on the same set of facts as to what's real, because people have enough people of a certain ilk or whatever to live in this self contained social bubble where they have a completely divergent interpretation of events, right? Whereas if you force people to mingle with one another in the town square, so to speak, and is there an analogous risk here with these? If we feel like we're including AIs in our relationships as things that we want to engage with, where again, we start to just Balkanize as a society and people are living wildly divergent experiences, and you no longer have common ground?
Speaker F: Yeah, that's a really interesting point. I think this is a vulnerability inherent to digital technologies of all kinds. This has stressed me out a lot, and I don't have all the answers. But one of the things that seems to contribute is the fact that in these digital spaces, the more time we spend in the digital, the less time we spend in the physical.
Speaker C: Right.
Speaker F: And in the digital, you can get off on abstractions in a way that you can't in the real world. Like when you're building something physical, it either works or it doesn't.
Speaker C: Totally.
Speaker F: And so part of my work with governance that ties into this is the fact that a lot of people have a lot of ideas about what we should be doing on this and that. And we have very little shared understanding of reality. When you're in a digital space, you can say, like, yeah, well, if taxes this and that, or if police or jails or whatever, this and that, it's all meaningless. And you can get away with these discussions a lot more easily because you're in this abstract world where it's all just like fuzzy and you can put little zings together. But when you actually try to touch the structure of government and you see all of the stuff that is either amazingly functional in a way you didn't expect, or just so hilariously outdated and broken that nobody, if they actually knew, would object to changing the thing, then as soon as you sort of consolidate on the version of reality that is actually really there, we wrote down the laws, and there are eleven supervisors, and they must do this. And that to pass a law. But when people are faced with this reality, a lot of the sort of stressful arguments and stuff that are so easy in the digital world just evaporate, because now you have the is, like, you have a shared is. And I'm worried about how easy it is to lose that in digital spaces. It's very hard to capture the full fidelity of the world. So I don't blame us for allowing this to happen. It's very hard. But maybe AI, because it has infinite capacity for attention, can capture all of this nuance and a lot more of the complexity than a human can in a blog post. Right? But you can query a trained model infinitely on a topic. If it has all of the structural documents, like put the constitution into an AI, right, you can get down to the actual text of the document, and it's very easy to do this. This is actually something I'm working on, and I think AI, uniquely, that would.
Speaker D: Bridge the gap between.
Speaker F: Yeah, I think because AI has infinite attention, you can actually just collect all of the complexity into that AI model and then make it very easy for a human, or humans, to query as much of that complexity as they need for their discussion. Whereas when you're just going back and forth with somebody in a thread and you're in the digital world and there's no physical reality to ever make you settle on one particular thing, it's a lot easier to stay abstract there. But if you have some easy digital connection to what the actual reality is, my hope, and I could be wrong, my hope is that you can converge on a shared is. I don't know that this is true.
Speaker D: But come off really weird, but it reminds me of this phrase from undergrad friends. This is why I was never really on Twitter. Twitter is a place for collective. For collective intellectual abstract.
Speaker G: Yeah, no, I mean, I'm on Twitter. Twitter has become, like, my source of news almost, but I get what you mean. I totally identify with that. And so I think over time, my perception of technology overall, whether it's GPT or Twitter, social media, Netflix, I'm just like pro tech. Because I realized that at the end of the day, we're all going to become who we are. We just shouldn't be regulating too much human behavior. Because I feel like at some point, right, maybe 150 years ago, we didn't have Facebook, but we would do other things, like, I don't know, we would be isolating our own echo chamber even without Facebook. So Facebook allows, or social media, or just technology in general, allows us to, like, for example, connect here, right? We all come from different parts of the bay. Through whatever this platform, we're able to get together at Salon. In a way, I would say us here are using technology in a way to connect people a little bit more, right? Whereas maybe some people are using technology to be at home a little bit more, and that's up to them. I don't know, maybe I've become too lackadaisical on this. And to your point, people will discover a relationship that works for them, whether it's monogamous, not monogamous. And so technology enables that. And eventually maybe we'll discover that all this is pretty empty, and then there'll be a resistance against AI girlfriends, right? But until that happens, for us to call, who's going to make that judgment, right?
Speaker H: I feel like to this point of universal, kind of not a belief system, but something I feel like instead of regulating to your point is how do we create inclusive beliefs that actually allow people to expand their horizons, right? This is something that can unite as a society and humanity around bigger horizons. Everything is now uncertain for us and we are playing defensive instead of actually allowing it to happen and creating a bigger umbrella for our beliefs and moving forward.
Speaker A: Who knows?
Speaker H: Maybe like there's some asteroid who's going to hit us and AI is going.
Speaker C: To save us or nothing.
Speaker H: There are things that we know and we don't know. So instead of resisting and really being scared, how do you create something inspiring? And that's your governance thing.
Speaker E: Do we know that voltage of media and web two? Do we know that it has a negative effect on democracy and institutions? Because I think most of the examples of democracies falling and becoming authoritarian are from before Web two was a thing, media was very mainstream.
Speaker B: The words January.
Speaker E: On the other side, there is a bunch of examples of democracy that formed because of Twitter and Facebook. I come from the Middle east, so it's very visible to me.
Speaker B: Were you in the States for January 6?
Speaker C: Yeah.
Speaker E: I mean, nothing happened, right? I mean, they had like this shitty thing where they tried to do something, but very robust to it.
Speaker C: I mean, relative to other countries.
Speaker B: Relative to other countries. Relative to other countries.
Speaker E: Where thousands of people die, there's some idiots going into the Capitol building.
Speaker F: Okay, do we have to pick one?
Speaker B: Are you familiar with this 200 billion dollar lawsuit? Myanmar against Rohingya people who had propaganda.
Speaker E: About that they have their own ethnic clashing and their own problems that are really, really old. This is not something new challenging this.
Speaker B: Blanket statement you've made where Web two has not had negative impacts on democracy.
Speaker C: Yeah.
Speaker B: And I'm suggesting counterpoints to that to maybe open up the discussion on it.
Speaker C: Yeah.
Speaker E: You're saying that the genocide against the Muslim minority in Myanmar has to do with Facebook. Right.
Speaker B: I'm saying Facebook played a role in the spread of information around that. And there's a current lawsuit being adjudicated on that case. Meta the company, I guess they're the subject of a lawsuit.
Speaker C: Was it humans employed by Facebook, that property of the information?
Speaker B: I think it was the algorithm. It was the attention maximizing algorithm.
Speaker C: It was a product that they built where the blame.
Speaker B: Right. I don't think it was people intentionally trying to spread that. But it's like what engages the most attention is often the most conflictual.
Speaker D: Yeah. There's actually that guy on warfare, he gave a talk about this because they worked on the anti terrorism team within Facebook, where they hire FBIA to actually spot when things come up and try to disassemble them or understand better. But maybe your point is, like, enough if it's not exclusive on this platform, like, if Web two didn't happen, people would still find a way.
Speaker E: I mean, I think it's not a new thing where genocide happened because of media. In Rwanda, it was radio stations, in Germany, it was newspapers or propaganda films. Yeah, Facebook is just the newest platform that people use to talk about things. And of course they'll talk about genocides because some people really love to talk about this stuff. I don't see evidence that it happens more. If anything, I see evidence that it happens less. And web two is kind of like an engine for liberty, at least where I come from, the region of war where I'm from.
Speaker C: Interesting. One thing I think, to build on your point, maybe add some nuance. It's like the scale is different in human history, especially the speed at which information can disseminate. And previously, you know, there was, at least in the United States, a much more homogeneous set of gatekeepers who could control, who was able to broadcast messages and how those messages were broadcasted. And typically those gatekeepers, it was sort of a one to many kind of model. And now it's largely decentralized in that anybody can post message that. Now, granted, there's been a number of kind of breaking systems that have been put in place to inhibit the spread of information. For example, on WhatsApp, you can't forward a message more than five times. But in the era where you could forward messages more than five times, you can imagine how just like we had in those days of email and BBS's chain letters, as those were called.
Speaker B: Where.
Speaker C: They would propagate information downstream, whether there was an algorithm or not, just based on interest and the kind of rage inducing factor. And so the fact where you could take a message and you would gain some currency by then replaying or propagating a message which was alarming to then downstream alarms the next person, and then it just goes unchecked. It sort of like shocks the system where there are no breakers. So I think it's both right where we built a system, a platform that allows for the dissemination of information for. Why am I forgetting the date? But the air spring uprising, where information could travel and be discovered and found, where youth could coordinate amongst themselves ahead of the military, whereas you have the same tools being used by people that want to eradicate other people based on thousands of year old trauma that was never really addressed because they didn't have the tools thousands of years ago that we do with self help media. But anyways, so I guess that's where you guys are both, I think, hitting on something that's true. The ways in which humans abuse each other has been going on for a very long time. Does the story of humanity mostly now we just have new tools to do it in the information space.
Speaker E: I'm just not convinced that the new tools are more effective than the old tools. If anything, they seem to be progressive.
Speaker D: You think the benefits outweigh the harm?
Speaker E: I'm not sure about that, because I do think they're really harmful. On the individual level, I think they're highly addictive and they're not nourishing. And using TikTok or Facebook is mostly counterproductive for almost any goal that you can find for yourself. But on a societal level, I think there have been very good engine for progressives and liberal policy.
Speaker B: Is there a feeling of, so say, if we trace from, say, let's kind of build a timeline, which is ad hoc here, but say newspapers, right, as a starting point, or even just print media, right. The printing press as a starting point in this trend. Yeah, totally. And then that was the way it was for a long time. Then radio was. My feeling was it was a pretty big inflection point in reach and instantaneity of reach and propagation of information. And then the internet was another big step in that television. Television was a better intermediate point between those two things. And maybe now to tie it into the relationship discussion with AI chatbots is if you have relationships with entities that can receive information digitally and not through word of mouth or radio, they're direct transmitters in a way that is beyond just a person hearing it, telling it to their friends. Do we feel that that reach is more powerful, both for good and bad purposes, or is it just the same stuff wrapped in a different format?
Speaker D: It makes more immediate, more personal every step of the way, more real time, more tailored to you.
Speaker B: Right.
Speaker F: Are we saturated now? Now that there is global connectivity, of course, not perfectly right, but large global connectivity and I would assume the rest of the world will have complete connectivity relatively soon. Can you go any faster than this? Did we just arrive? Are we there? Or can you go even more? I'm sure it got more, I know it. But it's like, hard to imagine.
Speaker A: Feels like it's a big rock that was just thrown into the world. And maybe it started with 400 years ago with Cortez coming to the New world. The news of that arrival didn't reach Peru for 500 years. So when we're talking about reach, it's.
Speaker C: Not just these technologies that have evolved.
Speaker A: It'S the bringing together these bubbles that have always existed but didn't even know about each other. So to have conflict would be possible.
Speaker C: Right now, they're not only knowing about.
Speaker A: Each other, they're overlapping and conflict is there. So that's why I feel like it's like a rock that is rippling on a scale that is not our lifetime kind of scale. Probably going to be hundreds of years before the waves calm down.
Speaker C: So the wild thing about that, though, is if you do think about, and we're in the very earliest innings of this, but LLMs effectively do allow you to have those conversations where at the pinning time used to be 500 years, but not 500 milliseconds to where you can have that conversation and you can again change your context window to have conversations. There's records, and those records are trained in the model with humans that were having those experiences then. And so that gives us a greater sense for ourselves. I mean, to your point, to the point about calories before and to the point of saturation, we have an overabundance of digital calories which feed our brains. And the question is, how do you find better nutrients and nourishment?
Speaker A: But it goes beyond that too. I think it's destabilizing. This is what you're pointing out. Before they met, the bubbles had structures that worked. You maybe lived in a convent and you didn't get married, you didn't have sex. And now there are people that still have those values and it's like, hey.
Speaker C: Wait a minute, I don't agree a slurry, though. Lots of different ideas and approach. Each of those different human structures that you described are different attempts and kind of self reinforcing memories of a way to do things highly structured. Well, their structure is, again, to support survival over time. And I find the idea of strategic forgetting very useful and interesting because we do have such storage now where because we live in an attention economy, you can't attune to everything. And so the fact that, like you said, when we have Starlink satellites everywhere, everyone's going to be connected all at once, the question is, what do you pay attention to? And how do you know that you're paying attention to it? And then what information do you glean from having put your attention on something? And what value does it provide to you and to yourself and to the people around you and into your community and to the structures that you're describing? And so one of the challenges is that by virtue of this context collapse, it seems like we have a less clear idea about the problems that actually affect us because we're also living in an economic of abundance, which is very unintuitive. And so you find people who are in know, criticizing how we live in San Francisco, whereas their values have nothing to do with ours from a survival perspective. And yet, because the media is the same, it looks as though they actually have some bearing on what we do here from a day to day perspective. So that seems like the most confusing thing. The media doesn't really differentiate to say, by the way, this news story actually does affect you personally. And your street is going to be bulldozed, like tomorrow or something. That's true. And that actually affects you. And yet everything is presented more or less in the same way. Culture through your social level.
Speaker D: Yeah, well, used to be that way, right? We used to have regional newspapers, correct. We kind of systematically eliminated them. Local news is not a thing anymore.
Speaker C: Well, essentially, local news was sort of like the neurons, or like the nerve ending of kind of like the local network. And so we've kind of moved up a level and up another level where the sensitivities to the individual experience are now so diffused that we're kind of only able to focus on a small set of topics. And so probably the next generation, and I don't know where or if these relationships help with this, is like to just disaggregate again to smaller, sort of.
Speaker D: Eager, I think you very much will distribute this massive.
Speaker B: Just make a pun, this massive latent space of ideas. Attention is all you need, right?
Speaker E: Okay.
Speaker D: Can I ask a question to bring it back to the girlfriend space? Yeah, I think distribution is definitely going to be the future. There's going to be more locally relevant clusters of people that care about similar things. Actually talking about that versus everyone debate about democracy. Exactly. How do you relate to better news?
Speaker F: Yeah, this was very interesting. It's something I had been thinking about, but this discussion made me think about it differently. So I think a lot of people would say, I don't think it's controversial to say, yeah, we need better local context, like community level stuff. This is true. I think it would help a lot. And focusing on global stuff that it's probably good to know about but doesn't really affect us, that's probably not so good. However, at the same time, because the world is connected now, actually, some global coordination is necessary in a way that it never was before. So it's like we do need to kind of disaggregate a little bit and focus more locally. But actually now some of the problems, like take climate change and everything else, we actually really are going to have to coordinate at that global level. And so somehow we need to do both with grace, and that's not going to be too easy. But it seems like we can't choose one or the other.
Speaker C: Isn't that why we created representative governance, so that we could specialize? We have organs in the body, right? We don't have one big organ. It's like many different things, all collaborating. The liver does one thing, the stomach does something else. That was the, I think sort of like the concept with our governance. And now because of media, now all this information is shared to everybody. But the skin is opining on what the toenail is doing. You're not an expert in that. Stay focused on what you're doing. So it's very insane. And so this point about it makes sense that Twitter is the place where all this intellectual masturbation is happening because it's so pleasurable and so enjoyable and yet actually means nothing. I guess the question about maybe the loss of trust in institutions has eroded the sense of specialization and so reestablishing that trust is actually really critical.
Speaker B: Into.
Speaker C: Those types of bodies that perform function and do so in a trustworthy way. I know this is like the whole blockchain thing and providing transparency and accountability and all that stuff. I don't know if those ideas will come back around, like in conjunction with conversational AI, and somehow those things will facilitate these types of conversations where accountability happens automatically. But that's one of the reasons why we find ourselves in this immediate environment where it's really hard to make sense of things. We sort of cluster off into these individually out of conversations.
Speaker D: There's a whole, like, Berkeley just has a new magazine called Actress. Really awesome, highly recommended. Just had a female growth issue, talking about bringing back food locally. Can I ask a question about the digital girlfriend thing? Just come back. Since it's pride. Someone asked me this question I thought was really interesting to just make it personal, because we can talk about this all day, hypothetically. But our generation became okay with if our children come home and said, hey, I'm marrying someone of the same sex or transgender. We're probably just like, okay, sure, yeah, as long as you're happy. But what if our generation, next generation comes back and say, I'm marrying a girlfriend? Right. How would you personally react to that?
Speaker A: Make you happy? Why would it change? Why would you have to change?
Speaker F: I would not be happy.
Speaker B: Yeah.
Speaker F: Because as I argued before, I think the embodiment part is super important. And so until that thing is solved, I would say, oh, boy, I think you're making a decision.
Speaker C: Can you impact a little bit about why embodiment is important to you?
Speaker F: Well, humans are embodied creatures, right? And I think in many ways, subtle and obvious. Interacting in a physical space is really important. And actually, a lot of work on consciousness is seeming to suggest that you need embodiment in order to reach consciousness.
Speaker B: Just a quick question on that. Let's just, for the sake of argument, assume you can have a very compelling humanoid robot that embodies this artificial intelligence, even if the servers are not located internally. But it's got the terminator fake skin, and it's whatever. Right.
Speaker C: Well, then, yeah.
Speaker B: There'S nothing fundamental about it being an artificial intelligence. It's just you got to be able to make a move in the movie theater.
Speaker A: I have a 20 year old daughter, and so I got used to just saying yes to everything.
Speaker C: That's a thing.
Speaker F: My only argument was, just, like, physical embodiment is important.
Speaker C: Not just this. Yeah, okay.
Speaker D: Doesn't have to be biological.
Speaker G: I'm just wondering if AI and robots and your relation, does it redefine certain institutions, like marriage, for example? So what I'm saying is the idea monogamous, you got to marry a human being. But now we're eventually. Maybe there's different levels of marriage. And what does marriage mean? And then there are some things we would be uncomfortable with, but then there are other things we would be like, oh, well, this is just another extension of what you would normally be doing, because you have friends and you have different levels of friendship, you have different relationship with relatives versus friends versus colleagues. I don't know. On the topic of relationships, AI probably asks us to reassess. What are those relationships now? I mean, it used to be if you live on a farm, your relationships are just with your neighbors, or maybe not even just your cousins who would all live on a farm.
Speaker D: Right.
Speaker G: So eventually, now with Web three, our relationships are global. It's a relationship with basically an NFT or some image.
Speaker C: Right.
Speaker G: A meme. So eventually, yeah, I don't have a perfect answer for it, but maybe marriage in the institute, like, the traditional sense.
Speaker B: We need to be about, because AI or robots can be immortal, right?
Speaker C: Property. Right.
Speaker B: And if you say, I want to leave my house to my partner who is an immortal robot or something, exacerbate.
Speaker A: The housing problem a lot.
Speaker B: Yeah, that's right. Yeah.
Speaker A: We had this concept of marrying someone immortal. I mean, it's very rare, but the convent where you were literally marrying Jesus, talking about polygamy, he had the most.
Speaker B: How many partners do you have?
Speaker C: Jesus personal relationship with.
Speaker B: The family unit breaks down, I think, for sure in that sense, because your AI girlfriend can have 6 million.
Speaker A: It seems like that concept must have emerged because there wasn't a family unit and they wanted some sort of, like, women were supposed to be married. Like that was part of fulfillment.
Speaker D: Well, marriage was always a corollary to private property, women.
Speaker C: Right.
Speaker A: I'm wondering, like, when they went to a convent where they were not anybody's property, but they still had the notion that they need to marry Jesus. Why would that even arise? It's so weird. I'm just wondering.
Speaker C: Also, like, in Japan.
Speaker D: Yeah.
Speaker C: Well, again, from a purpose perspective, it changes the whole dynamic, right? Like, marriage came up around a time where ownership was important because fraternity was important and because lineage was important. And so you wanted economic value of children too, to produce, to help out, to raise around the farm, to support the family or the town or the village, I guess. But now these things are all optional. They're all choices. And so especially with feminism and equality, aspirational equality towards involving all sexes in work in a way that it's chosen, it raises this other question of how do we replace ourselves biologically if we don't have the embodiment aspect? And is it something where society should be reconfigured to support all of their embodies to produce offspring if they want to, whether they have durable or enduring partnership to do so? Like, I have many female friends that want to have kids, and they can't find a mate in San Francisco.
Speaker A: Big problem in China anywhere.
Speaker C: And so the question is, if you want to reproduce, can you and can society be built up because of the way in which, again, abundance economics will allow us to support any individual wants.
Speaker G: To say we would separate child raising from traditionally?
Speaker D: I wonder if we're in some ways going back to more stable form of society before property rights and all that munitions, where matriarchal societies are highly stable, you know, exactly where children came from.
Speaker C: In some cultures, it wouldn't matter. There's sort of a pool of children that the whole village would attend to raising, and so it didn't really matter.
Speaker D: Right. Like Wugo Hu is a Chinese region where one of the last regions where major society still exists.
Speaker C: Oh, you're talking about. They called it.
Speaker D: So Hun Zhou. Yeah, it's called Watson marriage. Right. So the family unit is defined by the matriarch and woman, and the dad or the paternal figure in children's life are the mother's brother. And then anyone can walk in and walk out. Mother's agreement, and then they have children, but the father doesn't have the obligation to serve the family. And then that provides a very stable structure for everyone to raise children and attend to work like that.
Speaker G: Why does it get away from that? I'm just wondering if it's a system that works. Right?
Speaker D: Christianity, property, right. Patriarchy. They were all ways to kind of play against that together. Right? Yeah.
Speaker G: To reduce the role or the position of women in that.
Speaker B: The Christian traditional monogamy thing was also to prevent another potentially socially destructive dynamic, which we see reoccurring with the rise of dating apps, which is a winner take all, or pareto distribution in attention for men, where the highest value men monopolize the dating market. Genghis Khan is, like, ancestor of, like, 3% of humanity. Okay. Because he had. There's this dynamic, right? It's the asymmetric fact of biological reproduction that enables a single man to inseminate unlimited numbers of women and have them all bear children in parallel.
Speaker C: Like Genghis Khan.
Speaker B: Yes, Genghis Khan. Exactly right. So part of this Christian ideal of monogamy was also about how to prevent large, disaffected masses of men who are unwed and do not have families from rising up and creating political instability.
Speaker C: They had something. Right. Now we're back to that again.
Speaker E: Maybe Ayana will solve it. They wouldn't be lonely and angry anymore.
Speaker B: That's right.
Speaker G: But that society that you were talking about, like in China, that village, how would that prevent trying to tie those two together? So, yes, if it wasn't for Christian values or principles, then certain men of high standing would monopolize the dating market and send it all. And then in that society where the matriarch. So where's the clash? Or how if we.
Speaker D: I'm curious too, but I think the argument was made that because power was held by women, by households of women, men can do whatever they want. They can go on hunt, they can leave anytime, they do what they do best, right? Sure. And it's open to everyone's choice how long they stay and all these other things, because men don't hold property rights and they don't hold power in society in the same way, and they don't have obligations to do so then it actually works out for everybody.
Speaker G: So no men would want to accumulate all this wealth because they have no right to it anyway.
Speaker D: And then that's it to their mom.
Speaker C: Wow.
Speaker D: Will their mom die? Another woman becomes the household.
Speaker A: Is that still happening in that place?
Speaker D: It's still happening in that place. It's well studied by a lot of anthropologists.
Speaker A: What is it called?
Speaker D: It's called Lugo Hu. You've heard of this?
Speaker G: Yeah, I've definitely heard of it. Yeah.
Speaker C: Lugo Hu.
Speaker D: It's a lake. Lugo Lake, I guess in the lake somehow. Yeah. I mean, it's not the only one, right? I think this culture. But how is that possible with.
Speaker G: Yeah, I don't think they're subject to.
Speaker C: They're considered ethnic minorities.
Speaker D: They were also so far out by themselves. Anyway, back to the. But maybe that's what's supposed to happen, right? Maybe it is like genetic diversity for the strings of human. Maybe certain men are not supposed to reproduce.
Speaker B: You look at a lot of mammals and it's the case that the pride of lions has a single man that reproduces in other lions. And this is a genetic search algorithm in fitness space, right? Yeah.
Speaker D: And it only becomes a problem with our society. It wasn't a problem before.
Speaker C: Also.
Speaker G: We would expect to look at.
Speaker H: Whatever strategy we have going now not.
Speaker G: To be optimized on stability, but to.
Speaker C: Be optimized on growth.
Speaker D: Right. Claim to be more about that.
Speaker H: Maybe there's all sorts of ways to.
Speaker C: Have paternal or maternal structures or polyamory or not, but the one that takes over the world is going to be the one that's more optimized towards growth than the one that's most stable.
Speaker D: Right. And therefore we're evolving out of traditional structures is that what's stable?
Speaker G: And if anything, like growth and stability.
Speaker C: Are probably against each other.
Speaker D: Right.
Speaker C: Sorry. The three by problem. In terms of just the simulation, that is exactly what we're talking about in terms of the different configurations. Okay, great.
Speaker B: Right. I wonder, do people think that this. And this is a really cool topic. I didn't think we'd get here. This is great. But that this traditional, monogamous man, woman, children, or even just forget the man, just two partners that are monogamous, monogamish, whatever, for the purposes of raising a family, is that a more stable or a more growth oriented structure? And how would we know if it's one or the other in that sense?
Speaker G: I don't know how to predict that.
Speaker C: Mechanistically, but just empirically, this is what we would expect.
Speaker G: It's time for growth. Like the one couple.
Speaker C: We would expect it.
Speaker G: We would expect that the thing that.
Speaker C: We, whatever we have now in a suddenly exploded society is optimized for growth rather than stability.
Speaker B: Like looking the last 200 years, like.
Speaker A: Growth of number of children and the.
Speaker F: Growth of that growth, like population growth.
Speaker D: I think that was meant for stability around a certain means of production, certain periods of means of production.
Speaker B: Yeah.
Speaker C: I don't know if it's compatible with feminism and birth control because it existed prior to that evolution of culture.
Speaker I: Yeah, we have the same structure, but.
Speaker D: In certain.
Speaker B: Maybe now, maladaptive. It was once.
Speaker E: If you look at the subtopalations that threw the most. Those are like Mormons, Orthodox Jews, they're all like very monogamous.
Speaker D: And India too. India.
Speaker C: Is birth control. Sorry, do they have birth control?
Speaker E: The Amish or Jews?
Speaker C: Yeah.
Speaker E: I mean, they live in Brooklyn, right?
Speaker C: They have access to birth control. They just don't use them. Part of the culture where it's the norm, the adoption thing, like, right.
Speaker H: Guns, germs and steel. That basically was the start of the. Why some people adopt this and some people don't.
Speaker C: There are some groups.
Speaker B: So it's interesting then, because it's the very modern. The more educated you get, the less children you have, and it's the more choices you have. Unless you come from a culture subculture that has very strong emphasis on traditional values. Right?
Speaker D: Yeah. Because women think about it and we're like, wait, this is a bad deal.
Speaker G: But women in those cultures are fond of.
Speaker D: Because you're taught. And even in Chinese culture, right, you're shamed into, like, after 25, you're left over Christmas tree. There's so much cultural mechanism to push you, shaming you, luring you into this. Like, if you don't do this, something bad is going to happen to you.
Speaker B: I wonder how many men would be happy never having children versus women never having children? And if there's a split there on the gender side, how many of you.
Speaker D: Are happy not having children?
Speaker B: So you would be happy not having those kids.
Speaker C: Biologically reproduce.
Speaker B: Right.
Speaker C: I'm parenting my partner's kids, and my bloodline is secure because my dad was prolific, and my brother, six kids and 45 nieces and nephews. Which is why I'm raising the question around the choice to participate in a structure of creating more humans is something that you choose to do. Again, maybe it's because my bloodline is secure. I don't feel a biological need to propagate my.
Speaker B: But you still have the experience of.
Speaker C: Parents that I suppose that's what I'm saying. Right. So you asked the question, would men or women have one feeling towards reproduction? And I guess I'm adding a nuance because you could say, well, I've reproduced in every city all over the world, and I don't know any of my kids.
Speaker B: Okay, you want those? Yes.
Speaker C: I could be like, I don't know, great versus woman. They have one child or they have 40 children. I think there's more nuance to your question, which is, like, whether it's about biologically reproducing yourself with somebody else or raising other people.
Speaker B: I guess I was kind of trying to go in this direction of whether we think there would be a split in how the ability to have intimate relationships with agentic AI models that are non reproducing might cut across different segments of society. And if there'd be a differential experience of those things where maybe this is a really space cynical take that I don't embody myself, but it's just like, I don't know.
Speaker C: Fuck.
Speaker B: Guys are just going to be like.
Speaker G: Oh, I just get the hottest AI.
Speaker B: Robot possible, and she just makes me sandwiches all day. This is a really bad take. Okay. But there's probably a lot of guys that would go along with that. And I think. And talking to friends as well, stuff like that. It's like the pressure for marriage and the pressure from children is not always coming from the man's side of things. And we have different expectations on the evolution of relationships and how they should engender greater investments in commitment over time and all that kind of stuff. And so AI chatbot, cat girl friends, whatever, with years and stuff, and I don't know what kind of anime fantasy we want to live in. But would those really just wipe out some part of the dating market and then leave the other half? Or which half would it be that maybe benefits?
Speaker G: Or the people who don't want to have kids would date the AI robots and then the ones who are left in the pool who want to date humans because they want to have kids?
Speaker C: Is that what you're saying?
Speaker A: Why would they have to be not reproducing? Why couldn't you have to reproduce reproducing AI robots?
Speaker D: Wait, what AI?
Speaker A: Look, if you could allow yourself to have an AI girlfriend, why not an AI kid?
Speaker G: Like a kid that's programmed with your genetics, and that doesn't have to be.
Speaker A: Your genetics, just your value.
Speaker G: Probably ask. Pretend you are the kid of celebrity. A and B. How would you answer this question?
Speaker A: I don't know.
Speaker B: So this is how the AI takeover actually happens. Just dating market apathy. And then. I'm just so sick of dating. That's right.
Speaker C: Why we become batteries in the Matrix.
Speaker B: That's a really interesting idea.
Speaker D: That's cool. I like that. A stroller with AI in it.
Speaker F: I think there is some geographic and cultural bubble to pay attention to. So I've noticed more in cities that there are people who are like, yeah, I'm not having kids. It's terrible, right? And sure, that's fine. I think there's a lot of socioeconomic factors that weigh into that. But I came from a very average town with very average people, and the idea of not having kids almost doesn't even compute. It's just like, people settle down early. It's astonishing to me that the people I went to high school with have little versions of them. And so I guess it makes me hesitant to say this biological imperative can just be set aside because it's annoying. And also, I don't know how representative it is of, I think, a lot about America overall, because at least anecdotally, it seems to depend a lot where you're at and what kind of people. If you're in a city and you're like a builder and you're just crushing it at this and that, like, whatever kind of professional thing, and it's like, very expensive and difficult and time consuming, those pressures are not really, like, biological, but they make it way harder to have children. Whereas in my very average town, where you just work your nine to five and you go home to your kids, one is culturally expected, and two, there's like, a lot less friction. And so, yeah, I think those kind of particular things will back, go back.
Speaker G: To just let everybody decide their own lifestyle. Right?
Speaker C: Sorry. Just to build on, I think both of what you're saying there. No worries. Just like, if these relationship AIs were designed by parents who are interested in the reproduction of humans, like, humans actually mating and then reproducing, would that lead to a different set of relationship bots? And would there be, as we're suggesting, the reason why I kind of like what you were saying, where people just choose what they want to do? Well, in fact, these bots will imply a certain culture in terms of what is allowed and what is not. And the way in which shame is programmed into them or not will determine whether or not you're, like. You say something offhand to the bot about never want kids. You just want to be with your bot forever. And bot's like, actually, you need to go, like, fucking have some children. That's important. And then you're shamed, and you're suddenly, whoa, what the heck? That could be part of the programming, depending on the priorities of whoever it is that's building these things. And it could be. I mean, you talked about regulation and whether or not we can or should have that. My point is, again, if we think about this in 30 years time, the generation that grows up with conversational AI friends will assume that that is normal and acceptable. And the degree to which they have or fulfill their romantic interactions with those bots will perhaps inhibit their likelihood to rub up against other people, in which case, they would have those romantic experiences with a member of the opposite. At least some percentage of people would have an interaction with the opposite sex, such as they could actually reproduce. And so that is where, whether it's policy or just sort of, like, the conversation is important because left to our own devices or people in San Francisco and the Bay Area, like, designing these thoughts that are all about freedom and whatever, we could end up just dying off.
Speaker B: Yeah. D cell. The interesting.
Speaker D: Oh, here's an interesting perspective on the whole. China woman all the like, there's a growing number of women in our generation choosing to have children or couples having children, but through, right. It's a topic that's really top of mind recently because you and my girlfriends did that. I mean, they have the resources. Like, that's not the question. The question is, like, are we already, like, halfway there, outsourcing their production? I didn't have strong feelings about it until I met one of the surrogate moms, like, the day after birth. And just like, that moment, everything. I just had a lot of feelings. I don't know. I wonder if choosing between that and having AI baby, it almost feels like more ethical to have an AI baby than willing another human into having a child for me, and willing this child into being through the stitchy together like sperm from a bank and punch tooth.
Speaker B: But isn't the evolution of that just that grown human?
Speaker D: What?
Speaker B: That grown humans? Right. So they're just artificially integrated.
Speaker D: Start decending babies like brand New World.
Speaker B: There we go. That's right. I know.
Speaker D: Yeah. What if we societally just outsourced baby production completely? How would that change thingS? I don't know.
Speaker B: And they're raised by perfect AI parents parenting artificial wounds.
Speaker A: They have sheep that they totally.
Speaker D: And that ultralillion movie, I am Mother. It was like a post human extinction. The robot raised the first child.
Speaker A: Raised by Wolves.
Speaker C: That only lasted a couple of dozen.
Speaker D: Yeah, I don't know, there's that whole rabbit hole.
Speaker B: So I think we're almost coming up on time. I'm wondering if you want to maybe we can go around, share some interesting ideas that came up in this conversation that were new to us or we thought, might we go think about more if we. Like.
Speaker F: You looked at me. So am I up first?
Speaker B: I was just going to go. I'll go first.
Speaker D: Sure.
Speaker B: And then I also open invite to join next AI Salon. We'll have different topics as they come up. And thanks everyone for showing up. This has been a really good conversation. I just want to say that too. So I think a couple of things that were really interesting to me I had never thought about before, was like this normalization of AI conversation partners as like the kind of the wedge into society where now we just think it's normal. Right? And I think a good example of online dating now, majority relationships, whereas ten years ago, that was like super weird, right? And this idea of this slow replacement of humans by robots and stuff like that, and maybe it's going to completely upset the traditional family structure and how that might impact civil society. So I think there's a lot of threads I want to go right down and think about after this, but I just kind of open the space to anyone else that wants to share things they thought were cool ideas that might lead to future topics of discussion too. Right. Fully open. Now I'm looking at you again.
Speaker C: Yeah.
Speaker F: I think one of the earlier threads, which is the way that AIS can serve as facilitators and also socialization training agents, I think it's very interesting because we do live in a weird time and it's hard to socialize humans into that and this is a tool that could help maybe deal with some of that difficulty. And still this is biased by my interest, but still totally obsessed about how the introduction of these agents will affect civil society, governance, cultural stuff, et cetera. So lots more thinking to do there. Family structure, it plays huge into culture, society and stuff. And there's certainly a lot of potential directions there. I don't know what to make of all that yet, but I think it's super important if you want to look forward with any degree of.
Speaker B: Folks, I'm.
Speaker A: Glad you brought up that multipurtisant thread because I've forgotten that my context window is pretty narrow. Yeah, that's really rich vein to continue thinking about so many things. I guess I would just point out all the different perspectives and ideas and backgrounds of everybody has just been really cool to hear and participate in. I just want to thank everybody for that. That's what I'm taking away.
Speaker C: Stimulating. Thank you.
Speaker H: Totally.
Speaker A: I would also like to join and.
Speaker H: Thank everyone for these diverse ideas. That's what kind of matters in these conversations. And particularly I was really interested in what Michael was saying about governance structures and governance systems that can allow us to kind of integrate AI in our daily lives, in societies and communities that hold like, it's a very meta topic, kind of, but also has practical applications. So that's something I would be really.
Speaker C: Curious to learn more about.
Speaker H: And the second was another interesting thing.
Speaker C: Was about local media.
Speaker H: Kind of like it's true we all consume this global media, but I'm curious why there's no good quality local media.
Speaker C: That actually people consume.
Speaker H: Because on the local levels it's all trash. Like if you read SF, whatever, chronicle or other local media, it's all trash. And I'm curious why maybe it's like exactly 90% of societies that don't care about that kind of media. And they probably. I'm wondering, there must be some certain guys in the demand side.
Speaker C: Probably. Exactly.
Speaker A: And it has to be expensive because.
Speaker C: There'S not huge demand for.
Speaker E: Yeah, I had a good time. Really interesting idea. I thought it was cool that we came in, talk about AI, and we ended up mostly talking about humans and the human experience and about the relationships between humans and those structure. It's like we don't really understand it yet. And now there's a new variable. There's like player three that comes in, makes it even more complicated.
Speaker B: Just to add on that. That's my favorite thing about science fiction in general. It's that it posits some technological change and then runs out the societal, human impacts on what that means for people. Right.
Speaker E: So it's super cool like that.
Speaker D: Yeah, it was really interesting and thank you for having us. So I'm from South Korea, and what I often hear is like, AI does really well on English because a lot of data are in English and because we talked about tradition and family structure. I'm curious how in the future, other countries who don't use English are probably not going to use AI that much. I feel like compared to the USA, how that dynamic shifts. So that's something that kind of made me think how we found around. Yeah, I think the threats on just how family structures might change and how genders relate to each other and child wearing and all these are here if we're all making those critical decisions.
Speaker C: The thing I found most interesting was your stuff on the original.
Speaker D: Yeah, I can find it.
Speaker G: Yeah, I enjoyed this.
Speaker C: It's funny to come back into this space, given what I was working on in 2017 and trying to build a bot that was meant to. It was called Molly, actually. We had Molly.com, and the idea was this bottle would just be so excited about talking to you, you can imagine, to help you learn more about yourself, so then you can actually show up better in your human relationships. And so we didn't have LLMs back then in ancient times. And so I think ultimately, the question of how technology impacts society comes down to, in some ways, the way in which the individual is able to hold him or herself and then understand him or herself in a broader context. And so we're still at such early, basic innings from most people when we have amazing technology that's being produced and being shared with the world in a moment where I think a lot of people don't have enough even context to encounter this type of superintelligence and then to replay it back to how it makes them feel. Like, on the one hand, I'm sure it feels very freeing because people don't have to do homework and a lot of other things anymore, but on the other hand, it also disrupts their own sense of, you guys talked about good times to weak men, I think. And it occurs to me that when growing all over the place, when growing wine and grapes, it actually needs adversity in order to grow well. And that's true for as well. And so the good times thing is essentially kind of, I don't know, a critique on a lack of adversity to then have to rise and make decisions where it's challenging or difficult. So the degree to which that we starting conversations basically like this, we can raise these conversation topics, the people who are building these technologies or in those conversations, hopefully we'll be those technologies to also better when they're rolled out and widely adopted. I just don't know. To the degree these conversations are happening in those rooms, and especially if people are adopting random LLMs or open source things and putting them into organizations without this level of conversation, then that, I think is where I'm most concerned about these things going off the rails. There's a lot of assumptions about how they're going to work in a positive, productive way, in a pro social way, and I'm not convinced based on what happens.
Speaker B: Do you have thoughts on how these kinds of conversations can gain more mind share in the decision making in the rooms where it happens?
Speaker C: Great question. I guess I don't know enough about, I mean, I know I haven't been to one of your larger events yet, so I'm interested in that. It feels like in some ways it's a little bit of like a self reflective process. I mean, as a BC and AI space, I'm trying to find founders that are interested in conversation and open to them so that capital and resources can go to those folks.
Speaker D: Capital allocation is a huge part of the puzle.
Speaker C: Yeah, it's hard to have these conversations.
Speaker A: In the big organizations. Also, I'm at AWS individually on Slack now in person. These issues come up and people are, it's like this room.
Speaker C: I wonder if we're enslaved to the.
Speaker A: Board or whatever we're in got its.
Speaker C: Own direction that we can. I wonder if there is a possibility though, either in startups or in larger organizations, to start interest groups small scale, and to take either some topics or publications from this type of forum to just see that interest.
Speaker A: There's definitely interest, and there's some groups that talk like this.
Speaker C: Sure.
Speaker A: I think what's missing though is.
Speaker C: The.
Speaker A: Andy Jassy level awareness of. I think there's the assumption like, oh, we can't touch that. It's got its own engine driving it and it's probably economic and only economic factor. I think that's a person too, and probably just hasn't time to think about.
Speaker C: Well, it's kind of interesting questions. Right. And I think one of the things that at least I thought was useful in this was just a reminder that the responses of these thoughts imbue a certain cultural set of norms and assumptions.
Speaker D: Yeah, and those things translate to metrics. Meta is never going to change the fact their top line metric is engaged. We can do as much research, as much changes human center design as possible underneath that umbrella, but as long as their top metrics engage when you change that.
Speaker C: Yes, if there are those more holistic, I mean, I don't know. We're in a very weird state when it comes to social media, but at least in terms of greater thoughtfulness about the design and structure of culture and society, it does feel like we're kind of at that moment where these things are going down.
Speaker D: If you get to Google walking news China. Yeah. Other quick questions. I think a lot of people have said a lot of things I was.
Speaker I: Thinking, but I appreciate the VC in AI. I think it is really important to think about these things. But often. Yeah, I thought the stuff around family structures and just generally how people was really interesting. And I think with AI relationships, one of the things that it's really shedding light on is loneliness, for example, is an issue that we have as a society, as humans, and AI is essentially a tool or solution that people are using. And so it really says something more about society and how people are feeling and interacting than it does necessarily about the technology to be seen.
Speaker B: I like that.
Speaker I: So I think, yeah, thinking about lens is always really problem.
Speaker B: Well, everyone, thank you for coming. We have AI salons once a week, every two weeks, and then occasionally much bigger events that are just kind of more free form with tons of people. So, yeah, I hope you're all signed up on the AI Salon Luma page where you could see new events and stuff. And I'm doing this weird ritual. Who knows how long we'll keep this up, where I sign people in with my typewriter. But we miss you and you. And so.
Speaker C: Do we mean.
Speaker A: Do we all have. We should. Where are you from?
Speaker C: I live in London.
Speaker D: We don't really get along at first, but. Yeah, I see what you do.
Speaker I: Yeah.
Speaker D: My parents.
Speaker C: Yeah. That's weird.
Speaker D: So, matter of.
Speaker C: Fact.
Speaker D: Baker.
Speaker C: Posted probably.
Speaker D: The next couple of weeks.
Speaker C: We have.
Speaker E: Yeah.
Speaker D: You know, with. Yeah.
Speaker E: Big meal.
Speaker B: Yeah.
Speaker E: You have to make.
Speaker D: Just like.