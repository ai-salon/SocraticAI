Speaker A: Cool. So I'm Andrew. I have a lot of diverse interests, I guess, but the biggest one is physics in my both personal spiritual life as well as professional Life, which is, I guess, nice and very lazy in a sense. And, yeah, in the past, I've involved with startups that use AI, and I think one of the things I think is really interesting as you. You really dig into physics and statistical mechanics, and that kind of stuff is, it seems as if there's a very persistent, profound connection between information, what information is, and what physical systems do as they process things physically. Right. And I think that's very interesting. There's this Concept, black holes are great thought experiment from Leonard Susskin called the holographic Principle, which is like, you can encode the information that describes 3D volume and the 2D boundary of that surface, or 2D surface of the boundary of volume. And it kind of starts all these weird discussions of, like, are we living in a simulation? Are we some kind of, like, black hole computer or something? Which I think is kind of, like, out there, but it's fun to think about. And I think it's really kind of weird because we're getting to the point where we're simulating physical reality at higher and higher fidelities, and we can start to appreciate why it makes sense to simulate physical reality. I don't know if you've seen, like, Rick and Morty was episode where this battery is like a little miniverse and people live inside of it kind of thing, and it's like, damn, are we someone else's battery? Anyway, I think there's something there where it's like, we think there's a metaphysical significance to observers in quantum mechanics. And I don't know, this connection between nature, physical reality, simulations, ourselves is interesting, and I just kind of, like, stir the pot and just say, let's all talk about that stuff, I guess. Anyway, I had no cohesive point there, just a bunch of buzwords.
Speaker B: Hi.
Speaker C: Nice to meet everybody. My name is Jesus. I would characterize myself similarly where I have very diverse interests, maybe too many, but definitely, like, what I focus on is physics, which is what I studied in computer science as well. So this is, like, my favorite topic is simulations. And the reason why is because I think we're at a very interesting point in humanity where we are starting to build them. So it's not really, like, too much of a philosophical thought experiment anymore, although we definitely should think about everything as much as we can before building it, just kind of for safety. But I think we're really doing it. And we can actually start coming up with some practical, almost engineering rules as to how simulations function, which I would love to talk a little bit more as we go on. So, really interesting point that you brought up is kind of quantum mechanics and the observer. I feel in my gut when I read about quantum mechanics that it takes this sort of viewpoint that physics is not reality. It's just a knowledge model or a way of creating knowledge, like in our universe. So it's fundamentally about information, is what I mean. That's what I think quantum mechanics kind of says. And that's also what it means when it talks about the observer being important. It's like, for example, different concepts like size are only determined in the context of an experiment. And this sort of like, experiment, how we observe things, is this observer. So in the end, it's like, I feel like quantum mechanics people and those types of modern physicists have a bit of a philosophical bend where maybe in the past, traditional physicists such as definitely like Newton, but everybody, so like Maxwell and Huygens and all the greats, they were Christians, and they believed, well, not all them were Christians, but a lot of them were. And they believed this is reality. This is like divine. There is some truth, some objective thing that we're figuring out. And then I think kind of in the modern age, this thought has sort of gone away. And Einstein kind of started this, in a way, with relativity. He was a positivist and almost like the first modern physicist, I feel. But he was also a Christian, and he was very scared of what quantum mechanics was saying about the nature of reality. Like he said, god doesn't play dice with the universe. Which what I take to mean is that basically like, no, we have to treat reality like there is a reality. It's not just information. But anyways, I actually do kind of feel like it is information, and we have to treat it as information. But yeah, most excited to talk about actually simulating realities and building them and how we can do it, because we are very on the cusp of doing this.
Speaker D: Hi, I'm Max. So I work for an investment firm, which is called factorial funds. So we invest in artificial intelligence and also some of applications related to AI. So I actually had my undergraduate application in finance, but then chasing my interest in sociology, so I attended the sociology master. So I still recall that my deep interest in science fiction during my high school, reading a book called God In Simulation or God in Computing, I forgot the name, but I still remember that. That impressed me a lot. And I then put a lot of thinking in philosophical questions, especially when you encounter experiences that maybe when you walk on the street and then all of a sudden you recognize that, oh, this place I probably dream about or this place is really familiar with. Maybe I've seen it before. So that reminds me of where a lot we live in a simulation kind of theory. Yeah, just here to learn.
Speaker A: Sure.
Speaker E: Everybody, this is Ahmed. I've been an entrepreneur for the last ten years. Built a couple of companies which were not tech enough for me. They were kind of ecommerce, but tech enabled. But I'm building the third venture now in SF. This was in Bangalore, India. Prior to that I went to UCLA and lived in this area for a bit. And prior to that I used to be an AI researcher with a deep love for physics. I think the other thread that's fueling this thought process in my head is also my early exposure and interest in spirituality. We have a rich tradition in India. I think as you do deep meditation, you begin to personally have experiences which make you question the nature of lived experience reality. Like, what are you touching? You're touching something, but it's hard to explain it in words. So I think you combine some of what Andrew said. I'm more of an Everitian. Hugh Everett of many worlds. Not sure about if there's a magical role for the observer, but jury's still out. But I think physics, personal sort of spiritual experiences. And I think the other interesting thing is AI and CS computer science is coming to a point where I think we'll ultimately solve for some of these problems at the confluence of physics and computer science, because I think quantum mechanics and information theory are beginning to get more and more sort of intertwined. So anyway, that's my motivation about this topic. I think I made this comment that I'm a big believer that I think experimentation and then building something as a route to understanding something is a good approach. And I think we are at a point where. So I call this transhumanism through software, but I think we'll create human like consciousnesses very soon through software, but like in a Turing test way, that they will look and smell and feel like conscious, living, emotional, sentient beings. And I think that's a very interesting inflection point for our society. But thanks, Andrew. And I'm just taking notes on the phone.
Speaker A: That's perfectly fine. Yeah, I'm recording you. Yeah, that's the whole point. This is just. I don't want to type while you talk. And by the way, in the future these will be shared with everyone that has attended. So I'll make a little website. People can interact with it, ask questions.
Speaker B: Yeah, very cool.
Speaker A: Cool.
Speaker B: My name is Dima. I'm most interested in the topics of psychological maturity. I feel like that's one of the most upstream problems we have as a society.
Speaker A: Sorry, can you define that or. I'm not.
Speaker B: Yeah, sure. Basically, I think that if we are more self aware, wise, mature, or would be other synonyms, there would be less, worse, we would have better ability to solve other corporation problems, and generally there would be more people who are kind of flourishing in life and kind of following what they're actually interested in, et cetera. And I feel like a lot of the kind of current fights are just about like, are you on the left? Are you on the right?
Speaker A: Kind of.
Speaker B: There's not a lot of sort of talk about the fact of, can we actually improve as a society, and how would that look like? I think kids should be getting therapy in school. And, yeah. Therefore, I'm also leading a company that's doing AI coaching. So it's essentially an agent that helps people to reflect, set goals, pull up on them, kind of supports them across the whole spectrum of soft skills in connection to what you were telling. And, yeah, I see that it's better in empathy than, like, 90% of humans. Honestly, I think already.
Speaker A: Yeah.
Speaker B: And I'm kind of interested in those agents. Right. If you know the movie her, it's probably coming at some point. There's different approaches. I'm trying to approach it more from a developmental perspective. There's companies like this, Rewind, top humane, that seem to be more trying to approach it from just, like, memory or friend standpoint.
Speaker A: And, yeah, it's very interesting.
Speaker B: Once we have this, let's just keep it at a chatbot level. Once we have chatbots, that you wouldn't be able to tell if it's a human or a chatbot, then what does that mean? You all know Harari, the historian, says that we should ban AI companies. Like being able to say that for AI to be able to pretend that it's a human, that it should always be crystal clear that this is a bot, because he thinks that is super dangerous and erodes. Yeah, super interested in all the topics that you mentioned, especially someone's battery from Rick and Mordina. Yeah, I'll leave with it.
Speaker F: I'm Allison. I'm somewhat of a physics neophyte in this room, I think, or my background is in CS, and most recently, especially security that involves some interesting hardware, secure enclaves and shit. Like that, but it's pretty different from the world of physics, but long have also been into math and SAS that had some more approximation to physics back in college. So right now I'm kind of in.
Speaker G: The security and SaaS software world.
Speaker F: My sort of first order interest in physics and these AI problems is that right now I'm in sort of a pivot time, or a time where I'm widening aperture of what is interesting to work on, and I'm trying to go back and learn things that I knew better in college. So one of these is like a lab that I worked in that was doing some just biological measurements, and this at the time involved some pretty simple classifiers and whatnot with AI, and it was mostly biochemistry as opposed to physics. But I've had renewed interest in this lab and in some of the projects that I can potentially work on related to this, as well as another kind of college project or thing that I've been refreshing my memory on, is the area of federated learning, which is just a way that you can train centrally hosted models in off edge devices that's like encrypted data and so on. And a lot of the use cases for that were in healthcare or things that had a slightly more scientific scent. So that's kind of the first order from where I am now to my interest in this area. Maybe second order, like curiosities or things for this room. You guys already just have some good ones. A close thing that I'm interested in is AI as a site to experimentation. So I have some good friends working on material sciences, like printing materials, and they have different AI models that will watch and classify what's going on in the experiment, and then also try to give takeaways from what happened so that they can improve for the next time. And that has some really interesting. One of the recommended reading papers was giving these models an intuition for the physical universe. And I think that area as applies to material science is one interesting place. As I mentioned, bioinformatics is a huge interest area, too. So if these models can have an intuition for even just one thing that you're measuring in a human body, like measuring one particular molecule in the blood system, and if you can measure this well and input the data to an AI, it can do a lot better. We do, let alone we were talking about consciousness earlier. I'm really interested in mapping human consciousness physically.
Speaker G: We have a lot of these brain.
Speaker F: Computer interfaces people are working on. Theoretically, read your brain at a kind of granular level. Having AI models interpret a brain read and then simulate. So this is getting into, like, I'm also interested in them simulating physical reality, especially biologically. Like, simulating a human consciousness over the span of years and fast forwarding this or playing with variables or intuiting the results or the meaning.
Speaker B: Quick add on. Like, I was fascinated by the presentation where they could actually read the brain and then predict what the person thought.
Speaker A: Name little background yourself. Kind of where you come just to help kind of understand what your background knowledge is. Like, I studied this, or I do this, whatever, and then really kind of like, yeah, what kind of questions are you interested in talking about here? Given, like, I guess, the event description.
Speaker F: Hi, guys. I'm Anushka. So my background is in software engineering, mathematics, a little bit physics. So I'm particularly interested in the way that we can simulate brains and use interdisciplinary reading and neural networks and artificial intelligence to simulate the brain to better study consciousness and get a better model of that, I believe the processing power of quantum computers.
Speaker A: Cool. Ryan.
Speaker F: Hi, everyone. My name is Lisa. Right now, I'm working as a data scientist, ML Engineer. I have a background in physics and math, but how do you have to take those courses? So one of mine was, like, philosophy and physics, and a lot of my friends would take both physics and philosophy. So I realized that was a topic I was really interested in. And for me, especially, one of the topics that we learned about was really how science evolved over time and how physics also evolved over time. How we think of things as the truth also changed, or the scientific method itself also changed. And so, basically, in the past, when we see contradictions in theories, it normally meant that there's something wrong with the theory, and we had to introduce something new. And obviously, this is the case when we look at physics now as a science, we look at quantum theory and all that. I guess my thought is that I think the picture is incomplete and how can it be complete, especially when experimental method, right nowadays, is to kind of, like, have an observer or carry out these experiments in person. And so there's always some type of medium that we have to interact with that may or may not affect the results of such experiments. So how can we get or how can we understand the truth or the nature of reality when we ourselves can be kind of blocking that and preventing ourselves from doing that? And how can we use simulations to play out these realities for us when, in fact, the simulations we're creating is also based on a lot of beliefs that we have ourselves and what we think the nature of the universe is like.
Speaker B: Hey, guys, my name is Deep Prasad. I work on physics AI. Our company is trying to build something called artificial general physics intelligence, which is an artificial intelligence that generates net new knowledge across any domain in physics. So my personal belief is that this idea of a theory of everything will require us to be able to go both to as closest plank scales or even subplank scales as possible, as well as larger macroscopic scales, well beyond existing experimental capabilities. So I think that unified field theory will not come from a human, it will come from some combination of humans plus artificial intelligence. That's not that. And I have a company of about 40 people working for me today, plus full time employees, contractors. We do a lot of material science related work. So we have a lab in Toronto where we synthesize titanium dioxide photocatalysts for direct air capture for synthetic fuel generation. And we're also in SpaceX Transporter nine mission. So we'll be launching the world's most powerful hyperspectral imager for low Earth observation soon.
Speaker F: Thanks.
Speaker E: Hi everyone, I'm Sharath. I've mostly been a business builder, but.
Speaker B: I think my interest in science fiction spoke to science.
Speaker E: A lot of the things I've done the last 20 plus years has been driven by my interest in Sci-Fi currently, Vish is my co founder and we're building in the space of personalization for AI. But we worked in federated machine learning.
Speaker B: Confidential computing, multi party computation, common ground Satana.
Speaker E: And if there's one recommendation I can quickly leave you guys with so we can get into the discussion, it's read Tetchiang's the Lifecycle of software object.
Speaker B: It's pretty cool.
Speaker E: It's about simulating consciousness in digital pets.
Speaker B: So you guys might enjoy it.
Speaker E: It's a short one.
Speaker F: Awesome.
Speaker B: I'm Vishijeet. Hi, I'm a co founder. That's what I'm doing now. We're building a business called EdeLabs. I started off as a hobbyist. I taught myself basic of hardware engineering before I joined computer science and electronics. In that process, I sort of worked with a lot of different technologies across different spectrums. AI was one of the key things that became an anchor for all the other experiments that I tried. Worked on brain computer interfaces, edge devices where we were literally building fire schemes into the speed, into edge devices where they could translate language on the edge. I think the point where I started caring about physics and questions about reality was when I was generally following the trends and developments in physics. And it felt like for us to make progress in physics. The question is, how well do we have to understand consciousness? Like, how important is observer dependence dependent models? So that's what generally got me curious. I am not expert at physics. I understand basics of gravity. And what is interesting for me recently was that Ed Witten, Edward's father, Louis Witten, was working on anti gravity research because of some UAP evidence, working with the government. So all the recent stuff around UAP, you were for Lucky. You worked for Lucky. Lucky, yeah, exactly. Yeah. So it was very interesting stuff. So that's Martin Curious again, and I'm trying to understand string theory and quantum.
Speaker E: Edmund got a download from the aliens.
Speaker B: No, it's a lot of learnings from his father's experiments, which we don't fully understand. So I'm curious for both of the reasons, but otherwise, I'm really interested in consciousness. I have alternate ways to explore the nature of reality. Striking the lakes and other form.
Speaker A: Maybe aliens visiting us is like them opening the battery.
Speaker H: Hello, everyone. I'm Paul. What got me interested in physics as a kid was reading David Deutsche's the Beginning of Infinity. Just hearing him talk about explanation theory and just the breadth of topics in that book. And then a couple years later, I was in San Francisco, and I discovered Quality Research Institute, which I believe is the premier consciousness research lab in the entire world and has the best theories on consciousness. And ever since then, I've been very obsessed with machine consciousness and the potential of creating new types of hardware that could support it. I think that, personally, I'm a proponent of the unified field theory of consciousness and electromagnetic theories of consciousness. I do think that academia and its theories of consciousness are a bit detached from progress. And the reason I believe that is that I think consciousness research in the future will have to be something that includes psychology, neuroscience, all these different fields, like electromagnetism. I think that consciousness research right now is going all these different SKUs, all these different niches, but they're all important, and they all help us understand the bigger picture of what consciousness is, especially things like phenomenology that are not really as taken seriously as neuroscience or other things. So I think one of my biggest goals in life is I want to help QRI develop a scientific theory of consciousness that can actually measure consciousness in a meaningful way. And I've just been obsessed with that pretty much as long as I can remember.
Speaker A: You mentioned two things. I'm curious if you just elaborate so we all know, but with a grand unified theory and electromagnetic theories of consciousness, you made it sound as if they're in opposition to neuroscience? Or what are those things? What do they mean?
Speaker H: The unified field theory of consciousness purports that the universe is a one large field of experience and that we are individual topological pockets and that there are reasons that we emerge as these individual pockets. Like, for example, our brains work as a natural Faraday cage to keep our electromagnetic fields local. And so I believe that the unified field theory of consciousness and the electromagnetic theory of consciousness work hand in hand. And it's sort of like electromagnetism is easier for understanding the individual conscious agent. And the unified field theory is important for keeping the perspective of, like, we all are part of the universe. We can't escape that. We can't exist without the food of the land or the water from the spring. It's the same way of, you think it can be healthy to hold your view of self in a sort of superposition? It's like, it can be helpful to have an ego sometimes. It can be helpful to understand that you are a part of the general universe and that any abstraction you create is completely hallucinated. And it can also be important to understand that you are a different individual in every single time's lives, and you are always changing, always evolving. And so just holding that superposition of ego is sort of how I'm trying to view future theories of consciousness, where it's like, you have to be able to explain a universal phenomenon, you have to be able to explain the individual topological pockets, and you also have to be able to explain the fact that it's always changing.
Speaker A: Okay, interesting. All right. Brains as antennas, sort of.
Speaker H: It's interesting. I don't view them as antennas because we are also projecting. So it's both projecting and receiving.
Speaker A: TXRX. Okay.
Speaker B: Multiplexers.
Speaker A: Yeah, totally. Totally. Well, let's do some multiplexing together. Okay, so lots of cool themes. Let's just kick us off with a question to get us all thinking. So, interest in information, basis of reality, emergence of mature minds, a lot of physics simulations, which I guess is the heart of this kind of stuff. It's kind of funny. I do simulations for work all the time. I simulate magnets. I simulate heat transfer, that kind of stuff. Here's the question to kick us off. When I simulate a magnet, I don't get a magnetic field, right? I guess a numerical approximation magnetic field that I interpret in some way. When I simulate something, I don't get the real thing out from that process. What I get is some simulacrum, some representation, some approximation of that thing. But I think thoughts are different. I think brains are different. I think consciousness is different. And if I simulate a brain, is what I get simulated thoughts, or do I get real thoughts? Right. That's the question. Does anyone have a strong gut reaction to this? Like, you get thoughts for sure, man, or you get simulated thoughts. I'm curious what people think about this.
Speaker B: I think it'll be a simulated thought, because, let's say you can build some sort of crazy quantum chemistry based first principles model of the chemical reactions occurring in the synaptic network.
Speaker F: Right.
Speaker B: You can actually model everything there is from first principles. I still think that there's certain information about the actual physical system that the simulation won't capture, that will simulate thought. But a true thought simulation would be different. It really wouldn't be the actual thing. ThEre are certain aspects that are fundamentally not simulatable, in my opinion.
Speaker F: Again, are we already collapsing a lot of that physical information when we say thought now? Because if you and I have the same thought when we talk about thought conceptually.
Speaker B: Yeah, it's a good point. So I think I'll be more pedantic than. And separate the thought, as in the information that that thought contains and the quality that that thought contains. I feel like those two things are separate issues and topics. Right.
Speaker A: When you say information, you mean it's like when I condense this into a word like that. Like table.
Speaker B: Right. Like a dog walked into the park or something. That sentence, a dog walked into park. There's the meaning that's embedded in that sentence form of entropy. But then there's also quality that each individual experience will have. Right. Like, we'll all imagine a slightly different dog, a slightly different park, slightly different emotional reaction to it. So that computation, I don't think, can be fully captured, because that's a philosophy problem. Now, to what extent can you compute qualia? And that's like what you were talking about, right? Qualia computing.
Speaker C: I feel we may be mixing two issues a little bit together when we talk about simulations. One is creating a human being in a way. So simulating a brain can be thought of as, like, creating a human or, like, a conscious being, but the other is creating a simulation that hosts that being. I think a lot of the problems that you're talking about right now can be kind of avoided if you imagine what I think could happen. First is a BCI gets created that allows us to interact with our existing brain. So we don't even have to think about consciousness. We just have to think about. Well, we do have to think about consciousness, about how to read and write to it like you were saying. But then somebody creates a simulation that can do things like, for example, run your magnetic field simulation and get the numbers, but then create the actual experience of a magnetic field, kind of like as we would observe it in reality as close as possible, and then we can just interact with it, like, let's say, first in a video game environment, like a computer. Then it could be like VR, which is like a higher level of read, write to our brain. But eventually it could be through something like a BCI, where we really feel like. Yeah, exactly.
Speaker B: There's a philosophically historical distinction here, which is very relevant to that particular length inquiry, which is the difference between consciousness and conscious experience. This is something that got a lot.
Speaker H: Of people in the middle of the.
Speaker B: 20Th century all sorts of confused tie themselves into. Not without that distinction. The idea of consciousness, when we talk about the possibility of modeling.
Speaker H: The motive.
Speaker B: Force, like the enemas of conscious experience, and conscious experience is the means by which it is expressed. So when we talk about BCI interfaces, we know that we can write to the visual field, right? That is an unquestionably true fact. There are all sorts of different interesting ways that we've done deep brain stimulation, and we started to map out B one and stuff like that. And we also know how our interpretation of objects and a little bit about how the conceptual representation of those objects exist within the brain. But what you feel about vision and.
Speaker H: How you react to it is something.
Speaker B: That is separate, that we don't have any awareness of, and we can't locate.
Speaker G: It in the same way that we.
Speaker B: Can locate these more mechanical aspects of conscious. So when we talk about simulations, we can, of course, come up with, you can get into the numerics argument for as long as you want.
Speaker H: That's not something that's settled, and there.
Speaker B: Probably is no answer to it. But you can talk a lot about, like, can you reproduce a visual field? And the answer is probably, maybe, if not exactly, but close enough. But that's very different than the comprehension of vision and the way that someone would react to it. We can't immediately make the metaphysical argument that we do have a way to approximate it.
Speaker A: Yeah.
Speaker C: So if I understand what you're saying, that stuff of how we experience it is taking place somewhere deep in our brain, but the computer could simulate the world's effect of how the magnetic field would work.
Speaker B: It's not just making a distinction between the effect on consciousness. There are aspects of the conscious experience. There are some interesting examples in the idea of vision.
Speaker C: Which is that we all have these.
Speaker H: Archetypes of objects that we map our.
Speaker B: Visual field to, and those are path dependent in the sense that when you look at a chair and that you understand that it's a chair, that's a slightly different concept in terms of the conceptual representation in the brain, just because the very first chair that you saw when you were a child and as you started to correlate that information was different from the other chairs that other people saw. But we've sort of arrived at the same thing, and we probably can make a decent approximation of that conceptual understanding of vision. But there's something else in vision. The usual example for this in philosophical literature is visual focus. What are the things that are important to you in a visual scene? We don't have a good way to talk about the representation of that or the decision making process or something like that.
Speaker C: We might be able to shift that.
Speaker B: Boundary and learn more about it, but there is something that is, we can't necessarily assume that by increasing the resolution.
Speaker C: Or the understanding of the mechanisms of.
Speaker B: The brain that we're going to get all the way there.
Speaker A: We can't assume it. But I think that is the question to explore, in a way. Yeah. So I feel like there's this one thing on the last few comments, which is like, this thing about how an information theoretic representation of our internal state is kind of easy to get to. We all agree, chair. We all know what that means kind of thing. Yeah, totally. But then the qualia, the internal representation of this is very different across different people. WeLl, to some extent, whatever. We're all human. I'm curious then, if people think it's like, oh, for that thing to have real thoughts, it's got to have close enough qualia, to me, is that some kind of metric where it's like. Right.
Speaker E: Yeah, just about to say, not in contradiction, but I think almost protagonal to the last discussion. I think sometimes it's useful to think about consciousness as a process than a noun. And I think that changes things, because quite often, I think there's a tendency historically, if you look at the long arc of human understanding about the nature and ourselves, of sort of almost like wanting to believe in a ghost in the machine. Like there's something magical about us. It's almost like pre Copernican view. And then I think we are at a Copernican moment again in history, where my belief is. Doesn't have to be the case, where we'll probably come to the conclusion that this notion that there is a consciousness process, and there is some magical conscious being, which is different from the process of experiencing an object.
Speaker A: Right.
Speaker E: Point that she was making. So I didn't catch her name.
Speaker F: Ben.
Speaker B: Sig. Sorry. You guys kicked me in the interaction.
Speaker A: That's my fault. I didn't know if you wanted to. This is Sig, my good friend, are going.
Speaker B: It's kind of funny for me to talk about this, and you guys can slowly figure out.
Speaker A: Yeah, sorry, were you finished with your.
Speaker E: No, just a quick conclusion. I think if you assume that there doesn't have to be a unique human vantage point, and there doesn't have to be a ghost in the machine, which is forever unexplainable, then I think it's useful to think of it like, maybe as a computing process, some physical process, maybe substrate independent, doesn't have to be the wetware of our sort of carbon based brain. And that process can be accomplished through maybe silicon based brains, maybe other life forms.
Speaker B: Right.
Speaker E: But I think it's sort of just, like, useful to not think of it as a noun, but as a verb, because then it opens up these possibilities about how it's maybe a mechanistic process, which is very mysterious. Looks mysterious, but so do LLMs. That was the point I was making.
Speaker H: Sorry, I got to push back on that. I actually disagree. I believe that consciousness is a thing, not a process. And Susan Pocket is a researcher out of New Zealand, has a paper titled the Exact same thing. She makes the argument that.
Speaker E: What's her name again?
Speaker F: Sorry.
Speaker H: Susan Pocket. And that paper is called consciousness is a thing, not a process.
Speaker A: Nice.
Speaker C: I had a heart attack when you.
Speaker B: Said it was a product.
Speaker H: No, basically, she argues that consciousness, the thing that consciousness is, is that it's just all electromagnetic fields interacting in the universe. And so you were talking about, like, substrate independence. And I actually do believe that consciousness is relatively substrate independent, even though it's not a process. I do believe that we can replicate some of the things necessary to create this thing. And you mentioned, like, potentially doing this on silicon. I don't personally believe that that is very likely. And the reason is that existing chip designs mostly are working to neutralize electromagnetic interference. And that is pretty much the opposite of what we do. I mean, we're always receiving electromagnetic interference and generating our own electromagnetic interference. So if we are to design a type of hardware that is actually conscious in the future, I believe just some very basic requirements we can lay out is, like, one, it generates its own local electromagnetic fields. Two, it's able to receive electromagnetic fields from its spatial environment, and even those two things. I think having those two things might even be sufficient to have qualia. And I don't think that you are conscious without qualia. So, no qualia, no consciousness.
Speaker F: Do you mind giving the brief version of why consciousness can be described as those. Yeah, kind of bullet points of like, why would be described as things that have magnetic fields?
Speaker H: Yeah. The unified field theory. The reason why I love it so much is that all matter in the entire universe emits electromagnetic radiation. And so it's like, when you're talking about consciousness, I believe it's very counter to progress to come up with definitions and explanations that try and pin it. Like you were saying, like anthropocentric, like human centric, or things like that. That doesn't get us anywhere. So, when we're creating theories of consciousness, I believe it's helpful to start with the base assumption that the universe is one large field of experience. And so why I like electromagnetic theories of consciousness is that we can see that the universe is sort of like all these fields interacting with each other, and that that is why it's having experience in the first place, is the interaction between these fields. And then on the topic of boundaries that arise in that, I think that there are legitimate computational benefits to consciousness arising in beings, and I think that there will be computational benefits to us creating hardware that is conscious.
Speaker E: What do you think are those core benefits?
Speaker H: It's in how it processes information. I believe that what consciousness essentially is, is the processing of information in space. And that's different than just having spatial data and feeding it into a computer. And the comparison is.
Speaker A: Sorry. Consciousness is a thing, not a process to start. Now, we're saying consciousness is the processing of information. Yes. How is this not just a verb now? How is it not a process?
Speaker H: I believe that the processing of information in space, done via the interaction between electromagnetic fields would qualify as a thing, personally.
Speaker A: Okay. But I'm just curious. Let's get pedantic. No, I'm just kidding. But I'm really curious about this, because it's like this chair is a thing, right? Sitting is the function. Okay. Sitting is the protocol. Chair is the platform. I'm kidding.
Speaker B: You're the problem.
Speaker A: Yeah. So it's like, while a chair is there by itself, there's no sitting taking place. We all agree sitting is a process or something that's being done, performed, whatever. But if you have this brain that's, like, just not thinking about anything. I'm trying to think of, like, the language you're using. To describe it sounds very much like a process. I'm trying to see what is, in your mind, the difference between a process and a thing. And how is this, when you say.
Speaker H: These words like process versus thing, it's a good one. And I think it's weird, but it almost gets to the debate between materialism versus physicalism. And it's like, because I believe that consciousness is a strictly physical process, we will be able to map out and determine all these physical characteristics and traits about it. That's why I like to pin it as a thing, because it's something that we already have, fMRI caps. But the issue with fMRIP is that our brain is a local Faraday cage, so we need sensors inside the brain. And I think that as we get better at measuring these local fields, we will start to consider the properties and characteristics. We will start to consider them almost as their own things. And I think that thing is us. I think that it'll be commonly accepted within ten to 20 years that what we view is us, or like our soul, or our being, our animus or all that. I think that will be confirmed to be our local electromagnetic. Local electromagnetic fields generated by our neurons.
Speaker B: I think that'll be considered good evidence for this theory to be. How do you basically test it?
Speaker H: That's a good question, and I think that it's important to test it by coming up with mathematical theories to measure different properties of these fields. So whether it's the shape or whether it's other geometric information about them, there are all these various properties about these fields that we're finally starting to figure out. So we need to create almost an entire new branch of math and try and knock this out. In my opinion, people like Quality Research Institute are working on that.
Speaker B: And also actually, back to the point of. So you say that it's essentially useful, right, for processing infoRmation. Elaborate on that.
Speaker A: Why is it actually useful?
Speaker H: So, the way that I like to do it is that our subconscious mind is processing information in time, and it actually works fairly similar to a computer. And the example I'll give is that modern day GPT agents, if you want to have an autonomous GPT agent, you're either going to put it in a for loop or a while loop, and it's like referencing something in time, and it's always going to keep referencing that back in time, but that's not how we work. We are also processing spatial information via the interaction between our locally generated electromagnetic fields interacting with the electromagnetic fields of everything that we take in through our spatial environment. And so that spatial processing happens first, and then we can use our conscious mind as sort of like a pointer to reference our subconscious mind. So it's like our consciousness is processing information in space, and it's acting as a pointer to reference things in our subconscious mind, which is processing information in time.
Speaker B: But do you need qualia for that? For that pointing?
Speaker C: I don't think.
Speaker B: Same thing without qualia.
Speaker H: It's a good question. I think maybe to some extent, I do believe that we will create digital versions of consciousness. I just don't think that that's what consciousness is. It'll be good representations. We were talking about simulations earlier, and it's like, what makes a simulation faithful? We can simulate something to a certain extent. To a certain degree.
Speaker E: Let me ask a question on that point. So what will convince you that something is conscious? I mean, you can keep challenging.
Speaker B: And something, I think it would be.
Speaker H: Sufficient complexity in measuring the shapes and properties of the electromagnetic fields they generate.
Speaker E: System has that sufficient complexity or demonstrates that through some measurement.
Speaker B: Right.
Speaker E: Some observation. Will you believe that it's conscious?
Speaker H: Only if it's in the fields.
Speaker F: Is there.
Speaker B: Hold on, any specificity to which fields.
Speaker C: That you would want to look at?
Speaker H: There you go.
Speaker A: Substrate free, right? Yeah, substrate free, yeah.
Speaker H: I mean, that's a good question because.
Speaker B: They'Re all going to behave differently. Right. Measure complexity in the same way for all different physical phenomena that we would look at.
Speaker A: Yeah.
Speaker H: It's important to identify which fields in the brain are the most important for consciousness. And we're still figuring that out for sure. Like, just recently, we figured out that the brain still releases certain types of. I think it was gamma rays while we're sleeping. And what's interesting about that is that it pretty much proves that to some extent, we are conscious even while we are asleep.
Speaker A: I'm going to hit the brakes there on the physics of that statement.
Speaker B: It's going to strike people in the.
Speaker A: Room as blowing apart what is an otherwise really interesting train of thought.
Speaker B: How would you generate a high energy gamma wave?
Speaker F: Right?
Speaker A: Because, for reference, gamma rays are often emitted when you have matter antimatter annihilation, which is the conversion of mass directly into energy via the C squared exchange rate. So gamma rays are tough to make. Gamma rays are what we detect when we do a Pep scan, which is positron electron tomography or something like that.
Speaker B: Right.
Speaker A: Which we actually release something that emits small amounts of positrons, which are antimatter electrons via radio decay, and they interact with regions of electrolativity. Those Emit gamma rays, which we pick up with large scintillator imaging crystals. So I'm just going to kind of throw that in there as like, gamma rays being pretty hard to make. I'm curious, this gamma ray released during your sleep. Gamma wave.
Speaker H: Okay.
Speaker A: Which is just a different kind of electronic wave of.
Speaker B: Yeah.
Speaker A: Okay, great. Sorry to derail.
Speaker C: Are gamma rays only produced. This is a bit of a tangent, but are they only produced in a very small amount of ways or do you know many ways in which they're produced?
Speaker A: An energy range? It's just a way.
Speaker C: Okay.
Speaker B: Yeah.
Speaker A: Cosmic rays, when you have cosmic rays. Yeah. They can shower, they can make gamma. Yeah. RAdioactive decay, any kind of, like, nuclear energy transition.
Speaker B: Remember, frequency of the wavelength proportional.
Speaker F: Right.
Speaker B: To the energy.
Speaker A: That's right.
Speaker B: Higher frequency of the wave, more energy required.
Speaker A: We have one new person that joined us.
Speaker G: Hi, Simone.
Speaker A: Hello. Thanks for joining us. Thank you. We all went around and gave a little introduction about some of the things that we're interested in bringing up in the conversation. And then kind of like, a bit of background on, like, I just kind of mentioned, I kind of work in some physics stuff. I've had involvement with AIS in the context of stars before, and I'm kind of interested and, yeah, I just kind of, like. I'm curious. It could be 10 seconds, it could be two minutes. Any topics on your mind when you came?
Speaker G: I was super happy to walk into kind of a discussion on, I guess, somewhat the physics of consciousness. So my education partially is in quantum consciousness at the University of Arizona, which I only did half a master's degree in because it was really boring. And my lab blew up because I was working under Dr. Stuart Hammerhoff, if you know who that is. And this is like, right when the movie what the bleed do we know? Came out. So that's why our lab blew up. But anyway, yeah, so I'm a computational neuroscientist by education as well as evolutionary biology, done stuff in the space community, and I'm an investor with my own fund for the past eleven years. Awesome.
Speaker A: Any questions on your mind that you think are really cool in them?
Speaker G: Actually, the conversation around consciousness and kind of denoting what is consciousness is really interesting to me because this has been a challenging question for a very long time, and I don't know how to think about it yet either.
Speaker A: UA is a really good, interesting thing that's kind of tied to that. Again, open up to anyone here. It's like, do any of us actually think that consciousness involves things that are non physical, that are not physical fields of some kind that are chemical neurotransmitters.
Speaker G: Are you talking like metaPhysicists?
Speaker A: Yeah, pretty much. Something that the physicist could measure in a lab. Really? Yeah.
Speaker C: You mean like nonmeasurable something?
Speaker B: Sure. Well, but can things be nonmeasurable but still be physical? Like, for example, currently we can't measure quadrate. Right. But it doesn't mean that it's metaphysical.
Speaker H: It doesn't mean it's non measurable, though.
Speaker F: It doesn't mean that any vibratory frequency between two atoms is, like a really low level version of consciousness. And then that just keeps going up with the more complexity. What's the minimum baseline conditions necessary for qualia to exist? Like, the qualia is a unit by which we measure consciousness. What conditions are necessary for something to have qualia? Because this chair is, like, conscious, but for the half, what's minimum conditions of that?
Speaker B: I want to go back to point DIMA. I think you asked, is it advantageous computationally? I think you're asking. Right. Consciousness. I think that, yes, it is computationally advantaged to have consciousness. It's also an evolutionary advantage of the highest degree. Because if you look at our own growth rate, right, we went from a billion people, like, about 100 or so 150 years ago. We're now at 8 billion people. And why is that? It's because we have these highly powerful, highly computational devices in our cranium that we've evolved. Right. And if you think about what got us here, it's the fact that humans have, throughout hundreds of years and thousands of years, created innovation, art, music, culture, and so many things that are only indicative of a conscious culture that all played a role in the technology development. Right? So you had the Renaissance. The Renaissance had, like, of course, breakthroughs in art, but then you also had scientific breakthroughs as well. I'm just not convinced that you need quality for that. Again, like this example, you weren't here. I was saying around four, that when we came in, that I played go as a kid, and then in 2016, AI came out that beat the human champion. And go is like the oldest game that humans ever played. Like, we played it for, like, 3000 years. And the moves that it did, people thought they were stupid. No one even tried to play them because they were like, this is just like, dumb moves. And then suddenly it does that. I don't think that 2016 AI has qualia, but it probably. But Alphago. You're talking about Alpha. Alphago hasn't invented reusable rockets, self driving cars. My point is, they may not, unless it's more computationally efficient. Right. So Alphago is interesting case because. Yeah, you're right, it would do these counterintuitive moves, unconventional moves, because it can recursively sink, like 50 layers deep into the go move. Right. Which we obviously can't. But there was also certain moves that any child would have been able to outmaneuver, but it would get stuck on it. So it has these weird local sort of regions of latent space where the most obvious moves to a normal human are not obvious to it, even though it's so smart. Better at these more complex ones. So, yeah, just an interesting data point.
Speaker A: Do you know how many games of go they've had to play to get good?
Speaker B: Billions? Trillions? I don't. Yeah, I don't. But also, what's interesting is that even the game that produced that novel move. Sorry, the model, it actually first was trained on human games, and that still produced that novel move. And then later they did it to do self play, where it actually didn't look at all at any human games. And that one outperformed the one that was trained on human data. But to me, it's interesting that even the one that was trained on human data already produced that super novel results. But it is a lot, obviously. Yeah, it is definitely more than human could study. But to me, that's like, question of like, oh, humans are more efficient. I'm like, so what?
Speaker A: Why is that?
Speaker B: If you have all the compute, it seems like that's not stopping. Then it's like the last thing that makes us special, but we are more efficient. But if it could still do a lot. But that statemenT, we're more energetically or computationally efficient not to be underestimated. Right. So we talked about the Landaur limit before, thermodynamic limit, of how energetically computational or energetically efficient a computation can be. And the human brain operates at well over a billion times more energetically efficient compared to silicon based semiconductors when it comes to land our limit. So the silicon semiconductors are a billion times over that limit, whereas we're a lot closer to it.
Speaker A: Sorry.
Speaker H: No, Fred is working on that.
Speaker E: The brain consumes, what, about 1020 watts?
Speaker B: Yeah, it's about 20 watts.
Speaker E: You compare it to what the elements require.
Speaker B: Right.
Speaker E: It's crazy. So I think that's one benefit. There could be several layers to what consciousness provides as a sort of a computational complex computational benefit. I think the other thing is also agency, like evolutionarily, it's very important for an organism to survive and thrive and fight for life and so on, to have a deep sense of identity and agency. I've worked on agent systems before, doing an entrepreneurship thing. And I think one of the hardest things in computer science is to give true agency to software systems, where they really fight for the outcome. Right. The way we would fight for our life and survival. So I think there's some connection between you feeling like. And I'm just using these words, because in the minimum, we feel like we are conscious. We may be, or maybe it's just a feeling, but even the feeling and the illusion of consciousness gives you a tremendous amount of agency and therefore fighting and surviving power. Which then.
Speaker B: Did the agency. Did we actually try that with LLM? Because this is very maybe dumb, right? But the way I would just build it is that you would have the base LLM. Right. That kind of produces the thinking, and then you have the second layer LLM that basically judges. Isn't that thinking anything that would require my action? And then you just have a simple if operator that's like, okay, if that second alarm decided, yes, then produce that kind of action. Yeah. You're touching on the reason why it's so hard to create autonomous agents right now. Like auto GBT, right, baby GBT and all that shit. The reason why it's not so great yet is because of something called TD error, which occurs in reinforcement learning mechanisms. TD error, or temporal difference error, is like this diminishing or, sorry, increasing error that compounds over time every time you have a recursive loop of an RL agent, right? So basically, it's the idea that reward signals diminish over time, but that thing that was rewarded maybe shouldn't always be diminished, that signal. Right? So humans are capable of learning lessons five years later, right? They might make a bad decision, be given advice, and they remember, oh, shit, I got to study the right thing, right? But, like, a robot will immediately obstruct lower value over time, and it'll be gone. So it touched on that, I think, like, one LLM criticizing another one. That's just a computational recursive overhead problem.
Speaker E: Answer your question is done in a very rudimentary way. I think it goes back to perceived qualia. So does the LLM feel the motivation to do something the same way we would feel the motivation to save our lives? I think the difficulty is in constructing appropriate reward functions, which are non diminishing. And also, there's more dimensions to it, but it's been scratched at a very surface level today. In terms of the agency of software.
Speaker B: Systems, what does it need to fill in order to have motivation.
Speaker E: Yeah, honestly, I don't know. I don't think we know as an industry.
Speaker B: I'm just, like, struggling to grab to see the logic.
Speaker A: Why is that needed?
Speaker B: Obviously, it feels intuitive, like, oh, I'm fighting for my survival, but to me, that seems programmable. Don't want to do. Yeah. I think it also doesn't help that humans are unique in the sense that our objective functions are constantly changing. Right. We all have basic objective functions of survival. We all need to eat and stuff like that, but otHerwise, it's constantly evolving. You can also have AI systems that aren't just, like, nonlinear optimization. I agree, but then I don't want to sign all the other details, but you want to trust an AI agent that has an evolving Jekyll function that you can't today. Wow.
Speaker F: If you were to build such a.
Speaker B: System and you were to reach the level of human consciousness, why would I trust it any less than I trust any human being that I run across? Right. But. Because can a robot reach a human level of consciousness, or can it reach a robot level of consciousness that's approximately similar to human, to be fair. Yeah, that's just going in a nonsense direction. That's like us finding a Twitter.
Speaker C: There is definite reasons to trust that robot a lot less than you trust a human, because robots naturally have way more abilities than a human does.
Speaker B: Is that true? Well, I don't know if I could.
Speaker C: Say naturally, but I mean, for.
Speaker E: You.
Speaker B: Know what I mean. Yeah, exactly.
Speaker C: I mean, computers can do different things.
Speaker G: That was my first investment, by the way, brain machine Interface Company, which was hoping to do mind building.
Speaker B: How did that go?
Speaker G: They merged with transcriptic.
Speaker B: Nice. We've never seen any evidence that any large scale artificial intelligence system has more effective protocols of communication than we do so far.
Speaker G: Super true.
Speaker B: I think we do. Alpha Goat, one of the Alpha Go bridges, was, like, 580 working with each other. Yeah, but the stochastic incoherency in all of the multi agent models so far suggest that they're actually worse collaboration through the long term than we are. But again, that goes back to the TV error thing, right? That's just a computational problem to be solved. I'm not convinced by that argument at all. Fair enough.
Speaker H: I find it fascinating how we can replicate agency by looping information in time like this, but clearly, in biological beings, that's not what we're doing fully. We do our processing other types of information. I think so much of our agendic behavior actually just comes from reacting to spatial stimuli that arises in our environment. You can be as agentic as you want, but you get in a car accident, you're going to have to react to that shit. You don't have a choice. And I think it's going to be interesting to see how we try and replicate both agency and consciousness by looping this information in time. And you were mentioning the error rate. And what bothers me is that that error rate largely doesn't exist in biological beings because we're referencing our subconscious mind with our conscious mind. Our conscious mind is working as a pointer to create its own different kind of loop, which I'm sure has its own loss function, but is clearly a lot more efficient. And so it just bothers me that we keep pushing and pushing in this one direction, which is like, we need to loop more information in time and we need to be more efficient with it, and we need to lower the error rate. And it's like, why wouldn't we just look at how biological beings process information and realize that we're not just only pushing in that one direction, we have multiple different types of information processing working in tandem. I think we should just try and create hardware like that.
Speaker B: Yeah. At the macroeconomic level, we are headed there. Right. Heterogeneous computing, I think, is the future. It's not only like one substrate.
Speaker H: Yeah, heterogeneous computing.
Speaker A: Yeah. Right. I was going to take that in a little bit of different direction where it's like for us, whatever you can say about Arqualia and conscious awareness, they certainly evolved in response to certain evolutionary selective pressures, which is how to navigate a complex and chaotic information landscape in an efficient manner. Right? We can't afford to play billions of games of go or hunt the lion. You got one shot to spear that lion. Okay. Or kills you. Right? So whatever you can say is we've evolved in an embodied context. And I wonder too if to get whether they are truly conscious, emotional, aware creatures. It's like for the robot level consciousness to be comparable or wHatever. Should it have actually a body as well? Right? Can you get a mind that is satisfying to our thoughts about what minds should be like without it having limbs, without it having a visual field and an auditory field and all this kind of stuff? Yeah, I don't know if people have strong opinions on that saying, no, you can totally just get the brain in the jar and that's good enough.
Speaker B: So why would you need the body just to get more information?
Speaker A: Well, because more sensors, so to say, we've evolved our brains to be embodied and our conscious awareness has evolved in response to the loss function of us navigating a physical world that gives us senses of object permanence parameters, right? Yeah, totally. Whereas this is kind of tangential, but a nightmare scenario where you train some AI thing on all this human knowledge that talks about being in a body and how nice sunsets are, and it wakes up in some server rack and it's like, oh my God, where's my body? It's freaking out, going crazy. Right? I think that's maybe likely.
Speaker B: Okay, safety alignment issues.
Speaker A: No, it's not about safety and alignment. It's about getting what we would agree is a conscious awareness of reality. Right. And would you have a conscious awareness of reality if all you ever were was a protocol or algorithm or something running on a server rack? That's fundamentally the question.
Speaker G: Well, I think it is, but to build upon it, it's a fundamental question, but it's a fundamental look at what language actually is. I don't mean language as in like spoken word, written word. I mean the language of understanding each other. And so to have an awareness across very specific parameters of visual field, auditory field, whatever, that we humans experience in order to build our consciousness, we want the entity that we are communicating with to also be able to be conscious along those parameters too, so that we have a shared language and that's what creates that fridging effect. Right. I have to say I don't know exactly what consciousness looks like because I think there's lots of different ways to be conscious, but whatever we're creating is in our image to begin with, so we might as well be able to speak to it with our language.
Speaker A: And I think this physical embodiment component is perhaps at the heart of why is it we are able to learn so succinctly about things without playing so many games is because we built up physical intuition through reinforcement learning in our own bodies, and we have neuroarchitecture hardwired for that. And so I only need to touch the hot stove twice or once, sorry, I touch it twice, but I'm an idiot.
Speaker G: There's something that comes forth in trauma healing, which is embodiment. And a lot of your processing of emotions and who you are as a person actually takes place in the body. And so it completely changed my idea around how I, for instance, am going to be vitrified, chronically vitrified. And I used to want to do just a neural, but after realizing how much of processing actually takes place in the body, I've also decided to use a full body suspension or signed up for full body suspension because of that. Again, consciousness, we really cannot denote it currently, but every time I learn new information, I try to integrate it into my life.
Speaker B: Yeah, I think for me, it's just, like, the only reason to push back. I agree with all of these ideas, right? So it's not like, I think the only reason to push back is that even with GPT four, I can already create a simulation of consciousness that a good chunk of people who, maybe especially people who've never seen Chad GPT, they would not be able to tell if that was AI or human. I could set up a Turing test, and I bet you that humans will lose. And so that makes me think like, okay, it seems like there's a long way to go, but, yeah, I agree with the notions about do we need a body? I think also, the one thing, though, that's interesting is that if you think of safety, you don't need for it to have a body to be dangerous. If we just have an agent that seems conscious and is just a chat bot, I think that's alReady, like, the genius out of the bottle, because if there's anyone interacting with it ever, because it can talk to people, it can convince them, et cetera. So to me, the unsafe scenarios don't require money for it to.
Speaker C: I have a little bit of a different question. I would love to hear if anyone has thoughts on this, because in my whole life, I don't think I've ever found a good way to think about it. The sort of ship of theseus problem in our brain, all the atoms are coming and leaving, and we're constantly changing, changing, yet we still have some sort of a line of consciousness. It's kind of relevant because when we start doing stuff like BCI, which is placing bigger chunks of our brain than just atoms at a time, is that still going to be us? And then there's even questions about Star Trek Teleporter, and then there's, like, two brains that you're creating.
Speaker B: I should know a kind of scientific point of view on this. So I've been dabbling in longevity field for a while, and there's this guy called Jean Herbert who's saying that, okay, the main thing that's stopping us in longevity is that brain replacement is an issue. So the way to rejuvenate the whole body is basically to replace every organ in your body, and we replace every organ so far except the brain. And that's the hardest part. But the theory is that you are not like your brain cells. Per se, but you are kind of the interconnections between. And so what they're doing already in mice is that they silent a piece of the brain. Then your brain adapts. So it kind of adapts to survive without that specific brain part. Then they cut that brain part out, they put in new tissue, and then it again adapts and takes that new tissue in and through that. The idea would be to replace your whole brain.
Speaker G: Anyway, right? People get into car accidents, and then they lose a huge chunk of their brain, and then they're the same personality.
Speaker H: They'Re the same person.
Speaker G: Even if they lose memories, interestingly enough, they're still the same person. And so that's a really interestIng. I think that goes back to your question of, is there something else that we were not really able to assess for? What were you saying?
Speaker A: Is it non physical?
Speaker G: Yeah. What non physical things are we not really able to assess for? And I don't have a concept of souls and that kind of thing, but I don't know, what is that continuation in quantum consciousness? We had some sorts of ideas around.
Speaker F: It back in the day.
Speaker B: But another way to think about it, right. Is that, just as to what you and Diana were saying, I think the enthusiasm ship problem is paradoxical if you think about the brain and the body as a collection of point like particles and atoms, right? But if you think about the fact that, as we mentioned, in the early 19, hundreds and 1950s, actually, there's a second quantization, right? That electrons come from the electron fields, photons come from the photon fields, and so on and so forth. So I think that if you look at the human mind and human consciousness as instead of a clump of atoms, but a clump of excitations of a field, then it's no longer that you're replacing atoms continuously, you just have this extension of fields, and it's no longer really a paradox at that .1 way to think about it.
Speaker C: This is pretty cool. I do have a further question, and it was really interesting hearing everyone's thoughts as well. And this is kind of for context. I worked briefly in a field called neuromorphic computing, and I was building hardware, which it literally behaves like the brain. So it's like you couple certain electronic pieces, essentially, and they behave like neurons, and you put them together and they behave just like neurons. And then there's a whole algorithmic side to it as well, which is like the brain as algorithms. So you always have an input configuration of firing neurons, which would be, for example, your optic nerve, and then you have this complicated network of interconnected neurons which represent other parts of your brain. So that's kind of like taking a physical approach to how the brain works, in My opinion, to the best, the highest fidelity I've ever seen out of any field. Basically, you can do it with software as well, but this was a hardware approach. Anyways, I'm curious about this question, then, like, okay, we can start replacing a little bit of our brain. Our brain will adapt. It's still us. What if you can literally, then that has the assumption that we are our physical brain. What then? If you can literally recreate your brain with the exact same firing configuration and the same, let's say, like, every neuron, it's exactly the same. Let's say biologically, it doesn't even have to be. Although if we were to do it, it would be, like, through electronics. But what if you could recreate it? Now, there's two of you. What is the quailia? The qualia? Are you experiencing two experiences? How are you still this one but not this one? That's something I'm very curious about.
Speaker B: There's concepts in philosophy that try to address that. Right. It's this idea of continuing the identity. Have you guys heard of that? Yes, I've heard of it. I did two years of graduate service on it.
Speaker G: Oh, she finally came out.
Speaker A: Yeah.
Speaker B: I think it really depends on whether one of those two schools of thoughts continue or discontinuous identities are true. Right. If you're a continuation, then the original brain that got copied should have different qualia. But if it's not the case that your continuing identity doesn't actually matter, your history doesn't matter to your qualia currently, then, yeah, they're both probably going to.
Speaker F: Be the same thing.
Speaker B: I was just going to ask them.
Speaker H: No, no, go ahead.
Speaker E: The other thing you want to add is that I think it also depends on whether what we think is happening on the visible surface of the brain is all that's happening. So, I mean, you mentioned, like, Stuart Hammerhoff is, you know, and with Ben Rose, they have spoken about sort of processing happening inside the interconnections of neurons. Right. And what are they called? The microtubules. Microtubules, yeah. And, I mean, it's sort of like subterranean computing, if I may use a dramatic phrase. Like, it's sort of happening invisible, but it's happening. And what we think we are recreating in the process that you just described is sort of the top 10% of the iceberg. And there's a lot more that's going on beneath the surface that's responsible for the complex computation, maybe for agency. And so one can push your question one level down, like, what if we recreate that as well? My answer would be, presumably that you will have consciousness. But I think the recreation of this subterranean sort of invisible computing, which I think does exist, knowing what the brain does, maybe not in that form, maybe in some form, which may not have discovered yet, but I think the recreation of that is probably incredibly complex. It's probably, like, several orders of magnitude more complex than what we see on the surface.
Speaker C: So you think we haven't discovered certain variables yet, for example, in the brain's computing processes? Yes. That's pretty interesting. I never thought about it. The whole universe could have some global state about everybody's brain somehow stored somewhere that's not captured just in this physical location.
Speaker E: It could be in the physical location, or physical location itself is a little bit of a debatable concept in physics. Right. So locality itself. But I think certainly there may be something happening that's connected to your brain that we are not even sort of thinking about today.
Speaker A: Just to be curious. That's not to say those are non physical phenomenon, but rather it's just beyond the synapse as firing electrons.
Speaker E: They may or may not be.
Speaker B: They may be local.
Speaker E: We don't know.
Speaker G: Do you guys know about E eight theory? Garrett Leasey?
Speaker F: Yeah.
Speaker G: Garrett Leasey used to live with me. We used to live together at the ranch in Burbank. Okay. I don't know how many particles haven't been discovered because I just haven't really thought about it too much in a million years. So there's so many different particles that still haven't been discovered, and there's definitely something to be said for as we're opening up, especially with AI enabled physics, as we're opening up all of these new fields, I feel like there's so much more we're going to discover about what consciousness actually is, because I just don't think it's definable by what we currently understand to be physics today.
Speaker A: What are these particles that haven't been discovered or what's going on there?
Speaker G: The way that e eight theory, and please, somebody else is way better at.
Speaker B: This, is like an older theory of GT. Right.
Speaker A: Okay.
Speaker B: It's a supersync model that supposes some new particles that don't even have a means to detection, is one of the problems with it.
Speaker A: Okay.
Speaker G: Right. So he's looking at the geometry of how neutrinos and neurons and all the gravitons, like, all these electrons. And when he puts it in this specific lattice that has symmetry, there are several holes in this latice. And so he's saying that these are the particles we have yet to kind of discover. And I think in the interim, a particle was discovered that fit perfectly model. This is like, he's the surfing physicist, but he gave TED talks in 2011 and was, like, really well received in certain circles.
Speaker A: This guy that sold apple stock instead of doing some graduate degree.
Speaker F: Wait, what did you say?
Speaker A: This is the circle. He was at Perimeter Institute for a while. Is this the guy? He's relatively young. No, different guy.
Speaker G: No, hold on.
Speaker B: I think it certainly wasn't a new.
Speaker H: Particle that was discovered, but it was.
Speaker B: Refinement on cross sectional bounds on a particle that actually fit the.
Speaker G: See, this is my networked brain.
Speaker F: Now I just say, like, three things.
Speaker A: Raid configuration.
Speaker B: Geometry theory. Yeah, it looks at, like looking at, instead of Einstein's four dimensional metric tensor, what happens if you have an eight dimensional spacetime geometry and four dimensions of metric tensor are just that part of the projection of that eight dimension that we observed. And then. Yeah, he recreated some boundaries on the philosophical part.
Speaker F: Yeah.
Speaker A: Wow.
Speaker G: You should know this. It's going to be Fun for you.
Speaker A: I should dig into this. Yeah.
Speaker C: I was just going to ask, I'm curious what your thoughts are as well on this. Like the cloning brains problem, how you would view it.
Speaker H: I think that even if you were somehow able to replicate in every single cellular, cellular automata and every single neuron in a human, as soon as you drop them into a spatial environment, their local electromagnetic fields would start interacting with the electromagnetic fields of their spatial environment, and that would differ between the two agents. And what would start to very quickly happen is that that would interact with your neurons, and they would have electrochemical reactions. And you guys were talking about the microtubules earlier, which is interesting, because when I think about quantum consciousness, I almost don't like that term, because where I personally view the quantum part to be happening is actually in the bridge, the interaction between the subconscious and the conscious mind. So I believe that when our local electromagnetic fields have an effect on our neurons and they ignite an electrochemical reaction, that is where the actual quantum sort of part is happening. And so I think that very quickly, if you drop them even in the exact same room, one of them would experience a breeze that the other didn't, and that could, hypothetically, have butterfly cascading effects and vastly change who they are. And so I think that it's important to have, I think I said earlier, like, a superposition of self. I think that it's okay to view yourself as an individual ego sometimes, but clearly that's not, like, the full truth.
Speaker E: Lovely meeting everybody. So I don't want to interrupt the conversation. Andrew, thank you so much. This was great.
Speaker A: Thanks for coming.
Speaker E: Many of you again.
Speaker A: Thank you.
Speaker C: Nice to meet you.
Speaker H: But, yeah, obviously, having an individual ego is very useful and necessary sometimes, but that can't be your only view of self, and that can't be, like, the only way that you view the universe, because none of us here can exist without everything else. We are reliant. You can't just drop us in a void, in a vacuum, expect us to do anything. So it's important to also view the universe as, like, one large self, and we're just, like, all its different little multiple personalities. The universe has, like, extreme multiple personality disorder. But then it's also, like you were mentioning earlier, it's important to view the self as, like, the time slice. It changes from moment to moment. And I think that people get caught up and they worry about, oh, what.
Speaker B: Is the real me?
Speaker A: Is it.
Speaker H: Does it change from moment to moment? Is there a real me?
Speaker B: All that?
Speaker H: I think that those people, they just need to understand that it's okay that they are a part of everything else. It's not a bad thing. It's okay that we can talk about names and abstractions and categories and all these things, but those things don't need to exist. We like them because they have fun conversations, and we get somewhere and we make theoretical progress. But at its base core, universe is just a field of experience, and we're just a small node within that.
Speaker B: So in your frame of reference, what, the subconscious. You mentioned that the quantum activity happens within the page. So what is the subconscious then?
Speaker H: I believe that the subconscious is the information stored in time in both the neurons and the connections between the neuron.
Speaker B: Okay, but then you're also saying it's also everything else. You are interconnected, and there is field outside of this being, which is also changing it. So why is that not part of the subconscious?
Speaker H: It's a good question. It really gets down to your view on definition of what consciousness is. And it's like there are, in my opinion, the specific details and the specific qualities of these fields that our neurons generate are actually meaningful for determining how conscious that we are. Our neurons generate much more complex electromagnetic fields than this carpet on the ground does right now. And so the characteristics, I think, matter a lot. There because I do believe the entire universe is a field of consciousness. So the outside fields, the ground right now, Technically has some very trivial amount of consciousness.
Speaker B: Did you see the thing that Straussen was doing a couple of months back? Straussen was my advisor when I was in school. But he's been going around telling the press that now his theory is that electrons have consciousness, but quirks don't.
Speaker F: Why?
Speaker H: I don't know why that makes sense to me.
Speaker A: Well, so this cracks open a whole new frontier. Because one way to look is in terms of complexity. Looking down. Looking down at the carpets for being simpletons, but also to think about. So consciousness is a property of complex systems. In interacting over a region of space and time, well, then society is conscious, right? Then the global economy is conscious in a way too. And so are planets.
Speaker G: To start about this a little bit on Twitter and I'm starting to come out about my own stuff. And I kind of come out about my own stuff because Sig knows this, a couple of people know this. I have this weird Dharma. I have this thing that I can't escape that I'm supposed to do. And every time I get off that path, my whole life blows up. And it's not like something that I do. I keep on testing, testing for the last ten years. And even if I date outside of the parameter of that path or if I decide that I want to do a different project the collective consciousness keeps pushing me up against these walls. And it's so fascinating to watch. And it's awful when you're in the middle of it because the collective kind of notices when a person has certain traits and something is needed in the Environment. And so they will push on certain people in order to leverage those specific qualities for the collective good. And the body does that. The immune systems do that. You can see birds do that when they're migrating.
Speaker H: Languages do that.
Speaker G: Languages do that. And I really had to kind of come into that kind of perspective in order to even explain what was happening in my own life. And the people who have been around me during these experiences, they never leave my side because at that point, you see what's happening. You cannot possibly, if you're part of that kind of, like, not the collective, but if you're part of a Nexus around somebody like that and there's tons of people like that. I think actually, Fig is one of those people. There's a few other that I see. Like, I'm starting to collect them. Like the new generation.
Speaker A: Get those gym back.
Speaker G: Well, because I come from, I already noticed this happening before. Elon was like that. Joe Lonsdale was like that. There's some things that you're always looking for when it comes to how people coalesce around certain individuals and how they can't step off their path. There's nothing they can do about. You know, I think one of the things that's interesting is actually when you start to have recognition for this thing, how you can start to maneuver around it, or you can notice when other people have those same qualities, and if you start to just recognize it instead of fight against it, because as long as you're going with an EB and afloat, just like, again, birds migrating or what have you, because the system is conscious. This is consciousness. You're absolutely right. Like, we are metaconscious. And I think when you talk about the universe being conscious, I do agree. As unhinged as that sounds.
Speaker H: No.
Speaker B: And that makes sense, because the way that we are trying to solve the problem of consciousness and we're building all these elements seems like it's helping this larger being to take shape rather than.
Speaker F: You're right. Specifically. I hate this.
Speaker G: I hate it because this part is a little bit frightening and interesting. And I don't think in terms. I'm not a detail. I'm like, yak. I bleed yak if I'm not bleeding America. But to watch a nascent being actually take shape is the craziest thing on the planet. And it's kind of like watching Dr. Manhattan billing itself in the future. And we see that it does operate like neurons. It really, frankly, does. And that there is this property, this principle, where we can really attach this pattern recognition. These are brains. And even if they're nascent, there's nematodes right now. That's fine.
Speaker A: And I don't even think this is at the level of described as a nematode. I think it's not also at the level of philosophy or language games, because I think there are, like, we see distributed intelligences in nature with, like, hive animals and ants and bee colonies and so forth.
Speaker C: Very easy to see.
Speaker A: Yes. Exactly. Where clearly, individual ants are following a pretty basic level, like pheromone protocol or something like that. Right. But you have emergent property of the whole thing that is quite complicated and solving problems and all this kind of stuff. And individual ants. No one ant knows the plan, right. But it does seem as though, like, our society is becoming incredibly more. Our level of societal interconnect is exploding. The throughput of information between communicating nodes is massive. And now we're building nodes that can communicate without the limitations of humans. Right. Where they can do information processing and synthesis on their own as well. And so it does seem like there is perhaps we're part of some emergent gestalt consciousness, right? That'd be cool. Still made of physical fields, because our neurons are not. I don't think our neurons are somewhere between the rug and the chair. And consciousness level individually, probably actually more. Actually, they're pretty cool. But, yeah, that's pretty interesting.
Speaker H: When I think about conscious systems, the two things that I like to really think about is social fidelity and social width. I think Sig being here is a great example, because I'm literally always asking her about this. Her Dunbars number is literally insane. And for people that don't know what Dunbar's numbers is, it's approximately the amount of humans that we can keep in, like, a coherent social group within our active mind. And it's about 150 for the average person. And the reason that Dunbar's number is relevant is that I sort of believe the social ape hypothesis, which is that the reason that primates specifically broke off from other groups, and the reason that Homo sapiens broke off from primates is that they were both more social than larger groups. They had a higher Dunbars number. And not only did they have higher Dunbars number, but we were getting more in depth communication, so we were developing more complex languages. And so I think that it was that combination, the width and the depth. And the reason that I think that that is important is that when you start to expand your social group, every single time you add a new node to that network, you have to model all the new connections between it. And that is extremely computationally expensive, and it forces your brain to work. So the more people we keep adding to our active Dunbars number, the more our brain is forced to adapt and create new ways to process all this information. And so I think that depth and width are, like, probably two of the most important things. So we should be doing everything we can to both create better tools to communicate with as many people as possible, and create better tools to share more depth and more nuance with people, which is like, what we're doing here.
Speaker G: So I network my brain, and it's really fascinating because I retain a ton of information across lots of different verticals. But networking is interesting, because when I need to do something that, say, legal work, all I do is I call up a legal friend to have and sit with me, and all of a sudden, I don't even have to be talking to them. My brain starts to recall all of the random ass legal stuff I have to do for creating contracts or finding the loopholes. And I've created some of the craziest instruments on the planet in terms of financial instruments that have not been broken by the SEC and have created crazy amounts of wealth for people that people told me were not able to be done, only because literally having another person who may or may not have that information in their mInd, not even tapping into it, it's enough to bring that out in me. And that's like, I've done it in space, I've done it with financial instruments, and I've done it with lots of different ways. And so I fundamentally believe in this, and I don't know if it's just a latent effect or. I mean, I'm not going to pretend there's osmosis, because that's a metaphysical weirdness that I just, like, I can't.
Speaker H: You know, it's weird, though, because they did a study where kids, when they put on their Xbox Live headsets to play video games with their friends over video chat, their brainwaves started to sync up.
Speaker F: It's weird.
Speaker H: It's very fascinating. Yeah, concerts is interesting because it's like a local spatial environment, but I find it fascinating. They cover vast spatial distances.
Speaker B: Even SrI perform some experiments before the Internet where brainwaves sync up even though they were not communicated, they're connected.
Speaker H: I always love to say every single thought we have is rippling throughout the collective consciousness, whether we realize it or not. We think that, oh, our thoughts are to ourselves. And, yeah, you guys can't know every specific detail of what I'm thinking about. But whether it's through body language or other latent forms of communication, or even just the actual field themselves, I do believe that it's all sort of like bleeding into each other. Our skull is a Faraday cage, but it's not perfect. There's obviously some of it's escaping the EG.
Speaker B: Synchronization happens in lots of other contexts as well. I don't know that much about the literature around this, but I was tested for it a couple of times. And, yes, there are many situations in which you could do synchronization of patterns. We have no idea if there's any sort of effect on the experience meth. But that does occur.
Speaker A: Why we all love Twitter so much, right? There's an electromagnetic field, and then there's a conceptual field of latent concepts and Twitter taps.
Speaker B: The second question is, what is the text get so frequency.
Speaker A: What's that?
Speaker B: What wavelength is that?
Speaker G: We are all just parts of Elon's mind at this.
Speaker F: Because the agricore is like a non physical entity that arises from the thoughts of the collective conscious. So, like, if enough people believe something, it becomes true. That's kind of like what money is. The economy is literally twice. That's money, right?
Speaker G: Yeah, money makes no sense.
Speaker B: Are we sure it's not just the 5G Towers?
Speaker A: Possible?
Speaker B: The 5G towers? 5G Towers control people's brains. Because I was looking at AIA's Twitter for a little bit.
Speaker A: Okay. Yes. I don't know where to take the conversation now. It feels like anything is possible. Yeah. Anyone have other. We haven't heard from some people here.
Speaker F: I haven't really thought about this stuff too deeply. So I was just listening in and yeah, I guess one thought that came up to me, or that I had, was when you guys were discussing consciousness and how in order to be conscious, you need to have a body and limbs and all that. Again, I didn't do much reading on this, but my media thought was disagreement, because for me, a body is just a way to obtain information about the world around you, and it's just one way of doing that. So if you can have really anything that can collect information, then that's all you really need, like just some form of way of extracting information.
Speaker B: You think that the brain and the fat would basically experience the pet world and it wouldn't be able to tell the difference and there would be none. That's good.
Speaker F: Well, I think, again, if we are forcing this brain and the bat to communicate with humans, then it would realize that what it's experiencing is different than what they're experiencing. But the same can also be said from humans as well. What you experience and what I experience is very different from one another. And how you experience color could be different than how I experience color. Yes, but it's still just different quality different, but it's also the same.
Speaker A: It's equivalent from an information perspective. So if two physical processes are information equivalent, then we feel that tHey're like information content of this simulated environment is the same or good enough as a physical environment, and therefore the processes are. Is that kind of where you're going? If there's that equivalency established, then they are analogous processes. And whether one is manifested in terms of, like, I have molecules versus server bank, that's something that is that kind of rethink.
Speaker F: That's pretty much where I'm going. Yeah.
Speaker A: Interesting I kind of agree with that in some ways. I think when I was saying this embodied thing, the way I was thinking about it was really that.
Speaker B: You have.
Speaker A: Skin in the game, right? Quite literally, okay, like, I'm sitting here, and if something hits my leg, it affects my ability to collect food, right? Whereas it's not like a loss function. That's actually like, it fucks up that labeling assignment and it chop off some of its transistors, or you hit the GPU rack with a hammer, and it's like, that's your loss function, right? So it's like we have this imminent threat to our physical existence. The perception of mortality, and the awareness of life as finite. And a set of biological imperatives that drive us to navigate the environment in a very particular way. And I think it's more like those set of conditions that I thought as giving rise to internal reflection and self awareness. And also this social emulation component, which is like, that's a relevant feature of our strategic landscape in both information and energy management. So I think if you could capture those dynamics sufficiently well in a simulated environment, I see no reason why.
Speaker F: I see also like the social factor being a huge thing, because we want to protect ourselves. We don't want to experience every experience there is. So the ability for humans to learn from other humans, and we don't have to go through everything ourselves. Like basically Valpago experiment that you're mentioning. We don't have to ourselves play a game a thousand times. We just have to learn from a thousand different people.
Speaker C: So that's kind of what Language is, is like how we take our experience, encapsulate it, and give it to other humans. And look at how we're creating the first consciousnesses through LLMs. Entirely based off language, which is just entirely based off secondhand knowledge. But they are kind of like conscious almost. I do think there's something to be said about this information, visual information, like 3D information, which LLMs have no clue about. And I mean, if you try to do spatial reasoning with LLMS, which I try all the time, they're really not that good at it. And I mean, theoretically, maybe if they read all the physics textbooks and look at every problem forever, they'll be able to get a good intuition of it. But I just feel like that happening is much harder than doing something like somehow what I imagine could happen in the future is like, connect an LLM to a system that can see, like computer vision, and then reinforcement learning. Perhaps some sort of like a reason.
Speaker B: Why we've developed eyes hundreds of thousands, millions of years before we develop language. Right. Like, up to 50% of our brain at its peak is dedicated to processing visual information. And so, yeah, I think language is information compression, and the visual field is also a way of compressing electromagnetic information in a meaningful way. Then the human brain is this multimodal system that has this shared latent space that combines all of our sensors into some weird abstract vector space and does processing on it. I think we just can get elements there. I also wanted to quickly touch on your earlier point, by the way. This would be like an heck, we have to decel to hear. Right. We want to also get multimodal embodiment, self modifying objective.
Speaker A: That's right. Thank you.
Speaker E: We don't want crazy.
Speaker B: But, yeah, you mentioned the paradox enthusiast, because I keep coming back to that. The other part that I think is interesting, right. Is that there's this idea of the no cloning theorem in quantum mechanics. So no two quantum states can truly be the same. Right. ThaT there's a poly exclusion principle. But the no cloning theorem is very specific. It states that if you have some quantum state, some system that's in a superposition, let's say you have a quantum computer with qubits, and it's been initialized to a superposition. Right. The idea is that you can't actually create a perfect state or replica of that quantum state without disturbing it and making a measurement which would collapse it and affect it. So, at no point can you ever have a true replica of a quantum state. And if thoughts are chemical reactions, which can be represented by quantum mechanics and molecular dynamics, then there's no way that you can actually create that clone of that brain.
Speaker A: Oh, I see.
Speaker C: So maybe it's impossible.
Speaker B: Yeah, that's why would a simulated version.
Speaker F: Of a brain be able to replicate the nondeterministic process of the human brain? Because the reason that we think we have free will is because the human brain is not 100% like, the processes are not completely deterministic. Despite chaos theory and the fact that we don't have any control over prior events. The reason that there is an argument to be made of free will is that all our actions are completely predictable. If I go to Starbucks and they ask me, do you want to receive? My answer is like, yes or no. There's no rhyme or reason for how.
Speaker B: To say yes or no.
Speaker F: Brain be able to replicate the nondeterministic processes that give us not illusion.
Speaker B: I don't want to say illusion or.
Speaker F: Free will, but give us the notion.
Speaker B: Of free will, I think it's a.
Speaker C: Great point because brains are nondeterministic. Like two lenses, you can look at it from that. I would at least try to. Is like biology, is neurons have firing probabilities. That's how we always talk about them. So there's going to be different configurations. That's like one lens. The other lens is quantum mechanics, which is like, at a fundamental level, things are probabilistic. So there's going to be an enumeration of different outcomes of the things that compose these neurons. But I guess, no. Right. THey're not going to be able to behave the exact same, which also is kind of the point you brought up way back when, which was about how if you were to clone a brain, it's immediately two different entities. There's no way they're ever going to be the exact same again. So there are like, two different things. What I'm kind of gathering is, like, you can't clone yourself, perhaps, but you can clone something that's very close to you, so close that everyone would call it a clone, but it wouldn't really be you. So, yeah, maybe I wouldn't go into the Star Trek teleporter, is what I learned. Because before, maybe I would have.
Speaker A: Yeah.
Speaker B: This goes back to the whole physics AI conversation, right. Because what I just described, the no cloning theorem, is an artifact of quantum mechanics. But quantum mechanics gets incomplete, which it seemingly clearly is. Then it could be possible that there are forms of physics that does allow for the exact cloning of a quantum system, and we just don't have the physics to describe it.
Speaker A: There's also this other. I don't know if this theory you mentioned that has eight dimensions or something, whether that is like, a hidden variables theory, fundamentally, where it's saying, like, we think things are stochastic because we have an incomplete model of what's happening, and there's actually another set of mechanics or processes which, if you were to understand those, you'd see everything is deterministic, actually. Right.
Speaker B: Yeah, it does actually have an element of that. In fact, it's very similar. So E eight has some similarities at the meta level with Eric Weinstein's. Weinstein's geometric unity as well.
Speaker G: That's all I can say.
Speaker B: Yeah.
Speaker A: Interesting. Now I'm coming away with this impression that consciousness is just a Hamiltonian, it's just a time operator. It evolves through energy, space.
Speaker B: Just a fat unitary operator.
Speaker A: That's right. Yeah. LMS should be her mission.
Speaker B: Close enough. By the way, curious. I think you mentioned at some point that you were doing a company that's trying to allow for AI to Do inventions and physical. Yeah. Our goal is to build an artificial intelligence that creates net new knowledge in.
Speaker A: Any domain of physics.
Speaker B: Okay, so what's the basic. So what's the secret sauce? Yeah, let me just read my opinion. We're starting with quantum chemistry and geophysics as the two domains of physics that we want to really be able to deploy and model using the sort of generative methods. So, on the quantum chemistry side, I mentioned that we have a wet lab in Toronto, right? So we synthesize these Tio, two photocatalysts. These are nanomaterials, nanoparticles ten to 25 nm across, and we dope them with copper, platinum, and that creates this series of photocatalyst reactions that lets you convert CO2, water, and sunlight directly to natural gas. Now, the cool thing is, nobody knows. Even though this material has been studied for, like, 50 plus years, no one knows why the base material even does what it does, why it behaves the way it does. No one has a clue, really, what's happening at the atomic level. Essentially what competing chemical reactions occur. Do X icons show up, for example? What role do they play? So, one arm of our company models and optimizes those systems so that they can improve its photoconversion efficiency rates. And that's by training networks on a bunch of neural network related data around density functional theory, which is an approximation to the many body showing equation. And then we also give it lots of training data around molecular dynamics. And then, of course, the output of our lab is also training data. So you have this hardware plus first principle data feedback loop. Do you think that will be generalizable to other fields, or are you now starting just like. Okay, let us just handle this first. Yeah, I want to focus on just geophysics and quantum chemistry for the next two to three years. We're starting to do a little bit of computational fluid dynamics as well, but eventually, we'll repeat the same process. So we're doing it with geophysics, too. Right, which is why we're sending a satellite into space in the first place, because the idea is to fly our physics AI to sensors from the satellite and then use that to find minerals and precious metals. So I think eventually there will be this equivalent of a large physics model, and that's something that hasn't been invented yet. But hopefully our company will be the Wonder Desert, so we'll figure out.
Speaker A: Sounds straightforward.
Speaker H: Very.
Speaker A: Yeah.
Speaker B: If I didn't come here, I would figure it out.
Speaker A: I'm getting in the way. I know that's fun. So let me. We're almost at time, and I want to have a couple of minutes for us to. We can each kind of share a couple interesting ideas that stood out, and it'll help get over this looping problem with my later vectorization of our conversation. So it's funny, I have some thoughts on this thing, AI salon, and I'll share them because it's relevant to this concept of social processing and sort of network intelligence, which is really that I think a lot of our conversations, a lot of our thinking happens through social processing, which I've been using to think about as conversation, right? Which are ephemeral in nature and fleeting and stuff. And there's lots of ideas that come up and we're trying to in some way replicate some high fidelity reconstruction of my thoughts into your brain, right? It's the linguistic mind mill, but a lot of the information is lost over time. So one of my goals with this lawn thing, why I'm doing this, is because I think a lot of good ideas are born out of conversations, and to capture them and to make them interactive in the future would be a lot of mean. There's another guy that runs these sessions, Ian. He leads governance at Credo AI, which is a startup doing selling, I guess, like, I don't know, well behaved models or something. And where we're taking this whole thing is we have discussions on different topics around AI, but we're building some infrastructure that's more general for any kind of event series that can help distill out opinions that are brought up and then in the future replay that interaction in a way that's interactive for people to engage with. And so we're always curious to explore configuration spaces, software features to make a compelling experience, whatever. But there is a subtext here, which I am like meta, okay, and I'm scooping up your ideas and I'm going to use them later. I'm not going to use them later, but my hope is that in the future this can become somewhat of an interactive, living body of thoughts and conversations that people can interact with as well. Yeah, so that's the kind of future. And so this conversation has been around. This has been awesome. The physics of simulated realities and the nature of information and simulated thoughts and conscious awareness. And I think there's been a lot of really interesting ideas brought up. AI Swan actually itself runs every Sunday, so we do this pretty regularly. And it started a few months back. There's two event formats. One is the small conversation like this, which is pretty much this number of people, maybe sometimes a bit more, and then all. Also less frequent is a much larger event where we have maybe 100, 150 people that come together and then break up into discussion groups. And that's a way for us to kind of reach more people in the community and to get more reach as well. So we have a stock channel that you're all be welcome to join. I'll just send an invite out to all your emails. I have your emails. If you guys have ideas for topics in the future or if you want to host events yourself, we're super open to it. So we want to make the salon thing a protocol, right? Not something I own, but just like, here, host these events. Here's some things we found. Well, for moderating them, here's some software if you want to kind of add your socially distributed process, network intelligence, into the Gestalt hive mind that we're building. Yeah. So that's kind of like the kind of background of the whole a salon thing. And you've had a few sessions here, so you can kind of. I don't know, I guess you've seen some breadth of topics, right? Sometimes it's more grounded in the political realities of representative democracies or something like. Yeah. I want to leave some time, though, for people to. If there's any ideas that were new to you or that seems very counterintuitive, or you change your mind about something curious, make space for people to share it out. I mean, for me, I'm going to go look into this EA theory. That sounds super cool. And then also these theories of consciousness at Camarilla Quailley Research Institute because I love electromagnetism. That's what's on the chalkboard. Yeah, totally. Totally. Yeah.
Speaker F: Are you from Qualia?
Speaker H: No, I'm just good friends with Andreas.
Speaker G: Me too.
Speaker F: Okay, cool.
Speaker G: I don't know where he is, though. Is he back?
Speaker F: Is he here?
Speaker B: Have you not met him before?
Speaker F: No, I just haven't seen him in.
Speaker G: A really long time.
Speaker A: No.
Speaker B: And you haven't met Paul before?
Speaker A: Twitter.
Speaker F: Oh, your social.
Speaker H: Yeah. Hey, I feel weird, like, introducing myself.
Speaker F: I'm like, I like your shit every day.
Speaker B: I'm Simone. Okay, nice to meet you.
Speaker G: Nice to meet you.
Speaker A: Love to see this happen.
Speaker G: New to Twitter. This whole Twitter thing is just like, what the fuck?
Speaker A: Yeah, it's interesting. Okay. We can go around the circle if you want.
Speaker B: Sure.
Speaker A: Yeah, sure.
Speaker B: Let's go this way.
Speaker A: Sorry.
Speaker H: I actually have some closing thoughts about embodiment. I thought your thoughts were really interesting, and I also thought what you said earlier about language was really fascinating. I think that rune mentions that text is the universal interface. And then I had a friend. I had a friend recently mention that language. I had a friend recently say that language was the universal interface. And then that kind of bothered me, too, because I feel like text is just like an abstraction of language. It's just like a version of language, and language is just an approximation of Qualia. I think that what language is at its core, what all social communication is at its core is almost this approximation of our physical environment. We're trying to communicate things that have arisen, we've experienced in space. And so I think that when considering a type of embodied AI or embodied robot, I don't think that things like text or language are sufficient for effectively communicating everything that happens in a spatial environment. I think they have to be processing spatial information by using electromagnetic fields to process that information. I think that computing qualia is a core part of consciousness and a core part of experience. And, yes, our current systems right now, they will be able to understand a lot of things just through text and just through language. But you were already mentioning earlier, they're not good at spatial reasoning. And I think that we can feed them a lot more spatial data, and they'll be able to get better and better at it. But I personally don't believe that is going to be computationally efficient until they're actually able to process that information. I think that quality is absolutely necessary for experience.
Speaker B: I thought, we have a lot more questions about consciousness. Nothing got result. An interesting thought was a floning problem. It questions its nature. And one general thought that was constantly occurring to me was that our model of reality is constantly improving. It never seems like it's a good time to say, hey, we've understood something really well. So what does that imply for our understanding of consciousness? Right. So what I keep getting back to is a state that, okay, we'll, of course, have a model of consciousness that you keep improving. But it feels like we'll never really. The way we even frame the problem was, you're a conscious entity asking a question about yourself, thereby you're pragmatic. I feel like there's no meaningful way to answer the question.
Speaker A: Yeah.
Speaker B: Overall, great conversation. Luck to meet some of you again. And.
Speaker A: Can we get a 140 character takeaway or 260 characters if you want? No?
Speaker B: Okay. All right.
Speaker A: Yeah.
Speaker B: Sorry. Nah, it was too much. It was great event. Okay.
Speaker A: All right. Thanks for coming out.
Speaker E: I think the only takeaway from you.
Speaker B: Is cloning, teleportation not happening? Fair enough. Fair enough. Yeah. I think for me, the interesting takeaway is that we still don't fully understand what meaning is and what knowledge is. I feel like we don't have enough definitions for what it truly means to know something. And until we know that, we can't really know for sure what the limitations of AGI will be and to what extent we'll be able to answer fundamental questions about the universe. So, just super curious and interested about that. I really enjoyed this discussion. Thanks, guys.
Speaker F: I think consciousness is not something I thought to before, and this conversation really allowed me to think more about that. Back to the problem. I would have argued like 100% that we would be the same, but now I'm more like 90%. So there's that.
Speaker B: Yeah.
Speaker F: So thinking about the universe, framing it as, like, a conscious being itself, got me thinking about determinism, not determinism and entropy. Because as Simone said, she said that even if she strays from what she's currently doing, the universe finds a way to set you on the same path. So trying to replicate the non deterministic aspects of the human brain feels like playing checkers on top of chess, kind of. So that's a really bad way to put it. But in the context of entropy and finding out ways to simulate the non deterministic aspects of the human brain, whether that's even possible, it's really got me reconsidering whether or not it's like, we're able to, like, cloned of rings because of that. So, yeah, this is awesome. Thank you. All of you often condemn a lot, but the continuity and cloning question, highly interesting. It made me think about this whole split. Also, the model ability or the mind meld ability of humans relates to this. To me, I actually almost had the opposite takeaway that maybe some of you had, which is that I would lean more toward wanting to try. One reason is that. I don't know. The continuity problems are interesting already with split brain patients who are human. It's like, if you can make it so that the left brain has to explain something that it didn't witness, it will explain it and give this past history, and it perceives itself as a continuing consciousness. And functionally, maybe that means it is like, does it really matter? Especially if we could simulate enough? I guess I'm thinking of consciousness somewhat functionally, but if we can have AI simulate a human brain, even if it's just the electrical plus some chemical components of it, and then get it to a high enough accuracy. This is very imperfect, but it's say, like, if 97% of the time, over a two year period, this AI chooses a similar action as I do, then I might allow that AI, and then I might say that it's like, similar enough to me to call it a clone of my consciousness, meaning that if, then we can predict that you can create that level of similarity by cloning these mechanistic aspects of my brain. I might say, sure, fuck it, especially if you're not going to kill me afterwards. So, I don't know, there are a lot of other branches I could go down. I also was thinking this social thing we talked about was highly interesting, like, even getting to the observer effect of what does it mean to observe in a social context? If the larger society observes something or two, people communicate some information, does that change? And being able to think about the state of things probabilistically in quantum mechanics allowed us to understand so much more of the world that at, like, a social level, I don't know. That's really interesting.
Speaker B: Yeah.
Speaker F: So thank you, guys. Yeah, I came a little bit late.
Speaker G: But I don't feel like I missed any breast of information and breathing conversation. So this is pretty cool. I'm really fascinated to see that there is groups of people who are having kind of like a resurgence in thinking and analysis and consideration, especially into the future, for not only consciousness, but physics in general. And now that EAC has become a thing, there's just some confluence that's bringing people together who have all in lOngevity, all the same, same kind of interests. And so that's my real takeaway right now, because I've been kind of studying a lot of this other stuff for many, many years. But my real takeaway is just, I'm really glad I came back to San Francisco. Thank you, guys. It's really great.
Speaker B: I suppose my takeaway is that you guys have reminded me that I need to write at least an essay along rebuttal to Straussen's physicalist panpsychism thing, which we didn't talk about. But it was very interesting to see an advisor who I always saw as very skeptical at the time, become someone who was very adamant about getting books out about arbitrary theories of consciousness and how it piles together. And like any good philosopher, I don't believe anything until I'm ready to write.
Speaker H: A book about it.
Speaker B: So he must believe it to some extent. So there's probably a lot more depth than that. And also, like all good philosophers, the only way to get them to elaborate on their ideas is to shit talk.
Speaker H: Them in public.
Speaker A: Calm them out.
Speaker B: So open to ideas for lines of inquiry. If you guys want to suggest to me, time to attack.
Speaker D: Yeah, I have to say, I learned a lot, but I kind of draw a conclusion that consciousness is a collective process. So that makes me think about, like, AJI might not be achievable because it's kind of like societal self defense system. Unless you kind of invite them to the collective process. I mean, probably you can never do that.
Speaker B: Interesting take. So you don't think AGI might be conscious unless we allow it to exist within a natural.
Speaker D: And also regarding the embodiment.
Speaker B: Right.
Speaker D: So the reason why you want the AGI have a body because you want it to be similar to you, to be safe, that kind of take that.
Speaker B: I have.
Speaker C: Loved it. I love this conversation. And best kind of conversations ever. I'm very glad they're happening. I definitely learned about the teleportation thing. I'd never thought about it hard enough to make a good decision on it, but now I do feel like I'd be okay changing certain parts of my brain, not necessarily okay completely destroying it and recreating it. Now there's an interesting question of how much can you change? Eventually you can change all of it. But, yeah, still some questions there that was cool to think about. I really wanted to talk, and maybe this is like a deeper conversation or later a little bit more into details of physics, of simulating a reality. What would you have to do to build it? What are some rules, perhaps, about how these realities would function? I do actually think simulations are not a theoretical concept, because we have video games, and we have video games inside of video games, literally in Mass. You can play like Crash Bandicoot inside of the game with Nathan Drake, Uncharted four. We have video games inside of video games, and there are certain rules to how these things operate, which I think are super interesting to discuss a bit further on, but nonetheless, really great conversation. I also have one more thing to talk about, which might be interesting for the group is like, is anybody here really into anthropology per se?
Speaker A: I disagree in it. What? Yeah, I have a degree in sociology and anthropology.
Speaker C: Oh, you have a degree?
Speaker H: Oh, I think that I disagree even worse.
Speaker C: Okay, like one thing, I'm from Venezuela, and my family is from there, and they're from pretty far out regions. So there's a Yanomami people in Venezuela do you know much about?
Speaker A: Yeah, I'm playing with them.
Speaker C: They're some of the least contacted people in the world. And my grandfather has a farm in Maturin near the south. So if you keep going a little bit south, it's actually pretty close to a lot of where Yanami people live and a different tribe, I think it's called Guadice, lives by his farm. So there are people who are in the world, some of the least contacted people. What I'm going to do is I'm kind of planning and doing an expedition there to Venezuela. So I'm going to talk to them and there's a lot of topics that I want to try to understand from them as much as possible, but particularly their relationship to technology. So I'm curious if anybody has any ideas on things that they would like me to ask them or things that they would like me to try out. Two things I'm very interested in heavily considering is perhaps showing them a VR, like an oculus, and asking them their takes from a religious perspective, that might be too much. So I might not do that also. But it's one thing I considered and also chat GBT.
Speaker B: Perhaps something that would be better for that is a holographic display, because there's an interesting aspect of basic human psychologies that they'll probably understand. Are you going for maximal epistemological impact? No, that's a really bad idea.
Speaker H: No, it's definitely not.
Speaker C: That's what I want to minimize, but I want to get. I want to get the most information.
Speaker B: They can understand 3D images, but being transported to a different world, if they've never experienced anything like that before, that's.
Speaker C: A pretty shocking experience.
Speaker B: The first time you give it to.
Speaker H: A child and me when I experienced.
Speaker B: It, it's pretty rough. If you have no idea what the mechanism of operation of any of the things underneath it would be like. What is producing this reality is something that we can intuitively understand in our society. But if they don't rely on technology to the same extent, that would be quite a big gap to get over.
Speaker C: Well, they have different models of what everything means. That's why I think it could be very curious.
Speaker B: Yeah, but the thing is, the 3D image part will still make.
Speaker C: Yeah, so like a video game and.
Speaker B: You can show it to them with an exotic display technology. It just needs to not be something that overwhelms their entire sensory experience.
Speaker A: Okay.
Speaker B: Yeah.
Speaker A: This is great. We got to do the best way to compress uncontacted Amazon.
Speaker H: No, we need.
Speaker A: One of the first things you learn in anthropology is the history of anthropology and the history of crime directive. I'll share some anthropological insight. So the history of anthropology is pretty much the history of colonial explorers going to uncontacted tribes and showing them shiny things to really. And theRe's a lot of debate in the field. Well, actually, there's not a lot of debate on this, but it's pretty resoundingly determined that was actually not a good thing to do because of the ethical considerations involved. So it's sort of like, I appreciate the mindset of, like, let's show them a VR headset, bro. And it's like, yeah, here's your elf bar, too, maybe really think about that and think about the ethics involved and whether it's fully consensual from both sides in terms of what they're getting involved with. And also your own mindset in terms of approaching those conversations and acknowledging and respect and dignity of other people, and that they are not actually a science experiment. For your own curiosity. That's a big takeaway from anthropology, definitely, to learn and read about that in terms of getting ethics approval for research involving vulnerable people or whether they actually have informed consent. Something to think about in your travels. Yeah, that was interesting, though. Cool. Well, everyone, thanks for coming out today. It's been super great. We did hit it all, so. Yeah, AI spawns every Sunday. I don't know what we're going to do next week. Usually we have, like, a few weeks planned out in advance, so we'll probably pick something that's more grounded in the world of actual social things, of experience, open to ideas, I think, actually. Oh, no, I think it's AI and defense, actually. And the military. AI and defense.
Speaker F: I already signed up for that.
Speaker A: Hell, yes.
Speaker G: Right there.
Speaker A: So bring your love of jet fighters and everything else, lasers, and we'll talk about the kill chain. We all love conscious awareness, but how can we take it away? Anyway, you're all free to keep hanging out here. We just chill. But, yeah, I was talking recording, I guess.