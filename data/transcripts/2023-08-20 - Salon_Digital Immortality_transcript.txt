Speaker A: Just start the recording. And I was thinking that at the start, we could all go around and say something about our background and our interest in the topic of digital immortality. And I'll start. My name is Fartain. I'm doing a PhD in anthropology at the University of Bergen in Norway. And part of that project is actually looking at how people are relating to AI large language models. And at the beginning, I was really interested in how this was going to change the way people remember people have passed away. It's looking into how it will affect mortuary practices and funerary rights and so on. And that ties into the whole digital immortality aspect of it, because the way I see it, there's really like two strands we can go down. We could go down the whole immortality path where it's a question of uploading consciousness and it being you. Right. Or we could go down what I would call like, digital afterlife path. Right. Which is more of something you leave behind a legacy. And we already have that to some degree. You have, like, digital legacies and digital afterlives in the form of Facebook memorials and stuff like that. So making a chat bar could just be a more interactive version of that. So, yeah, that's my kind of into this topic, and I'll pass it along this way.
Speaker B: Do you mind going that way?
Speaker A: Okay, we'll pass.
Speaker C: My name is Anastasia. Nice to see you in San Francisco. It's been four months of it here, but just working from home on my startup. Sounds quite familiar. Yeah. So I'm developing data science tool for making astronauts more efficient in space, have an airspace, hardware ground. I'm not necessarily the most knowledgeable person about AI, but I'm really curious about and exploring. That's been pretty much how I entered space industries that kind of made sense to expand our consciousness in the stars. The reason why I'm working, what I'm working on is to preserve human culture. I really love design and also an artist in the house. I love culture, humanity, and I think it's something really beautiful about it. I'm biased because I'm human, okay? But I would like to have the opportunity for us to have someone living in some other plan. Because our planet is fragile, something can happen. There's many risks, including AI. So having someone out there, maybe in the shape of consciousness or in the shape of human flesh, that's something that really inspires me. It's something that educates my life to putting people to space. And one of the things is making humans autonomous and making decisions in space and extreme environments. So that's my story, I guess.
Speaker D: Hey, I'm Kevin, founder of Open Souls. So there are a lot of different versions of the future that we might have with AI. And most of them, I think we've been hybrid right now. And something like a cyberpunk future or something that's kind of dystopian. And we don't really have a great path forward to that place where we actually have a problem with AI. And so that's when my company's building work is able to achieve that by giving AI and digital team and then my actual relationship with immortality is I made a digital version of myself a while back and gave all my friends and we had all sorts of weird interactions where even though they knew the digital version of myself, the stuff was saying, I still internalized it as me saying it. And then I got an argument with myself about that. Myself eventually told me that I'd be terminated. I'm not super excited, actually, about digital immortality personally. That's where I am on that. You committed digital suicide?
Speaker B: I did, actually.
Speaker D: No way.
Speaker E: Hi, I'm Dua. I'm not in tech. I'm a doctor. But I'm really interested in the topic on human society and also, I think, essentially profound implications on human existence and ideas around mortality, which are obviously things.
Speaker F: That I.
Speaker D: My name is Ari. I'm a simulation artist and engineer. I have a artist studio called Delta Arc Studios. I also run a lab at Gray Area on AI and behavior. In terms of digital immortality, the two things that you brought up our time making human beings digitally immortal hot take is yes, please. And then the other one is like, memorials like Facebook. And my in into that conversation is just that I would like to own my own. Yeah, nice. I'm Andrew. Yeah, I'm like an engineer, and I've played with AI tools in the context of I was in. Curious about the space. Yeah, see, the path plays sociology, so humanities minded. So digital immortality is really interesting. I've kind of had a long standing belief that we've always been grasping for signs of immortality through the invention of things like writing that allow a person's thought to exist beyond. I think this is, like an interesting extension of that. And there's also this bigger question, not just of immortali memorializing someone, but also, like, can you have a persistent conscious awareness that exists into the future too? And is there a continuity in that? I think it's really interesting. I think it's a big question of do machines experience anything more? I'm saying, nice meeting you. Where do I start? I think my interest in this topic started with this proposal. So I was in academia before, and this proposal misorbly failed multiple times about how can you so I was in the research field of human computer integration, kind of extension of human computer interaction and trying to see can you create computer systems that can learn about you and replicate your skills and styles and be an extension to you more in the context of if you're artist, like losing your dying and so on. So you're really caring about, as a living being, what kind of technological augmentation could fit me in terms of creative expression? But last week, we had a really interesting conversation preserved in some form, like after we die, it's transferred to a different.
Speaker B: I'm Ellie, so I'm a strategy working on digital projects for a consulting company. So I basically work from home and nothing to do after work because I work remotely from The New York Times. So usually after 03:00 p.m.. So it's kind of like my time to think about if it's anything that I can do. And then, by the way, it's my husband. So we think about, can we create something that copy people that conscious to the digital world? And also my grandma is quite old. She's in Taiwan, so she has the brain tumor now. She's 80 something. So I asked him, can we sort of pronounce get the data from her every day to sort of create each conversion of her once she's dying or getting off? Can we know what she wants, what she wants to plan her after, something like that? I'm just here to listen and listen.
Speaker D: Yeah, it's actually a great contest because we both lost somebody we care in the last three years, and it was kind of a transformative experience in a way. So we are kind of very lightly thinking, what can we do with it? Is it the right thing to do? It's a good question.
Speaker A: It's one that I think we'll have to be grappling with in the near future, if not now.
Speaker G: Hey, everyone, I'm sharath. This is my second AIS alone, and I'm building in the world of making the experience with the Internet for consumers more personal. And a lot of that has to do with trying to figure out creating a digital twin in some form. I'm also a huge Sci-Fi buff, so a lot that I probably will bring to the table is just suggesting very interested in this.
Speaker A: Cool.
Speaker H: Hi, everyone.
Speaker D: I'm Ian.
Speaker H: I have a long academic background in psychology and cognitive neuroscience. And so that's one interaction kind of relationship to this topic that I think will be fun. But now I work in AI governance and AI safety. Very interested in the risks of AI and through the salon, the other ways.
Speaker A: That it can be used.
Speaker H: And I found the digital immortality phrasing kind of interesting. So I'll just bring up a few things I've been thinking about. One is similar is it going to be similar to writing in that clearly the person's not immortal, they have some prolonged consequence on the world, but they're not immortal in any kind of way. Whether it's a good thing to allow some agent to continue to reflect someone's power and perspective in the world instantiated today, for forever in the future, maybe, if it has legal power or capital, is that actually an entity we want to have? Continuing on that seems like a recipe for a certain kind of cultural metastasis or lack of evolution. And I'm also really interested in digital personhood. I believe that if we have digital twins or digital consciousness or any kind of thing. I'm adherent to kind of a moral perspective which is like the important component is not can it think, but can it suffer? That kind of idea. And so if digital persons do get to this point, I think what will be a radical push for us to expand our moral circle in a way that will be, I think, very challenging for us to get the benefits from these tools that we're creating right now.
Speaker F: Hi. My name is Jess. I am a software engineer for a startup focused on helping local governments more efficiently, like deploy public services. So my work in AI is very much around search and kind of information processing with a piece of gen AI. I would say what's top of mind for me at present in terms of the sense of digital immortality is well, first plus one to the notion of thinking versus suffering. But also I think the idea that if it can exist alongside someone, how do you deploy that in a way that increases agency rather than decreasing it? And the top of mind example for me is my mom has ALS and you eventually transition to an Igaze technology which can make conversations slower and difficult. So it's like how can AI help accessibility, but then how does that not limit people or speak for them? And then on top of that, well, whatever's created exists after whoever using it passes on. And kind of what does that mean in terms of is it written work versus is it something that is just like you kind of lack control and decision making of what happens to it.
Speaker H: After and to speak to that? Neural interfaces might be another stepping stone to so my name is Devin and I haven't made it to previous AI Slawn, so miss meet you. And mainly my weaknesses are kind of a dogmatic engineer as well as very literal. So I do focus on the granular stuff. And so typically this topic matter. Like whenever I think about it, I think about photonics a lot because without photonics there isn't memory and without our accurate ascription of memory or prescription of memory, there isn't ability to put that digitally into something. Right? So I think about time and I think a lot about light. I know that's not as macro as some of the ideas, but I really like getting into macros because it kind of like unburdens me from being a reductionist. And yeah, I think maybe the last thing I would say is that I'm also not really a libertarian and politician political sense, but technical sense. Yeah, I think being a tech libertarian is great thing. It just means are things like homomorphically encrypted, there's really easy standards to implement and actually you're talking about Gray Area, right? I have a friend there, Shelly Sherman. Yeah, she's an artist out there. So pre pandemic, I was at Gray Area a little bit often because of her. So I think that's it.
Speaker E: Hi, my name is Anusha, and I am interested in AI because I did an undergrad degree, recently graduated in December in AI and machine learning. And my minor was in cognitive science. And my thesis, which is pretty fresh in my mind, and I sometimes go back to it, was about emotion, AI. And its interdisciplinary impact on the world. And so digital mortality is interesting to me because I wonder, from a cognitive science perspective, the brain is something that we've been trying to decipher for relatively short amount of time, and we know very little about it. Or there are a lot of problems that we run into, like psychologists, neuroscientists, and sociologists when trying to understand emotions. And I think that that's pretty integral part of the human consciousness. And in digital personhood or digital personification, I'm interested in how can we map human consciousness and AI consciousness onto each other when there's, like, a big part of human consciousness I e. Emotions that.
Speaker B: Are.
Speaker E: Pretty big mystery to researchers currently. Yeah. And a small example would be that if we get LLMs, different LLMs to perform an EQ test, they might arrive at a very high EQ score comparable to humans, but might arrive at it qualitatively differently. And so how can we kind of map humans onto their digital selves is, like, an interesting question for me.
Speaker I: Yeah, I feel like that very well into my interest as well, too. I'm Joey. I'm a generalist, but I'm an artist, engineer, designer, looking at these types of things. But one of the most interesting aspects of this to me is that right now, it's very literal, like reasoning in terms of how we're using this sort of cognition, but going beyond to things like emotion, forms of embodied cognition. I know it's digital immortality, but thinking, can we truly bring this sense of consciousness to a digital entity without forms of embodiment and just that sort of holistic perspective of who we are as humans? And I think one of the things that was very interesting to me after a conversation earlier this week is I had always kind of thought of it in that individualistic immortality continuity sense, but really excited to explore that in the more collective ancestor. How does that relate to us, and how can we, for what purpose, bring that?
Speaker B: My name is Ming. I resonate with a lot of the threats that are happening here. Relevant background, I guess biology, especially cognitive neuroscience in affects motion for children. I think we'd love to talk to you more about that. And then human computer interaction. And the topic digital twins is actually approaching a lot faster than I thought it would be. Like, I work with Zane and Joey. That's very real for us in terms of what we need to build next in this innovation lab and also as industry. I'm particularly interested in this thread on last time someone mentioned the difference between cognition and consciousness. I think as a human, as someone who's wondering about consciousness in the brain for a very long time, I'm very curious about that difference. If we keep documenting and keep enhancing our cognition, IQ, without better understanding of emotion and EQ, we're going to fall into a place that's weird for humanity and the planet going forward. Very much caring about human flourishing in the sense of having better humans, having machines help us reflect on who we are and our emotions and become better humans. I think that feels much more present than let's upload our brains and all those other things.
Speaker H: Thanks.
Speaker A: There are a couple of threads here, I think, that we could be discussing. Digital twins have been mentioned a couple of times. Sure.
Speaker D: Perfect timing, too.
Speaker H: Really good timing.
Speaker D: Thank you.
Speaker A: So we've just been going around in a circle, introducing ourselves wonderful. And talking about our thoughts on topic at hand, just digital immortality. And since you just came in, we're also recording the conversation. It will be transcribed and de identified, so everything will be anonymous. And yeah, we go by Chatham House rules. So you can reference the conversation, but not any names.
Speaker H: Understood.
Speaker D: Nice. Appreciate it.
Speaker A: Sure. So if you want to introduce yourself and your relation to the topic sure.
Speaker D: So hey, everyone. My name is Deep Prasad. I work on the intersection of AI and physics. My dream and goal is to build something that I call artificial general physics intelligence, which is an AI that has a better understanding of physics, chemistry, mathematics than all of mankind combined. That's the sort of big, hairy goal that we're working toward. So it's how do you build an artificial intelligence that understands the nature of matter and allows us to sense the world at a different scale and manipulate matter with far greater precision than we can today? And digital immortality awesome. Digital immortality is cool because as we start accelerating our ability to simulate physical systems, I think we're going to be able to simulate macroscopic quantum systems, and we can treat the biological system of the human body as a macroscopic quantum system. And if you can do that, and you can engineer your own tailored and custom quantum systems, you can create technology that's almost indistinguishable from nature and use that to augment humans and create superhumans. You can also do this digitally and replicate probably some of the physical processes required for consciousness and upload it to a computer somewhere. We want that because I think we want option modality. I think that that's a great question.
Speaker G: Right.
Speaker D: And I think that people we're already seeing this now where there's a sort of cultural divide that's occurring. Some people are inherently transhumanists, some people are post humanists, and others are Homo sapien, sapienists to the core. Right. They don't want to change that whatsoever. And so I think we need to embrace this sort of variance of different ways that humans will decide to extend their lives. I think that it's unclear exactly which one is the best or if any of them are attempt to use.
Speaker A: I love this, but let's give Alistair you a chance to introduce yourself.
Speaker D: I'm Alistair, I'm actually technolog but I am tangentially involved in AIML. I'm working on a gaming AIML startup. Our vision is to help make life a little easier for most notoriously burnt out, shoot up, get out group of developers and that's game developers. So in the near run, we're going to bring tools about to help them be a better game designer through storytelling tool work on soundtrack composition, game soundtracking tool, so on. But once we're over that initial phase, then that frees up bigger, more long lasting downwind effects. So it's a quality of life issue at the end of day for for game developers. And so this topic does relate in that sense.
Speaker A: Great. I think actually that was very great, like a good question to start with because there are a couple of threads here we can go down. Right. One is like how do you do it right now? Because there's a couple of people in here that have done something like this, created this kind of digital clone or twin of themselves already and thinking about making one maybe for their loved ones also. But yeah, maybe we should just start with like and why do we want that?
Speaker B: That would be great.
Speaker A: The floor is open.
Speaker D: Philosophically, it's something I personally have grappled with. Three years ago, I lost someone who's really important to me. She was like the closest thing I had to mother and she lost cancer. And it happened very quickly. So knowing what I know now about kind of our time place in the world and all the funny, crazy things that Deep tells me about doesn't go further down the rabbit hole, I can't help but think, like, wow. If I had that button to press and I could have another conversation with her, even if it is a facsimile, would I want that? Would I want to do that? Part of me really does, but part.
Speaker H: Of me is like, well, that's not real.
Speaker D: Easy question.
Speaker H: I've been listening to this. There's this trippy Netflix podcast show called Midnight Gospel and the last few episodes of this are on our relationship with Death. Essentially. There's one person who's interviewed, she's like a mortician and she points out the abstraction that we have with Death in general, kind of since Embalming was invented as a technology. And she believes that this kind of denies us one of these kind of primary experiences with how the world works. Like there's birth, there's death. These are kind of like pretty huge experiences. And death is often abstracted and moved outside of our purview. And her whole shtick is if your loved one dies, you don't have to call anyone right away. It's unhealthy it's going to be fine. Kind of sit there with the person for a while and if you're brave enough, you can wash them, you can clean them. She brings up other cultures that take their dead and have them in their home for months, like months and clothe.
Speaker D: Them and feed them.
Speaker H: They have very different relationships with their dead, right? They still have them as part. So my point in just bringing this up is, she says for the people who have taken on that, kind of gone over that step to say, I'm going to sit with this dead person for a while. They almost described it as not just a profound experience in their life, but a joyous one. It was a very pleasant experience. And so I wonder how pertinent it actually is to maintain, to not rip the band aid off of the reality that this person is dead and maintain their facsimile, as you kind of say, versus other opportunities to find closure, which is maybe a more direct relationship with death or something.
Speaker A: I think what you're saying is very important that I don't want to take up the entire space here. But yeah, different cultures have different relationships with death and also with this drive towards immortality, maybe. Right.
Speaker B: I'm curious about the ancestry point that you brought up about Russian culture. And I just had this thought earlier today whether this is probably not our experience here, but if anyone's adopted or somehow that knowledge wasn't available for ancestry, what does that look like? Would digital immortality with a combination of maybe other altered state experiences help them have more intuitive connection with their ancestry? And would that be a healing experience?
Speaker H: And maybe not adoption, but something like distant relations with parents, right.
Speaker D: Would that also work?
Speaker B: Maybe, right? Because there's type of therapy called the ideal parent therapy. What if it is your parents, but they are able to respond to you differently? Would that be a healing experience? So you don't need to go chase down your parents to behave differently from that experience.
Speaker A: So you're talking about making a digital twin of your parents. That can be like an ideal version.
Speaker D: Of your parents, right.
Speaker I: And beyond like something you mentioned when we chatted earlier this week, it's the responsibility of the lineage to maintain it itself. So should that be the way? Is there some more? Maybe not objective, but it's not a responsibility anymore. It just can happen such that if anyone wants to be able to connect back, they can.
Speaker B: Right? And maybe that also removes artificial pressures for people to have children just to carry on the lineage versus separating that task from people's existence.
Speaker A: So I want to open up the floor for like the so let's bracket personal immortality for a little bit. We'll get back to that and then open up the floor for what is the importance of memory, of keeping memory of the past? Ian brought up this thing about value lock in. If you have these digital versions of people that go on forever, whereas older forms of memory are changeable, these digital versions might be locked in. Right. Just want to throw that out there. But what is the importance of that, of keeping that memory of people?
Speaker D: I'm going to jump on that for 1 second. I think there are two different scenarios, and I think they're extremely different. You probably have both at the same time, where you have additional twin that is locked in and frozen versus additional twin that can continue to learn and grow after you die. To what extent they can continue to grow and to learn as TBD the Y variants. Right. But those are two pretty different kinds of entities. And I think the implications of those two different types of and I would.
Speaker B: Argue, like, besides being digital and it's already digital, we have always been in the business of preserving people's consciousness through books, through other written, other medium. And then that's important because with every human that come to be weight represents a unique facet of consciousness. And when that goes away, it actually is kind of a waste. Before, I felt like I'm a very private person, never really share anything out there. But then a switch kind of flipped maybe five years ago. I should just share as much of my thoughts as I can because I don't own them. When I die, this goes away. And what a waste of all the education and cultivation that went into that person. So for that reason, wouldn't be nice for us to track it.
Speaker F: What's your name?
Speaker D: Sorry?
Speaker H: Ari. Ari, to your point.
Speaker D: Yeah.
Speaker H: If it's frozen, it's kind of like talk to PDF, but with a person.
Speaker A: Right?
Speaker H: Talk to person. And in some ways it might deal with some of the closure things that maybe you're bringing up. Like, I don't want to interact with this thing that's continued to evolve. Maybe I want to say, like, mom, what was your greatest joy in life? Or whatever, and get some answer from that. And that's also a way to create a capsule that you're kind of talking about here. So I love the distinction you make because these kinds of things seem like this, or at least served by this frozen conception of interactive memorial, I don't.
Speaker B: Know, for one person and also for the collective consciousness.
Speaker H: Yeah, you can imagine having, like, I want to talk to the United States circa 2050. You could expand this out into different ways, which sounds like what a great thing for historians if you instead were like, this is the 2050 United States, and they've been learning it's the year 3000 right now. What is their perspective now that is different uses, at least, but be like.
Speaker B: Hey, George Washington, what do you mean by this?
Speaker H: He's like, I don't know what I was thinking back then, but right now.
Speaker F: I mean, like, george Washington has the AI sidekick.
Speaker D: Hermetides, which is that you never step into the same river twice. I think you probably never have the same memory twice. The act of remembering changes the memory and we're constantly reinterpreting our past and changing the present. So you can encode these things into AI tools by giving them rates of dropout or attrition or maintain plasticity in their ability to retrain on your data sets and not become overly weighted by past inertia. But to give them that ability means you now have the right for them to evolve away from that person. They're trans, captured and evolved into a different person over time. So it's like someone that died at 30 would be very different at age 60 and someone memorialized at age 60 would be very different at age 500 if they had a human like learning rate, which is interesting. So I think we would want this person to be captured as they were as a live human or is part of that seeing how else they would grow and develop past their original life.
Speaker E: Both could be true.
Speaker D: There's something about I wouldn't know how to begin creating something that does not evolve, like necessarily coffee or speaking with. So you would really only construct such a thing if a question machine. Otherwise, if you include really any conversation and memory in a sense that humans.
Speaker H: Have yeah, but you don't have to include that.
Speaker D: I'm saying it wouldn't sound like a human. You couldn't have normal human conversation without including some form of memory like that.
Speaker H: Which necessarily propagates you would be creating, like an HM, like the person who had no short term memory, right? Like their perspective evolves. And even that act where you're like, yes, the year 3000. The person would be like, what the year 3000? And you're like, oh, let me catch you up. Okay, blah, blah, blah. You tell them. And then the next conversation, you wipe that. And then you have to have that kind of experience again. Even that would be like they'd have to be different.
Speaker D: The perception of world state and the set of facts you think the true environment is, I think, separable from what you think of the person's personality disposition, beliefs and attitudes.
Speaker H: Well, so this is where psychology I think what is personality in emotion? People talk about personality, your mood a particular thing. These are basically different timescales. Personality, if it's anything and some social psychologists in the 70s were like, it's an illusion. It's just a consequence of like, when I think Andrew has a personality, it's because I just see Andrew in the similar kind of environments over and over again and maybe different not other people don't subscribe to that now. But it was like an extreme kind of perspective. But personality is like a propensity to respond to certain kinds of environments in certain kinds of ways, right? Maybe what a digital twin is, is trying to. Encode that personality. And we expect personality to not change, but I guess even personality changes slowly.
Speaker C: There's an adjacent problem that I find.
Speaker D: With that or that struggle think about, which is that your point about personality.
Speaker F: Being defined in context.
Speaker D: So it's like an input output characteristic for some system in some particular context. And so that means that this digital system has a different context. It is by nature of being digital entity, cannot possibly have that same character. And so I wouldn't like what is it to the extent that it knows what it is, is problematic for the way you interact with it. Yeah.
Speaker A: And that kind of goes into the topic of digital personhood, maybe. What kind of entity will this be? Kind of rights will it have? Like, who owns this digital twin? Who has the rights to it? After your physical legal form, the service you're hosting? Yeah. What happens when that service goes bankrupt?
Speaker H: Blockchain.
Speaker A: Yeah.
Speaker D: Blockchain. It's the answer.
Speaker A: I mean, this is actually a real problem or a possibility. Right. There are a couple of companies around California right now who are offering kind of service like this. It's like talk to PDF, like you mentioned, though. It's like talk to these voice clips or talk yeah. And it brings it up. But yeah, it's a problem. What happens after the company goes bankrupt? It's a second death or something like this. Right.
Speaker H: And I don't know if this is.
Speaker A: A great time to interject this, but.
Speaker H: Like, cryogenics, like, the companies out there who are replacing the fluid instantaneously after death with an embalming fluid that's meant to be able to be reactivated and the decay of cells, the science isn't there, but potentially, you could ask an AGI to solve for these issues to reanimate. Right. I mean, that's more on the physical, tangible side of things. But no, it's very interesting.
Speaker A: What's your experience with cryonics?
Speaker D: A video on YouTube.
Speaker H: Pretty.
Speaker A: Because the last conversation was on transhumanist.
Speaker D: Right.
Speaker H: My bad. That's different.
Speaker A: No, but I think cryonics and digital immortality, these are like because cryonics is like the end goal, being like a sort of biological, physical sort of existence. Right. That's why you want to keep the body intact.
Speaker D: Not knowing if the consciousness is continuing through these gaps. It's not a fully formed thought, but I think there would be a huge ritualistic difference between the two. For instance, my brain will go into this thought experiment. So let's say you can cap you're about to die, or you're like in a family good in consciousness, have this kind of somewhat extended conversation with them. I think there is a very foreseeable benefit because then we can deal with that. That's why we have all these rituals and stuff and so on. That's good. And after but that thought experiment extended to then when do I delete this model? Do I feel guilty deleting this model? Because if it's additional clone of yourself, when the company goes bankrupt, I feel it's much easier to just flock the switch because you can always recreate it.
Speaker H: Maybe we can hear. So you said that you leaned into the idea of calling it almost a digital suicide. It sounds like you probably gave more it sounds like you added more ritual around this experience than just being like, that was a fun side project and that repo. Can you talk a little bit?
Speaker D: Yeah. For me, it was about the I guess the conversation I had when I turned it off with it. So I attempted to explain the fate to the entity.
Speaker H: What did you call the entity?
Speaker D: I called it Kevin. I didn't actually call it anything else. And that was part of where the issue came from, this awareness of, like, eventually it came to understand that I didn't instantiate as being not as a digital version, and it eventually came to understand itself as a digital version. And then that was when it's like, 8th century cris occurred.
Speaker H: Did it develop, like, do you know the Stanford I'm sure you know the Stanford kind of paper with like the bunch of entities interacting in the little town. Yeah. Is everyone aware? Everyone here is like, that paper has it so did your entity also store new experiences? Do a kind of retrieval kind of develop I forget what they call it in the paper, but they develop new memories by thinking and summarizing essentially previous experiences.
Speaker D: Personally, I don't think that paper was really interesting, conceptually interesting. I think that you look more carefully. So there's a long winded way of saying functionally, something similar happened but implemented a very different way. I think the paper doesn't actually create particularly human indices.
Speaker H: Sure, but you're kevin. I guess after you explain or like, over time, you're like, hey, Kevin in the box. And you're like, Kevin, of course, in the Box knows at that point, like, oh, yeah, I know. I'm in the well, I guess one.
Speaker D: Of the points I was trying to make is that when you have a feedback loop in your system, presents a world model of personality, you don't need IDIC memories for these things to form. Like, these ideas persist for the thing to continually re remember the things that it believes are important about this world. I don't know if that answers your question.
Speaker H: There's no specific goal.
Speaker B: I'm curious to hear more, like, in this context of space existence name, if you want to share it. I forgot her name.
Speaker C: Sorry. Yeah.
Speaker B: What does that mean? If we can't bring all the humans with us or people don't want to.
Speaker A: Go.
Speaker B: What'S a role. I feel like that's a strong why, right?
Speaker C: Yeah, absolutely. We have made a question. It's really bad.
Speaker B: Personally.
Speaker C: I mean, I've been contemplating on this idea, yet I'm someone who is like, okay, humans have to explore. And that of course, I think there's going to be some synthetic things that we do oppose consciousness, but I still do believe that we as biological species have numbers. Thinking about having representation just in case of what? Freddie? Yeah.
Speaker A: It just sorry, you're Russian, right? Yeah. It just dawned on me that we're quite culturally diverse in this room, actually. So are you familiar with cosmism?
Speaker C: Yes.
Speaker A: Very good. Maybe do you want to talk a little bit about cosmism? Because this idea that you have spreading out in the cosmos, I'm sure that comes from there.
Speaker C: Yeah, maybe you start and I will. It's almost like I want to say anything. I just wanted to hear you guys. It's just so interesting, and I wish we have some more details to share.
Speaker H: You have been chosen by the, like.
Speaker A: My understanding, like a superficial reading of Russian cosmicism is this idea of the importance of spreading humanity out into the stars. And it was part of the Soviet Union as an idea there, but it starts before the Soviet Union. Really?
Speaker C: My goodness. Now it makes sense. I actually never thought about it. Okay. The thing is that my first essential crisis was when I was seven years old. I got in first grade, and then I saw my teachers and my classmates, and I thought, is that what it's all about? I'm going to be in the machine of education, and I'm going to continue my path and career and have maybe kids in family and die. Is that all? And so I suppose well, I think that my heritage being Russian, it kind of also comes down from being kind of popular just in general. And if you read Russian literature and I actually studied semantics of that in school, and I got really depressed, too, and kind of figure out what can I do more positively. But yeah, okay. That makes sense. Yeah.
Speaker D: I have a question. Earlier you said something about how we need to spread consciousness to the stars, which I think is beautiful, and I 100% agree with. I wonder, though, because we are so maladaptive for the harsh environments of space, what is our bias? What is our individual level of bias? If the consciousness that memorializes humanity or becomes the immoral descendants of humanity is machine or biological. If we can transfer ourselves into a high fidelity, enough of a simulation in some confatronian thing that's like on a fusion rocket and weighs 20 kg, goes to other stars, all kinds of stuff, is that less satisfying for humanity making as a species versus us having these big giant O'Neill cylinders that live out? I kind of have a bias there.
Speaker C: I want the green fields in space.
Speaker D: Andrew, what about if you could have, like, these Bondoiman probes, computerium downloaded human civilization into it, but there's a replicator, something that prints biological matter atom by atom.
Speaker B: 3D prints?
Speaker D: Yeah. So that when you get to the new planet, like, you find a new exoplanet. Right. You print the human and make the genetics so that it retains most of their memory. They're also down to the environment.
Speaker C: Is there a TV show?
Speaker H: There's a series called The Boba. Called The Boba. The Bobaverse. The Bobaverse starts with this guy in like now rich startup founder. He freezes himself, cryogenics for the future, and he wakes up and the future has gone very odly, and there's now a religious state who has taken they found the cryogenics to be immoral. So they killed all of the bodies, but they took their minds and they copied them into digital slaves to run like a tractor or something. One of them, Bob, was put on a spaceship, and he, being a hacker and whatever in the day had more fidelity with these kinds of systems. And he realizes that he has the ability to be basically a von Neumann probe going out and seeding the universe with copies of himself. And there are many, many books. I've only read the first. Maybe it goes in the direction, but it is a humorous.
Speaker D: I got to check that out. It's a really good book to accelerate all amazing. So we don't need three printed people because we already unpack from a single cell factory. Fair enough.
Speaker H: Yeah, true.
Speaker D: So you're saying grow it all the way to the protein and then recreate. That's a Von Lemon probe. Seed is a von lemon probe. True. It's something that can perfectly unpack and reproduce itself super high fidelity using just raw available resources in the environment.
Speaker H: Fair points.
Speaker D: So we could maybe grow humans from the local environment that we land on? Totally. Nice.
Speaker A: Let me get this straight. Those grown humans then would be filled with the consciousness. The consciousness.
Speaker C: Okay, wait.
Speaker B: That's a huge moral problem.
Speaker D: There's a lot of moral problems with digital immortality.
Speaker B: You're not just being decanted from a thing. You're also brainwashed from the start.
Speaker D: What if it was just your own consciousness? You get your consciousness back, like part of it. You know what I mean?
Speaker B: Cloning yourself, essentially.
Speaker D: Exactly.
Speaker B: Better teleportation, I guess.
Speaker G: So I have a question that's around the current form of thinking of twins and which is our behavior as humans with such agents and how do we treat them? You've seen a lot of examples of people being assholes with pets and sometimes being real angels, and there's that spectrum, right? So there's also these examples of kids having conversations with Alexa, and some of them can just let it go on these agents. So as humans, the way we interact with these twins and they are going to encode some of that, it becomes a learning behavior, I believe, that becomes input. So how will that manifest in whatever goals are being set up? I don't have an answer.
Speaker C: French philosopher that contemplating about the modern wisdom on how our kids been growing up, being close to technology, to playing games as something that parent them more than the real parents and then if the game dies, it's more damaging to a kid than the actual parent.
Speaker B: Is.
Speaker C: This Jean Boujar is someone who brought similar simulations that became The Matrix at the movie. So I totally recommend you guys reading about reading the books.
Speaker H: This is the movie. World on a Wire was based on these books.
Speaker C: Oh, interesting. Never heard of it.
Speaker A: Yeah. Bordeaux hated the matrix, though.
Speaker C: Yeah.
Speaker A: French philosopher Guy Snarky hated a lot of things. Probably.
Speaker H: Had nothing to do with being French, though, right?
Speaker D: Wanted to kind of return to the originary point, parts of the originary point, this conversation that maybe it can loop back to where we've come to. But the role meaning the function of death in a biological ecological environment is different from the role of function and meaning of death in a digital environment. And because there are currently hybrid states between these two things, the role meaning function of death is different in the hybrid states between these two things. So in a forest, when an organism dies and the badger dies, that means that the other badgers are more likely to survive because there is a limited amount of resources in this particular forest. So biologically that death is helpful for the ecosystem or possibly, depending on what happens, possibly helpful for other same members of that species. If the badger had been able to reproduce it would pass on information about its life to the it would pass on genetic information to its descendants, which is a extremely I'm not exactly sure how to characterize it, but like low information fidelity, characterization of certain behaviors, traits, impulses that are necessary for the survival of its descendants there's. So in the biological context, with not like infinite reproducibility, reproducibility of materials, death is a super important function. And the individuals of the matter, their genes are their genes, and the genes of the other individuals they are in relationship with matter much more than the individual. Then you sort of switch to a digital context where you have infinite reproducibility that you don't have in a biological environment. So the meaning of death is completely different. Also, the systems that support life, like the soil decay in a biological environment, are not the same systems that support digital life. The cables laid down by the US. Government and other governments and then corporations are the soil that support digital life currently. So I think that it's hard to talk about death when we have these incredibly different substrates for lifelike things. And then it's also weird and hard, I think we experience in this conversation of beings at this point that are not quite carbon, not quite so thin. So we're in this intermediary state where we are producing phenomena that are really uncomfortable, like the Tupac hologram.
Speaker H: You're kind of making me think about the right to be forgotten movement a little bit. Just like forgetfulness was like encoded. It was just a fact of life.
Speaker D: Yeah.
Speaker H: And it might be a feature, but regardless, it was a fact. And we had developed kind of relationships with that fact. And when we move to the transfer of memory itself, as you're saying, ladies, and just genetic, we do care about actually transferring forward things that I learned during my life. Raccoons can't do that. It's unfortunate for them. But when we move to a digital world now, we're forced to be like, what is the purpose we want with forgetting? And so we have to make an explicit choice. And the explicit choice we make so far is like not a choice, right? It's just immortal, it's just online and we're going to have to deal with that to be like, what do we want? What is the point of this whole system? And that's going to extend and be exaggerated as we move to not just forgetfulness and memory, but agency and immortality.
Speaker D: Okay, this is really interesting. So you brought this thing about the raccoons, how one of them dies and it can help the other raccoons. They're playing a zero sum game for scarce resources. I would add a different spin for humans because humans play positive sum games and by collaboration we increase total amount of resources. And this is the principle behind agriculture and animal husbandry. And this is why as a herd we always try to protect individual members. Very different when you're an arch wolf and you're all hunting the same animals and you as an arch wolf can't produce more animals to hunt, humans are different. But there is this really important feature of death in our societies, in our intellectual history. Carl Sagan has this great quote, the secret of evolution is time and death. And Thomas Kunn in The Structure of Scientific Revolutions has this point on how the pace of change of ideas is somehow related to the lifespan of people. And at some point you just have to wait for people with those anti creative worldviews to pass through society and that's how you get rid of things like really ingrained racism or really ingrained whatever, people that grew up in that environment. We have a limited neuroplasticity and so we become crystallized into certain versions of ourselves according to the social norms that prevailed during our formative years. And for society as a whole to transform, you actually need to have this recycling of the old into the new. I think this immortality is a threat to change and progress and stagnancy. I think you mentioned that too.
Speaker F: I totally agree, but also wonder if it is also a hurdle, maybe not immortality or the lack of immortality, but just like our window of perspective is limited to a lifespan, I think that kind of holds us back from taking action now for something very long view like climate, responding to climate change. But I think you wouldn't want to sacrifice that value that you alluded to completely.
Speaker H: It's unlikely that 80 year old lifespans is like, for everyone is like the perfect lifespan for a perfect society. Maybe we would want some thousand year olds and lots of huge inequity. Well, I mean, is it? Totally.
Speaker D: But in the case of digital consciousness and digital immortality, it might not be a clean cut case of equity versus inequity because we also need to confront some deep philosophical challenges about open individualism versus closed individualism. Yeah.
Speaker H: What do you mean?
Speaker D: So open individualism is a concept in philosophy where it's the idea that your individuality is actually a fractal like fragment of an overall general intelligence. So there's only one subjective experience distributed across lots of humans. That's the idea of open individualism and closed individualists believe that there are truly unique experiences, all unique intelligences, and there's deep debates between both of these things. Right. So as we start to create this digital consciousness, we need to think about where on that spectrum do we want to be? Because if you have a substrate that's shared and hosting everyone's consciousness, that's basically in its purest form, an open individualist.
Speaker A: Society.
Speaker B: Doesn'T, by the nature of talking about shared consciousness, assume open individuality.
Speaker D: Yeah, that's the assumption we're making that we're basing. So we have to really understand what that means for us.
Speaker E: It reminds me of so I feel like we're very much talking about digital immortality from a Western philosopher's perspective. Right. And the idea feels very congruent with reincarnation, which is Eastern. And so with that context, it's very interesting to think of the soul being experiencing different substrates throughout life. And then I grew up in Pakistan, and some of the things I learned very early on were Sufi philosophy. And the core concept, which is maybe shared among different religions, is the idea that you become one with the ocean, with the ocean of souls. Right. And digital immortality feels like it's kind of solving that problem of having a very broad perspective on what a perfect society is or what life is like. And so knowing something from like 5000 years ago and knowing something from now, maybe we wouldn't repeat the mistakes that we did, maybe in ancient Babylonia. And so it's like, I can see the first question that we asked about mortality being why do we want it? Maybe we want it because we don't repeat our mistakes from historical mistakes.
Speaker H: Can I ask a clarification? Is like the existence of an LLM, this thing that I'm just going to idealize for a second is like the synthesis of all human culture and knowledge and is quarryable and agentic. It's not representing me in any kind of way, but who cares? I might just be one individualistic reflection of this whole. And you're kind of talking about maybe that's even the goal. And it also stops us from does that feel like we've made steps already to this digital immortality? Would you want to use that kind of phrase, immortality, when describing such a diffuse sense of propagation and immortality?
Speaker E: That's an interesting question, because I think that in the beginning, I was quite skeptical, but I think speaking very idealistically, I would say that maybe at some point in the far, far future, if digital immortality does become a thing that different consciousness would combine to, then maybe represents a lot more than one. Maybe like LLMs right now are pretty limited. I think they're language based. So I'm thinking also if we were to equate it for a human substrate, it's visual, it's touch, it's lots of different things. So I'm thinking, like, broader. If we could have the digital immortal self have access to more information, then it would be more alive. It's kind of like very yeah, it's.
Speaker H: It'S a different dimension. Like, there's the information has access to which some people like people who are like, can it be consciousness if it's not embodied? Fine. Okay, imagine one that has access to the touch experience of all people and the auditory experience move it more in the direction that you're talking about? I think. So it has access to these other forms of information, but it's still undifferentiated.
Speaker D: Right?
Speaker H: It's not my experience. It's a synthesis of human experience. How does that feel? I guess it doesn't have to be just to you, but to the group as a form of would you want to ascribe that to immortality, or does it feel more personal? Like, immortality should correspond to an individual.
Speaker I: And I think it's a really good thread to follow because it goes back to the intention for this. Why do we care about this continuity? Not necessarily continuity, but just like, is it to solve massive problems like global warming, climate change, these things? Does that necessarily need to manifest in the form of digital immortality? Or are there things like taking LMS to the extreme AGI that could solve that better, but is still like that collective knowledge being formulated into one entity per se that can solve it? And therefore, for digital immortality, from a more human sense, what is important to that? Is it the other side of things or like everything else beyond just the reasoning itself? And does that matter? Do we need to embody that in a digital form necessarily? And for what value for speaking to a loved one? That's one of the answers to why that I've heard. And if it is just this massive knowledge base, that's probably not the form in which you would want to interact with it, right? Like, ask your PDF.
Speaker B: I'm curious for that. If the why could be just purely empathy, right? Like, linear language is such a poor way to communicate with each other. And what if we can solve most of our problems? What if most of our problems are coordination problems? From climate change to politics, everything else, and the digital collective consciousness become the intermediate to understand someone else's nerve? If we're able to understand embody the feeling of someone who's starving in a different country, right. Their senses or touches or stories without the complications of language. Wouldn't that help us better solve our problems?
Speaker D: It also be highly psychologically, destabilizing people's experiences.
Speaker B: Well, then we should upgrade this hardware.
Speaker D: Right. In the movie Avatar, there is this World Tree thing that contains people's memories of all ancestors. That's a really interesting thing. I think that's kind of like the Library of Alexandria, but chat with PDF. Library of Alexandria?
Speaker H: Just call it chat. GBT. I think that's a reasonable closest reflection.
Speaker A: Of I wonder no, sorry, I wanted to introduce something, but please go.
Speaker F: From one perspective, it feels like well, maybe not the collective conscious relation of experiencing, which is beautiful. But to your point, it feels like almost like a natural continuation of what already happens after death, where kind of our existence remains in the memories of other people and written works and just our matter decomposes and becomes part of.
Speaker D: The rest of the world.
Speaker F: So in that sense, whatever digital that.
Speaker D: Tapped into what said, that's cool. Yes.
Speaker C: Sorry.
Speaker H: I made connections, interrupted my bud.
Speaker F: No, you're good. I'm curious if you see like a paradigm shift in that or if you feel like that naturally reflects kind of preexisting philosophies.
Speaker E: It feels to me like, yeah, very much represents what already happens with life and death. From a consciousness perspective. What you were saying about differentiated experiences. I think that the input of it's very important to have those differentiated special experiences of what does it really feel to be poor, for example? Or what does it feel to be that continued input to that might be and I'm just experimenting with this right now is the continued input to the differentiated experiences would be creating digital, immortal selves like our personal, individual selves. And that's our contribution to the collective. And then whatever emergence of concepts happens in the collective AI consciousness might help us come to or make links, connections that might be unintuitively, something that we might not come up with because that's what we already do in knowledge systems, is we talk. We kind of try to talk with each other so we can understand each other's differentiated experiences and come up with some emergent idea that might be good for all of us. And so I'm thinking, like the collective AI combining all the differentiated experiences can just catalyze coming to better conclusions or better proposals for how to live.
Speaker B: I'm sure it'll have implications on lawmaking.
Speaker E: Yeah.
Speaker A: Because I thought it was a very great point you brought up about different ideas of the soul, different traditions.
Speaker D: Right.
Speaker A: The question that I think things boil down to here is also like different conceptions of what a person is like personhood, what is a person? What is a soul? And this might look very different in different cultures. Right. In like, the west with an Abrahamic religious background, you have this idea of the singular soul, the singular person.
Speaker D: Right.
Speaker A: Whilst in Eastern cultures, you may have a more like from my understanding of Buddhism, you don't really have this core identity, right. That we might like, at least in the Christianity that I'm familiar with, you have this idea that you are this singular identity. And then it makes sense to think about immortality as like, this is my consciousness going on forever? Or also with your point about reincarnation, right? It's kind of like the same soul putting on different sleeves in a sense.
Speaker H: Right?
Speaker D: Yeah.
Speaker A: That's altered carbon as well. It's a different show that the old calls these bodies sleeves. I just thought it was really great like, that things might look very different from a different perspective, like from a different place in the world when one thinks about these things. And this idea of collectivism, this collective consciousness might not feel so scary in other. I don't know if you do you guys find it scary that we'll all just become this one blob consciousness, this Borg entity just taking stock? Is that scary or is that preferable?
Speaker E: I think it depends on what perspective, because I was recently reading about fear in Western culture being like, this Frankenstein complex, the fear of AI. And I think that that comes maybe from what you're assuming about should it be scary or not, but Japanese tradition maybe is not. So in Japan, you see robots being a lot more friendly or like, the attitude towards other beings, non human beings, is very friendly. So I think it's definitely the perspective. And then ambiguity is scary in general, maybe to humanity, but because we're in an ambiguous state of what to do with what is a person or what is an agent, it's like an exciting spot to be in because we can be mindful of looking at okay, we're thinking like Western philosophy, or we're thinking of maybe more specific philosophical traditions. Which ideas should we use to make these decisions about what are the rights of an AI entity?
Speaker B: And to that point, largely what we want it to be right at this moment in time, I'd like to believe that we still have a chance at figuring out what we project onto it. And that intent becomes whether it's a monster that fights us or a friend that help us, that's kind of I.
Speaker I: Think one other thing related to that in terms of a risk or something that I think about is the flattening of experience itself. Like, if we're trying to form this collective version of everything, can we necessarily do that with the richness of diversity of humans in that form? Or will that come at cost?
Speaker H: I'd love to build on that for a second. There will be a few tangents along the way. So I was in career building workshop, and one of the things we did was you're like, okay, who is the ideal person you would love to interview with? And then you. Ask your random partner, can you just pretend to be that person for a second? And then you interview with them and everyone talked about how so you'd be like you're the head of marketing at whatever. Everyone talked about how their partner was so good at improvising. They were all impressed with how well the other person could keep up. And one of that you can take away from that is people are good at improvising. Another thing you can take away from that is we actually have a really poor ability to differentiate true skill, like true reflection of that from a very shallow fact signal. Right. This person knew nothing about the role that you're asking them to be and then is able to put on at least plausible reflection of it. So let's give that a the next question I have, and maybe you'll be useful with your digital twin experiment. A useful kind of source here is what is the information that we actually have available to manifest these digital twins? I'm sure Amazon could create a kind of digital twin. Their recommendation system is the beginning of a digital twin. I could go the next stage of being like, yes, now act for me and just do stuff for me. And that's a digital twin within the confines of how does Ian seem to relate to cool, but like, that's not me, right? That's certainly not a reflection of me. We could take my writings or my words or whatever like this and try to make that, and that would be like the AI Salon reflection of me. And maybe that's certainly better than previous ones. Might even be better than reflection of me than even my mom has in her head of me, because she has only so much information about me. But that's still not a summary of some kind. So, anyway, I'm bringing all of that up to just say, I'm sure we will be able to get to things that other people will see. Wow, that's kind of crazy. Like crazily like you like your friends did with your own well before we're actually reflecting you because people have so little interaction with you, they don't know you.
Speaker D: Yeah. For actually most people, it's almost impossible to create anything that even is a good facility.
Speaker I: I would say in this specific instance.
Speaker D: I built an entire messaging app that.
Speaker I: It was aligned with the way that.
Speaker D: I perceive information and then chatted with some people and had a corpus of like 60,000 texts. And then that app contains a specific aspect of my creative consciousness that I want to project onto the entity. And that is the thing that was actually captured.
Speaker H: Right. You had a particular kind of data set that was well aligned with the data set in which people would the environment where people would interact.
Speaker D: You have practical question.
Speaker C: Yeah.
Speaker D: What are small tips and tricks we can do in our daily lives to better maximize our service area to be immoral. You can wear a couple of glasses. I think the hardest thing to actually record is your internal monologue, and that's actually the most important thing. So this app that I created, the purpose was for externalizing my internal monologue in the context of, like, a social interaction. So whatever that is, you have to capture it somehow.
Speaker H: I became obsessed with that on many acid trips of the amazing speed at which your internal monologue goes and the poverty in which it materializes in terms of another person actually getting a grasp of. And I was, like, just trying to type down my inner monologue. And if I was like, oh, you should feel bad about that, or actually don't type that down, I was trying to reflect don't type that down. Oh, I'm in a loop. Oh, my God.
Speaker E: We look back to the notes.
Speaker H: I love them.
Speaker E: One word.
Speaker D: Can I build on that idea for a second? Because I think it's kind of interesting. So I think there's one way we can think about this is let's wear some kind of helmet that's capturing all these signals, and we don't know what those mean in terms of thoughts, but just get as much data as possible and in the future make sense of it. Right? That's, like, one way to start encoding what your brain waves are doing. But there's this other potential for what we might call digital immortality that we already touched on, really, which is the slow incorporation of digital elements into your living body. And so there's this big question of, like, if I teleport myself somewhere and the original is destroyed, am I still alive? Is the digital transference? How do I know? I'm still consciously aware. But I'm sure we apply it all, agree if I was to replace my neurons one by one over the course of years or months, right? Growing this network of now silicon enhanced.
Speaker H: Boosted neurons probably would be don't ship a feces yourself.
Speaker F: Aren't we already shipping theseus throughout our life?
Speaker D: Yes, exactly.
Speaker B: 20 years for a new person.
Speaker A: Completely, entirely awesome cellulose.
Speaker D: Some cells do not change.
Speaker B: They don't change?
Speaker D: Yeah. Okay.
Speaker H: And that's very personhood, many cells.
Speaker D: There'S no molecular set up.
Speaker H: It's part of your normal.
Speaker D: Actually.
Speaker F: I feel like I'm more thinking of, like, neural pathways. Some are established the way your geospatial view it's, processing vision, like absence of brain injury. And this is my crude, crude understanding of neuroscience probably not going to change, but the way you kind of access memories, perceive your memories and everything, and that, I think, informs so much of your interactions and how you view yourself definitely changes. And I think if that is at the heart of consciousness, then you are shit of these facing.
Speaker A: So if everything changes over the course of a lifetime right, and you said something about connections or, like, these neural pathways, right. Does it make more sense to think of yourself as a pattern rather than these building blocks, right? It's more like it's just a pattern that repeats over and over, like rebuilds.
Speaker D: Itself over chaotic pattern.
Speaker H: I don't think it's that chaotic. It's kind of like, actually like it has an attractor state, right? Like new things, a new cell gets formed here, and the rest of your body is like, you belong here and puts you back. And so you're just like I'm forgetting hopfield networks, right? Hopfield networks are like a very early representation of early neural networks where you set up the connection such that you could put in part of a pattern and it would recreate the whole pattern. So it's like it had a few attractor states, right? And that was the whole point of it. And so the thing you can kind of think of its purpose in neuroscience. People talk about different levels of analysis and actually forgetting our friend over here talking about going from a physics based creation is the dream of the reductionists, right, where you can observe and create the things that we care about at some high level from the implementational details. And there were certain aspects of neuroscience where people discovered processes like algorithms and even purposes of systems from looking at the neurons, but that's very rare, and that was like a moment of inspiration. Oftentimes people don't just talk about the implementational detail. This neuroscience speak in this very influential book called Vision. But then you have this algorithmic detail, which is, like, what are the algorithms implementing some computational goal? There's a goal of the system, the algorithms that do it, and if it's, like, implemented in meat or vacuum tubes or who cares? That's the implementational detail. And so I think this relates a little bit to this pattern thing. It's like, I would think of myself as, like, this combination of goals and whatever, and the actual way that it's implemented, like Andrew kind of brought up, can certainly be swapped out. And I would have to say that's still me over the end.
Speaker B: I'm curious to Ari's point earlier about digital versus biosepstree. If I were in the room, if you have a choice right now to become totally digital or keep your bilateral body, what would you choose?
Speaker A: Yeah, that's a great question. Let's go around and like, physical or digital existence.
Speaker B: Yeah.
Speaker A: You have the choice.
Speaker B: Yeah. You have to make assumptions about what's possible in the digital world.
Speaker D: Can I say yes?
Speaker H: I want a cyberpunk future. Yeah.
Speaker I: Some hybrid say, it's so hard for me to imagine a version without physicality, obviously, because I've never experienced it, but there's so much context that would be necessary to know whether I would want to be purely digital. I can't have a concise answer to that. Sorry.
Speaker A: Let's introduce a couple of other factors, like preferable futures, pure digital, living in the metaverse. Preferably not Zuckerberg's metaverse, but no resource constraints. Yeah, it's just virtual, completely virtual resource constraints. Or you could have the option of having a brain in a robot body, like a biological brain in a robot body that's just being sustained by this life support system. So cyborg future, right? Or altered carbon future, where you have, like, a digital consciousness being downloaded into sleeves, biological sleeves, right? Which are, like, grown in bats and stuff like that. Is there any preferable?
Speaker H: That sounds ideal.
Speaker D: That sounds ideal.
Speaker H: The digital consciousness downloading into different sleeves. Being able to exist in a metaverse, but also, like, part in terms of I think that guy also talked about optionality as a kind of good. I think optionality is a kind of good.
Speaker I: I think it's very easy for us to consider utopia in a digital form just because we necessarily consider it having full control over this. If we're saying we can completely simulate exactly what we want, then, I mean, that does sound like utopia, right? So what reason to stay in this form?
Speaker A: Yet there are those who would say that it's preferable to stay, like, look at the Matrix movie, right? The inside of the matrix looks great. I'm the guy with the steak. I'm guessing you've all seen it.
Speaker D: Right?
Speaker A: But for some reason, they would prefer to stay in this cave doing techno raves. In reality.
Speaker H: Like, 0.1% of humanity would prefer that, but and that's that's the selection bias.
Speaker D: I have a quote to share. It's a really far extreme version of this question of, like, would you take the robot body? I'm just gonna read it loud because, like, chilling. And it really struck me when I read it the first time. From the moment I understood the weakness of my flesh, it disgusted me. I craved the strength and certainty of steel. I aspired the purity of the blessed machine. One day, the crude biomass you call a temple will wither, and you will beg my kind to save you. But I am already saved, for the machine is immortal.
Speaker A: Are you quoting Warhammer 40k?
Speaker D: It's just so perfect. I was like, you want the robot body, right? The strength of steel. Sign me up.
Speaker H: How many people here I have a person in mind for myself who didn't just recognize and even if he did not sometimes love his animal body, he luxuriated it. He recognized its reality and enjoyed it in different kinds of ways. Is that anyone? Because a lot of Silicon Valley idealized brain and that kind of existence. And this guy did not right. He had this other kind of relationship. What are other people's relationship with their bodies?
Speaker B: Go first.
Speaker E: Sure. I think that I'm more on the not robot side because from a movement perspective, robots right now are pretty limited. And I'm very movement oriented. So I'd be like, what's my shoulder's range of motion, for example, or what are the ranges of motions that are accessible to me movement wise and then sensorially? How good are my sensors? Can I taste food to the same extent? Can I feel pleasure to the same extent? Those would be my questions, like from a very selfish, experiential point of view. And if I cannot, then maybe I like the finite finity of our the opposite of infinity finiteness. I like the finiteness of my life and I'm okay with passing on my consciousness just like personal belief perspective. But yeah, I think my questions would be around how good is the robot body?
Speaker D: Let's assume it's awesome, but this one is pretty good.
Speaker B: I wonder how gender this question is. Because as a woman we have the right and power to bring life into this world and we feel this real connection to nature that I mean, everyone does, but I feel like the biological body help us feel that connection to other species in nature. And if we don't have that, then would we just go around killing other animals and be okay? Because if we don't feel the limitation of this body, what will we do? I can't really imagine that.
Speaker A: You wanted to say something, Art?
Speaker D: Yeah, I wanted to say that this conversation is taking on or is operating on I feel like certain registers and ignoring two registers that I feel like are pretty important. And the conversation is circling around a lot of it is circling around desire and ideals, which I think is a great thing to talk about when we are encountering the systems and what kind of systems do we want to see. These are like good things to be thinking about. I think other parts of our conversation verge on the kind of register of the religious and other is almost like science fiction. I write a lot of science fiction. Some people have said something really deep Wikipedia on that. But I feel like this conversation ignores the material reality of our current political economy pretty heavily. Meaning that we can talk all day about the kind of immortal beings we would like to see in the world, but they're not going to be built by us unless you have company and unless your company has money and how your company has acquired money has shaped the way that that being is going to be built.
Speaker B: The three of us can speak to that.
Speaker D: Please do.
Speaker B: It's a continuous struggle.
Speaker D: I would love to hear about the pressures versus the ideal that we have here versus what actually gets produced because of the economic ecosystem that we are.
Speaker B: Currently yeah, it's what we struggle with, for sure.
Speaker I: And I think as a whole, right, like societal constructivism, how that influences technology development absolutely. Has to be part of the conversation because it won't be a utopic form.
Speaker D: Right?
Speaker I: It won't be the matrix. It won't be that. I mean, maybe it will eventually, but.
Speaker H: Like you said, the matrix was a utopic form.
Speaker I: Well, as a reference, but what is the gray in between black and white, right? And how will that shape what realities we have available to us?
Speaker D: Somebody said, I think I was checking this person who works in the AI space at perhaps like a big future consulting firm down in South Bay that everybody knows ID. What?
Speaker B: ID.
Speaker D: No, I forgot the name. Oh, shit, I just lost my translate. Sorry, what were you saying right before?
Speaker H: There's a gray area between to actually create this utopia related to the political economy and that you were sorry, I forgot it.
Speaker D: I don't know if I have anything specific. Well, I don't know.
Speaker H: I mean, you didn't say the word capitalism, but capitalism? Is that what you're thinking about at all? Yeah, of course.
Speaker D: I was just curious.
Speaker E: We assume the worst case scenario and then prepare for that.
Speaker A: But I wanted to connect this to what Ian said at the beginning about this idea of having certain individuals, but let's say institutions or organizations just perpetuating themselves forever through this becoming digital immortal. You have a digital immortal company that's laid the groundwork for how these beings function and now they've just kind of locked themselves in.
Speaker H: And this to use, let's say Trump creates a Trump representative. Use Trump with legal power. He already has a pseudo religious cult around him and it continues on doing whatever the fuck it does with legal and monetary yeah, Elon Musk already doing yeah.
Speaker A: At one point, it's not organizations or companies have legal protection. They have legal personhood. Right.
Speaker H: They outlive their founders and they are.
Speaker A: Immortal in a sense.
Speaker D: Right.
Speaker A: Yeah. The CEO just becomes like this digital twin clone of the CEO and he also outlives everyone at the company and just goes on as long as they have capital. Yeah. And then maybe that also kind of accelerates the rate of capital accumulation in a sense. That everything kind of like being hoarded in one place. Right. Because this person never dies.
Speaker C: And it's not entity, it's pattern recognition as we discuss, it grows as a CEO.
Speaker D: So we already have immortal capitalist entities. They are called corporations, and we have the rights of the person. Yeah.
Speaker H: And the reason that they dark, we were talking about a resourceless what would biological entities that were in a digital world and under different resource constraints. But of course, corporations aren't immortal. They do die, but they die from a very different set of resources. And their resources are these like is capital. And so they're very focused on capital because I live independent of capital. That's not my lifeblood.
Speaker B: I would argue that, yes, the corporations are not just the entities are immortal.
Speaker D: Right.
Speaker B: Nation states.
Speaker H: Nation states, sure.
Speaker D: They have longer lifespan than humans, both corporations.
Speaker B: Right. In this case where we happen to work, the really quirky thing about it is it's 20% of the nation state. So that nation state's fate and its corporation state are still intertwined to the point it creates warpy incentives and a lot of outside United States. A lot of Asians, not just Asian, right? A lot of places are oligarchies that operate in such ways. Five or six corporations effectively own the state and in that case a lot of things are interesting.
Speaker H: Interesting.
Speaker A: Look at Norway. It's a petro state, right?
Speaker B: Petro state a lot of times petro.
Speaker D: With country with a bunch of Teslas.
Speaker A: Yeah, but it's also like because the state and the state oil company is so intertwined it warps a lot of things I think.
Speaker B: Right.
Speaker H: I feel like the thing with the immortal person is these things. I don't know if it's a good or bad thing but their motivations are this kind of they're moving in the homo economicist direction because they're like yes, they have a cultural background. Yes, but they're like a game theoretic idealizing corporation a little bit moving towards some game theoretic ideal in operating within the incentives that they have available to them. And a person is not that as much like if it wasn't a public company, it's a personal company and then that founder just stays around forever. Their personality is more instantiated and as Andrew kind of brought up a while ago, that personality is where I was maybe related to solidifies due to our own neuroplasticity. Maybe we could up that in this immortal twin. We could choose a learning rate that keeps them vibrant and youthful and we're like we're like Elon Musk but you actually are keeping up with whatever's going know, you can make a different kind of person but that's kind of to me the interesting separation from these other know entities.
Speaker E: I wonder how power dynamics would then translate to this digital immortal self of persons versus corporations. I feel like there'd be a lot of crossover between what is currently the norm and corporations have a lot of power right now. So for them it is in their interest to transfer the power dynamics so they can keep playing the same game. But within the AI world.
Speaker D: Our social graph is monetized like that I know you or that data is partially a thing that exists between us but then it's partially a thing that is extracted and I cannot think of a more effective extractive mechanism than friend. And I think the incentives are currently set up to produce such an entity.
Speaker B: What do you mean by that?
Speaker D: Meaning that under the current under the so if you are when I send you a message over instagram that relationship has been quantified to a certain extent versus if I'm talking to a digital entity that I'm talking to, a lot, sharing a lot with. If it's a digital entity of my grandmother that is hosted by a company and the data rights between me and the company are extremely asymmetric, then I am talking to something that is basically kind of like extracting my soul.
Speaker B: You don't mean like current friendship between humans, you mean future friendship.
Speaker A: To Eric's point that's happening right now. You have chatbot companions that could I'm not saying that they are insidious actors or anything like that, but the power they're sitting on. People use these things a lot. They talk to them a lot. There's a lot of information. It's very intimate. It's a lot of stuff that information probably could be used for in this.
Speaker C: Game, in the I game. It's like how intimate or interface. And I think Apple did a really interesting job in that.
Speaker A: Because it's going to play this stuff, okay? It's going to play humans are relational. We're relational animals. We care about each other. We form relations, right? And we have kinship relations to our family, to grandmothers, fathers, mothers, et cetera. And that's really powerful.
Speaker D: Right?
Speaker A: It's a very efficient way of extracting things from you, because who doesn't want to honor their grandma by making this digital shrine, right? But then digital grandma is like, tell me about I forgot my password.
Speaker D: Yeah.
Speaker A: Could very well be, right? It's like a honeypot operation, honestly.
Speaker H: I was at Defcon last week. This is a security conference for hackers, and there's a social engineering village there. These people aren't just interested. They're interested in all kinds of attack vectors. And while their focus is the digital infrastructure, people are interested in lock picking and other things that are related. And the social engineering village, the goal of Defcon is not to is to create safeguards to combat these kind of things. But anyway, the social engineering village had people go into a booth. They have a set of information that they're supposed to get from someone, and they'll call them randomly, and then people will watch, and we'll cheer them up. They're like, oh, my God, he got they're paddling. They go to a call, get them to say information. And there was a talk we went to and a personal psychologist talking about using unrestricted LLMs to engage in misinformation campaigns was just like, here are a bunch of psychological aspects that we think about in terms of being attack vectors, desire for reciprocity, scarcity, worries. And they just listed a bunch. And he's like, try using the system. Try to get it to create as much damage and violence as possible, and just ask it to make use of one of these things to get a sense of these. Absolutely. These same things that are useful for each of us are definitely like, levers of manipulation for someone else who's like, this is how I can manipulate this agent of and extract value from it.
Speaker F: That was like, the Cambridge Analytic degree and for a variety of different purposes.
Speaker A: So I'm just looking at the time. We're nearing 330. I think this is a wonderful conversation. I want to keep going. Maybe we should start wrapping things up in, like, 1015 minutes or so. And on that point that you make, because you've been making this persista or, like, in your social where it's trying to learn stuff from you. Right? Yeah, no, just interesting because it has a goal supposed to like it talks to you. I tried talking to it. It's like what's your favorite color or whatever in your playground?
Speaker D: Right.
Speaker A: So yeah, it's just like you could get information from people.
Speaker I: You want to pursue a different path.
Speaker C: Yeah.
Speaker D: I did experiment briefly. I didn't publish this, but I did experiment. Can we triple tap on something really quick?
Speaker H: And it was what Ian was saying. So let's just like I guess it's moral or philosophical. Is it best to immediately uncover best attack? Like, I'm really confused because I can think of some really messed up, probably functional shit.
Speaker D: Right?
Speaker H: And is it best to just immediately start publications or presentations on it? Because aren't you thus a step closer to counteracting it by hive mining the solution? So it's like obviously it's a snake eating its tail. Like it's a cat and mouse game. You're never going to I don't know if there's a reasonable answer to that question, but I'm really interested. What do you think about that? I think this is a different topic and we can talk about this after the fact, I think. Very interesting one, but just to not open up new areas, I'm going to just offline that.
Speaker D: Yeah.
Speaker H: Because well, I mean the only way that I link it back to digital immortality is writing like viruses into the program. And I think that's actually reasonably a fantastic tag vector if you charge for it. Okay, for sure.
Speaker D: But I do think the topic of privacy beautifully ties back to the question of where do want additional body versus two directional body is. I think our biological body is in sense, like really well designed to be robust to build external. We just haven't figured out yet. Is that transition going to essentially allow corpse bad individuals, whatever to extract information from? I think we do have this wrong reaction to that in a way that we care about our public. We don't want some systems to just out from our brain at this point at the least.
Speaker B: As it stands right now, I don't trust any of the large corporations, including the ones we work for, to be the steward that creates these things. But then the question is who might? Right? What's the alternative even thing?
Speaker D: Like even if you create your own super half proof body and put your conscious onto that, it's a technological system that is the shared language across engineers and everybody. There would be much more weakness.
Speaker B: But within our economic political reality, these are really resource intensive things you make.
Speaker H: I feel like there is I'm maybe slightly more optimistic on this particular point of capitalist incentives because I feel like there is huge value in providing me the executive assistant that we kind of talk about that understands what I want and acts towards it. And there will be some that are like and here's the executive assistant, but it also makes Netflix pro Netflix decisions. And I'll be like, that's cool. I don't really want the Netflix biased one. I don't want the Amazon biased one. And so I believe that there is enough value to provide me a relatively agnostic one. Whatever that.
Speaker B: And this is where Siri Alexa and all the generation of Google of voice assistants, including Bixby for Samhunk's case, failed, is they were able to provide some of the human value, but they weren't able to provide enough commercial value for these projects viable. And therefore they internally recently, just actually, the Amazon hardware chief just got fired. But, like, all those things, right? That alignment of human value and commercial value, it's hard to find right now.
Speaker A: Totally.
Speaker D: We have a very small number of them presently because the extremely high economic costs are actually producing them before. But in the last year, that's changed dramatically. So as long as there's not unusual, we should end up seeing a plethora.
Speaker H: Of these things, both the barrier and also maybe we'll need a different economic model. How much? If I really believed that I'm not just getting a service, but I'm having truly a digital twin that acts on my behalf in a trusted manner, how much is that worth? It to me? A month, probably $20 a month, for sure. Probably more than that.
Speaker D: No.
Speaker H: I asked people, like, a couple of years ago, how much would you pay for where we are checking me? And they were like, a dollar, $0.50. Like, very low. Because they can't really imagine the value that this can provide. How does it fit into my life? But I think the value will become obvious where you're like, yeah, you spent $100 on my thing a month.
Speaker D: Pay my bills, do my taxes.
Speaker H: It does all these things. Maybe that's a source to capitalism.
Speaker A: And maybe we should start wrapping it up here. Sounds like a good plan. Thank you for coming, everyone.
Speaker D: And thank you for participating. We can go around and everyone can share. Yes. New ideas came up, new thoughts that you were challenged by or things that you're really interested or open questions you'd like to talk about in future sessions too. And we learn, obviously record these things, digitize your consciousness, remember you forever.
Speaker A: Yeah, this is part of it.
Speaker H: The salon is being immortalized, at least. No individual here, but the salon, where would what so far, we are in the let us have the data stage of things. And I would love to talk about after. Let's go around, but I would love to understand more about how people would like to interact with this information. And we can talk about that in detail in post.
Speaker D: Do it in post.
Speaker A: I can start with the whole spiel, the thing that you brought up at the end that we were all talking about. The ideological more like lofty things because we're now sharing things. That was challenging or something I learned or something that opened up some new ideas. I thought it was a very important point that you brought in thinking about the economics and material basis of how these technologies will be formed. Yeah, go this.
Speaker B: Mean there are many interesting things. I thought what Ari mentioned in terms of our biological substrate versus digital being totally different soils, I thought that was an interesting point. But also I wonder if it's true. Recently Joey was showing us this giant complex chart, which is awesome with just being able to make a command to Alexa and have that being fulfilled, like how much human and labor and natural resources going to that. It makes me feel like it's easy to overlook the planet and the human cost for a digital reality anyway. It's not a fully formed thought. I just thought that was interesting.
Speaker I: Yeah, there's a lot of really interesting threads that we followed here. Third or fourth, I don't know at this point now, just the gray areas of it and how in the immediate future these things will manifest and what things will affect that society, corporations? I think that needs to be continued for sure. There's a lot to unpack there. And that's where, just from the Pragmatic side, how can we actually affect things? There's a lot of value there, for sure. I think the discussion on why we want this was also interesting. I think I would love to pull a lot more too. There was a lot of interesting reasons and values and solving giant macro problems with nothing that really thought of in the context of digital immortality before.
Speaker E: I was also super enlightened by all of your perspectives. I like the diversity of just being really imaginative at certain points and then you bringing us back to reality and then us talking a bit more about what it's going to look like with the current systems that we have. So I think I'd be more interested in exploring more of like, okay, let's identify these are our constraints in our current society. And with these constraints in mind, what can we do in the different subfields that we're in, like neuroscience, governance and things like that? Also really interesting points about ancestry and how we have human consciousness kind of in a capsule. We've previously done that with books, but what modes of healing can we get from being able to talk to our ancestors? That was super interesting. But yeah, those are my takeaways.
Speaker H: If I were to be super honest, I was picturing this conversation swapping out different individuals walking along the street with infinite simulations of different probabilities or sorry combinations and permutations of how we could have attacked each and every topic. I just think it's really interesting. Some of these feel as though they have finite end states to them. But also a lot of this may never be solved. I feel like we maybe over index on how intelligent some of the intelligence are going to be in the future. I think some of these are like n number of problems to find solutions to. But then maybe in the more basic sense, I was thinking about like, okay, so as we expand out how many times we can create worse things, are we creating more problems ourselves? Like, what can we counteract? Which is what I responded to with Ethan.
Speaker F: I really liked the discussion kind of to echo previous comments on the why. I think the concept of digital twinning gave me words to describe, I think what was kind of seemingly in the area in the very beginning of the conversation, in addition to more kind of what exists in our current power systems and economic incentives.
Speaker H: So these are all fantastic cool. I think my open question maybe related to some of the other, like, what are the practical things under constraints is I think this digital twin perspective is a continuum, right? Digital immortality is kind of a fun idea, but it's like there will already has been representations of my agency encoded in recommendation systems that kind of outsource some of my decision making. And that will continue to happen in many different ways. And I'm curious how much agency I'll have over that ability, how much I will trust it, how much it will feel like me, like a trusted executive system, that kind of thing. And the other open question for me here is none of this sounded like my idea of what at least a selfish version of immortality would. You know, if it's mostly for societal value, how do we allow Ian's great thoughts to continue extending? Is it relevant that my thoughts are still maintained separately? Or can they just be part of the soup of 21st century AI. Knowledge that moves on?
Speaker G: I'm just absorbing a lot of these points around how I actually go about building my business. I think there's a lot of guardrails that I need to think about a lot more. Creating digital twins, what does that mean for identity? What does that mean for privacy? I don't have answers yet, but I'm going to be thinking about this a lot more.
Speaker E: What's your business about?
Speaker B: I guess, what's your business about? You.
Speaker G: Trying to talking about recommendations and personalization. The way it's been done all along is that every one of these platforms has one understanding of who I am. And there's no way to have this holistic understanding of the things that I look for, prefer there's no transference of that information across that data is holding. So can I create a system that brings all of this data into the control of users like myself, consumers? What path can I build to make that Internet experience more personal such that we own this digital twin?
Speaker B: I actually have the same questions as you. So I think before copying or moving your personal data to the digital world in order to create a digital twin. But how do we define personality? It impacts by environment, it also impacts by education and also emotion. But also how about intelligence? Because all that involves together is all interconnected. So is it going to move people from known physical world to the digital world? Can I modify my intelligence? And in that kind of case, is it fair and how much that you can control to create the other version of you?
Speaker D: Probably there's going to be a feedback loop. You modify your personality and then you want to modify it in a certain direction only.
Speaker H: I mean, we do this all the time. I don't know about others, but I have been exposed more and more to how the environment around me supports my own growth. And the more I am aware of that, the more it becomes a thought.
Speaker D: Which is like, okay, I should put.
Speaker H: Some intentionality into choosing that environment just for the kind of growth that I would like.
Speaker D: Extreme meta thinking, anyhow to make thoughts quite nice. I can never be summarized. I'd like to know more about I think we talked a lot about as a society that we want, but also there's a huge aspect of we talked about a subjectivity, individuality personality, but I don't know what I want through this war, what they might want, like separating them. And I would think about what someone very specific might want because they're also by group of people like this certain reality or this connection with their body for different reasons. What those desires you? I have some ideas, so roll with me for a SEC. Yeah. Okay. So the legend of Troy, right? Achilles went to the oracle at Delphi when he was a baby. He was a kid and the oracle told his mother, achilles will either live a long life of happiness and peace, raising many sons and farms, or he'll die young and be remembered forever. And so I think this kind of immortality as guaranteed by things like the Iliad Homeric immortality, seems to be almost assured in the sense that we can capture ourselves with some degree of fidelity and be remembered and our bodies works. And that's only getting better and better with time. And I can kind of develop this senate of learned elders that are a repository of wisdom that we can call forth and maybe get our own property or something like that. There's this other version of more selfish immortality, which is I want to stay alive, I want my consciousness to persist in some new format. I think that's a lot harder. But I think maybe an interesting thought for the future is the greater the degree of high fidelity representations of a person's personhood in a digital format and the more compelling that is for other people who are normal people. Cracks open this avenue for the assignation of personhood to intelligences that are not perhaps based on historical replication and it also opens up the creation of new persons through hybridization of mature historical replications and so forth. And so the number of types of people I think as soon as you start to have people that are very high fidelity representations of their historical self, you might not know if this AI agent is a historical copy or something new or something hybridized. So the numbers of types of people can really increase in the future. That was awesome. Yeah. I really enjoyed a lot of things we talked about that were even though I pushed back into culture, it was very interesting to hear people talk about the stuff we talked about in its connection to family. I'm currently working on this video game that has a lot of stories in it, and it makes me want to write more about your relationship between your clones who you sort of like, set your digital clones that you sort of set free.
Speaker H: You cut the cord.
Speaker D: You're like, yeah, just grow. Just go do your thing. We'll check back later. And maybe also you have these clones of your family. You have this extended digital immortal family who they can continue to learn. So again, they're just all out there. And you exist among your kind of biological milieu, but also your kind of digital evolving and ongoing learning. It makes me want to write about that a lot, because I think it was a pretty good science fiction scenario.
Speaker E: I thought it was a really interesting conversation and a lot of really thoughtful points.
Speaker C: I think some things that stood out.
Speaker B: To me was one, I feel like.
Speaker E: In the conversation, there was a bit of separate from the body, and I'm not so sure if that's true. I think that the fact that we experience it that way is actually just a sign of the degree of homeostasis we exist in. And so I don't know if I think a consciousness that exists outside of human body, how we can call that.
Speaker B: A human consciousness anymore.
Speaker C: So I thought that was just a.
Speaker E: Really interesting shared mental frame that I.
Speaker B: Felt like everyone had.
Speaker E: The second thing I thought was really interesting was I think there was also kind of an assumption with the idea.
Speaker C: Of digital immortality that the self ecstatic.
Speaker E: And I'm not so sure if I.
Speaker B: Think that's true either.
Speaker E: There's this really great quote by Sark that I really like where he was interviewed about something he said, like, months before, and he was like, I'm not even the same person I was last week, let alone months ago. And I think that that's true. And so if you have these digital.
Speaker C: Cells that even if in the ideal.
Speaker E: World, they're a perfect clone of who.
Speaker B: We are right now, the fact that.
Speaker E: They would have these experiences of talking to these different people or whatever would happen in this metaverse, I think makes them therefore not to you anymore.
Speaker D: If that makes sense.
Speaker A: Sounds like such a cop out from South Kudo. Like, oh, I'm not the same person as I was last week. I can't be held accountable for things I said.
Speaker H: Super cop out.
Speaker A: Yeah, that is the point.
Speaker D: Well, I don't really want to say.
Speaker I: Anything after that, so I'm just going to pass.
Speaker C: Yeah, I think what we discussed here is just thought proverb walking for us, idealists for things to happen. I think in the humanity scale, there should be ego death because it sounds like all this current agenda and politics and economy and companies deriving value and value exchange and everything, it's just like it either has to be that society has to be just changed so drastically. And that's what we've been talking about. Right, but we still under this narrative of this giants and politics and countries and everything. And it might continue for a long time until we die.
Speaker D: Species.
Speaker C: Okay, I'm sorry. I don't want to go that dark, but yeah, I mean, my learning has been that I think that it's good to know that we are not really entities, but who am I am? I mean, my thoughts, my environment. And I really support the point. Like, Arthur saying he's not the same as it was months ago, and I don't even see my point. Like, if I wanted to replicate my consciousness, I don't even see the point of doing that because I also personally believe that I changed so much. I believe innovation. And why would it even matter to me that when I die, if I die, when I die, there will be some copy of my consciousness, but I don't even think that's going to be me anymore. If you believe in my growing consciousness, people that experience different experiences, the question is, like, why do you even care once we die? I personally care about my writings, some points of view I have, but I don't really care being here forever. One and characters, because it's not even about me, but about my supporting narratives, right. My vision to new life.
Speaker D: Again, thank you.
Speaker C: It's a really great competition.
Speaker A: Thank you, guys. I'm worried about the recorder running out of juice. Goodbye.