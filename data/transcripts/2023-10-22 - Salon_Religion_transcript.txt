Speaker A: Okay, so the topic this week is religion, as I hope all of you know. And I'm not going to introduce this topic too much. Instead how we like to start and we can spend a long time on this, so please don't rush is we're going to go around and introduce ourselves. And what I would love to hear is your, your name of course. We're going to try and repeat our names multiple times throughout so hopefully we can get to know each other. And a little bit about your background, especially if it can relate, like it could be your religious background, your professional or work with religion or AI, whatever you think is pertinent to the theme today and a question that's on your mind, something that you would love to kind of discuss today. Okay, so I'll start and then we'll just go around. So I'm Ian Eisenberg and yeah, run the AI salon. I have a background in cognitive neuroscience and psychology. And I then after my PhD kind of worked in hiring and now I work in AI governance. And so one of the things that I'm very interested in is both how do we, yes, govern AI systems. But I'm also really interested in how AI relates to how we govern ourselves and how we organize society. And another thing related to this topic is I got into this because of effective altruism. And while I'm, I guess culturally Jewish religion has not played much of a life, a part of my life, very much an atheist, but through effective altruism I've kind of seen that it's giving me some aspects that a religion kind of serves. It directs my life in some way. It sets like an objective that is kind of the purpose it gives community. And that brought me back to see like in the early 19 hundreds there were the secular humanists who very explicitly were like, I would like to create a religion without God. And so that's just like slightly opened up my mind to what religion can be. It's a very overloaded term and yeah, I won't say really what I'm mostly here to excited to hear what parts of this other people are interested in going through. So let's move on. Hi, I'm Joel Lehman. I've been an AI researcher for longer than I like to admit. Worked with little baby neural networks back in the day. Most recently I was at OpenAI working with algorithms that would kind of create their own training data and now I'm looking for something new. The way I relate this topic is that when I was younger, I was Christian and I kind of fell away from that faith kind of in like a militant atheist kind of way and now have kind of allowed myself more like a secular kind of Buddhism kind of approach also with a little tinge of EA in there as well. And one question I'm interested in is to what extent do kind of concepts of Buddhism apply to AI algorithms? Would they apply to AI algorithms architectures? And also would something like machine enlightenment be a different kind of solution to the issue of existential risk from AI? Cool.
Speaker B: I'm deena bigg. I don't have a background in AI at all. My background is in biology, specifically sociobiology and data and design, system design, and like community design specifically. And my interest in this topic I grew up Muslim, was not very religious and in the last, I don't know, three or four years have kind of become a lot more religious, but without sort of a paternalistic view of religion. But one where religion or God is in chaos and structure and the space in between and the space between zero and one and the infinity that exists there. So thinking about religion from sort of that mathematical lens, how does that play in AI? And I'm also kind of interested in cultural impulses and if AI is inherently monotheistic and how polytheism kind of showed up within AI. And.
Speaker C: I'm Maximpurlinko. I'm from Ukraine. I came here seven months ago to the US. I grew up Christian, but I had a TBI in school and that sort.
Speaker B: Of changed my worldview.
Speaker C: And now I'm atheist. What I want to find out is how AI will influence the worldviews of.
Speaker A: People.
Speaker C: And how will it influence religion in general.
Speaker A: I'm Kyle. I studied philosophy initially and then I switched to math because I wanted some more concrete answers. But I still kept studying philosophy on the side. I'm in the data analytics space and I guess I'm curious when he just said, we killed God, God is dead. Whether AI can kind of and we've seen people renounce religion within the last couple of centuries and whether AI can bring everyone back. Hi, I'm James. I work on AI and drug design. I was very active churchgoer in my youth through high school, but also in college and gotten back into it the last three or four years. Like go to church three out of four times a month or around that. And I guess I'm really interested in this because I think in a way, like, an AI can be like a similar crowd, like a human being in a way of just like you see yourself in it even if it's not there in a way. Some interesting questions around that religion. And I'm already very laid back right here. 45 degree angle the hut. Hi guys. I'm Rohan.
Speaker D: I just graduated from CMU in May where I studied cognitive science, but I also did a lot of multimodal vision language type of research. Now I'm a founding engineer at a really early stage startup doing AI agent type of research. But the religion angle is sort of similar to what some other people said. For me. I became militantly atheist at like age eight or nine and was like that until my late teenage years.
Speaker A: At that.
Speaker D: Point, I had some revelatory experiences about entropy and the nature of the universe, and I became a proto IAC. And now when this whole IAC kind of vibe has come more into the cultural sphere, I have sort of embraced entropy maximization as form of spirituality. And the other angle is there's a lot of alignments between these thermodynamic views on life and purpose and traditional Vedic religion, which emphasizes the role of sun and fire in life and ritualistic processes.
Speaker E: I'm sorry.
Speaker F: You said IAC.
Speaker D: Yeah. Oh, like effective accelerationism.
Speaker E: It's like sort of a Twitter meme.
Speaker A: But it's also real, also psycho. I liked the modeling. Besides asking a question, modeling like asking for definitions, because I'm sure a lot of us will come from different perspectives, and sometimes let's try not to use jargon, but if you do, feel free to do exactly what you did. So thank you.
Speaker G: Hi.
Speaker B: My name is Lynn. I don't come from the AI or spirituality space, just sort of more interested in it at a philosophical level. I currently work with the DoD on cyber policy. My spiritual background is one I was baptized Episcopalian, raised in the faith, and then sort of fell in and out of it over the years. Today I consider myself more spiritual. But the question that's been on my mind around AI and kind of our continued reliance on technology in our day to day is because for me, I've always come to religion at points of complete surrender. And AI is often used as a tool for us to better organize our lives, better maximize on a specific thing and real and control. In some ways, I'm interested in how AI can actually create space for that kind of nebulous place in between the randomness and how it can invite spaces for reflection in a world where we're really like.
Speaker C: Hey, I'm natalia. I'm a computational neuroscientist. I did my PhD in Netherlands, spent a total of eight years in astrophysearch, in brain science, and then I turned to my own company, and I am building the world's first online career incubator. And I'm here in Bay Area mostly because I need to be to know and better predict sentiment and better predict how AI is going to influence the job occupation right now. So I'm trying educated guesses in that respect to be a better career advisor. And with my spiritual journey, actually, I was baptized as a Christian. I'm polished, so this is a default. Like, no one asked for permission, but then my faith was challenged. When I was eight, my best friend was murdered, and she was the most religious kid in the classroom, so that made me think a lot because she was the good girl. I was not a good girl, and I was like, why was I spared? And she was killed, in the sense. And then for the next 30 years, I didn't really think too much about faith. But ever since I started my company four years ago strange things started happening. So every single time I tried to, I wanted to quit, literally, within a few hours, some savior would come out from somewhere, there was some unexpected money from out of the blue sky, or someone was coming to help. And every single time I had a bad day, there was action, reaction within a few hours. And I was like, this is just challenges my mind of a scientist, because it's just way, way against probability calculus. This is impossible. And I started getting more and more confused and starting to work again on my spirituality. And in the meantime I also got interested in Taoism. And Taoism is basically an art of easy living so that you're supposed to sell instead of growing. So use your natural try not to go against the force of nature so to speak lead things to natural flow of things and get a balance in life and basically more of a lifestyle than a religion. But now I can. My point of view right now is that there is some higher force that is a bit like light. So light has this duality that it has form of particle or a wave and it just manifests in different ways in different situations. And now I view up like godly forces that some form of a force that sometimes manifests more like a life force and sometimes manifests more as a person. That's my imagination right now. But yeah, I'm grateful to be here because that was also my royalty. So I think there's still a lot of work to do and I'm glad that you be here.
Speaker B: I'm saba imran. I am founder CTO of a company called COGE where we're trying to make it easier for people to apply LMS on their personal data and operationalize it in that way. So I have interesting insights about how normal people kind of engage with LMS and think about it how quickly they start personifying them. As for my personal background with religion or spirituality I grew up in a conservative Muslim household where wearing jobs and pray five times a day and then I deconverted when I was a teenager and also went through the militant atheist phase to write his passage. And then I started studying comparative religion a couple of years ago which has been a really interesting framing for me. I'm still an atheist but I studying comparative religion which essentially just takes all these different religions and draws parallels between them and how they're related to each other and how a lot of them seem to have common roots. Actually, a lot of the stories that you find in different parts of the world seem to be representing the same topics and events. It kind of helped me build this frame of understanding where people inherently are driven to search for meaning and they inherently kind of want to find some semblance of a higher order purpose of life. And I am super interested in seeing how AI kind of intersects with that based impulse and how people kind of, like, integrate AI systems into their spiritual practice and maybe even turn AIS into their little gods in their pockets or something.
Speaker D: Nice. Moving back. Wow. I resonate with a lot of things you just said. Kind of like, read my mind. I have nothing to add, actually. My name is Andrew. Welcome to my living room. Yeah. So this is really interesting. I'm interested in this topic in two kind of very different directions. One is looking at the historical role of religion in human societies as methods of meaning making and also methods of social organization. It's very easy to forget, but that for most of history, we organized our lives and our communities and stuff like that along really religious preception principles. And so now we live in this kind of scientific, rationalist existence where we justify decisions in terms of their economic benefit or some rational method, like kind of a utilitarian respect, really, as opposed to in recourse to religious precepts or moral truths that we think are eternal or handed down from a divine source. That's really interesting because now we have this new mode of interacting with collected bodies of knowledge, which for a long time were religious texts. And so our ability to recombine those and form new meanings from those things I think is interesting. So we can reinterpret past religious meanings, I think, in a very different direction. It's more just like, yeah, are we producing a god? Right? Can we produce some technological super being that looks that knows everything and sees everything and it has magic powers to understand physics more than us or something like that? And what does that look like? And I'm sure there are people today that referencing this EAC thing, whatever it is. There's a lot of discourse that it's like, we need to birth this kind of technological god. I think there's a crisis of meaning in modern life as it is because we've lost so much of our groundings and human traditions and moralities and rituals. And I think people are looking for new things to grab onto. And this AI god kind of fits nicely into this scientific, technical, rational, moral framework that we use to live our lives today. So, yeah, that's about it for me.
Speaker E: Cool.
Speaker B: Hi, I'm Amy. I'm a user experience strategist for an AI company. I do on a day to day work with people who, for the most part, are users who have some interest in AI, but many of them do not. Many of them do not have any intersection. People who are still grappling with the meaning of life. In terms of spirituality, I'll keep it brief, not religious. We grew up in a household where religion is supposed to keep leapfaging your culture. You don't think of that as religion. And that's really for us Buddhists. And so it's always been sort of a guide without really knowing it. I didn't have a seismic shift of, like, what do you guys call it? Military? Yeah, military. I never had that because I didn't really think of God that way. But what I did, my intersection of religion was when I worked in Israel and I worked in communities where northern parts of Israel particularly, where there are a lot of leaders who build their life around it, and particularly apocalyptic folks. And a lot of interviews in those times were of people who slowly started to believe that AI is the coming of the same thing with apocalypse, is that it's coming. God is going to come down and save us from this world, and AI is going to be the responsibility and so many sense. I'm not interested in AI, at least so much for myself. I'm more curious as to what will AI be for religious communities. How will they interact with it? What will it mean for them? What meaning will they derive from that, and how will they see them act upon it?
Speaker D: My name is Josh. I guess I haven't been religious for a long time either. Undergrad and things like that were kind of things like that. I ended up kind of on, I guess, leading with physics as my religion and then what turned into what I call trans anthropocentrism. So I guess most recently I viewed myself as like an anthropocentrist that doesn't follow specific religion as a way of getting closer to something like trans anthropocentrism. And then physics of kind of the guiding star. And I curved things for, I don't know, 1015 years. And then maybe seven or eight, six or seven years ago, I was thinking about what AGI would mean, and I was walking through some museum and I saw some treasures from some random empire 200 years ago, and I was like, these people mean shit. Nothing. And I went through the whole existential cris again. And then I summarized it to myself as like, you either be a God or you be forgotten. And I'm kind of stuck with that narrative for a little bit, which is, I suppose, a little apathetic. And now I'm starting to look more at mortality in a different way, and so that's what I'm building towards. And there's like a longevity mortality kind of AI intersection I'm working on and a religion and AI at that intersection.
Speaker F: My name's Corey. I don't come from an AI background, but I work for an AI company. I've been customer success at Pinetown. So I've had to ramp up on AI and elements very quickly over the last year while helping other people ramp up quickly on it as well. So that's been an interesting journey. Religiously. I was raised Catholic, very Catholic, went to Catholic school pretty much my whole life, flirted with the priesthood, decided I wanted to have kids someday. So I didn't do that. Never really went through a full on militant atheism, but did go back and forth from Catholic to atheist to nondenominational Christian back to Catholic briefly. None of them ever really fit, but I knew that I was looking for something. I was looking for some way to make meaning of the world. In the last five or ten years or so, I've started gravitating more towards Neopacanism. Part of that was an attempt myself to try to get in touch with some of my ancestral roots and understand where people who came before me came from and what their lives were like. And reading through a lot of the myths about Thor and Odin and Loki, I realized that these myths aren't trying to explain where the world came from so much as contextualize it so that we can understand how we fit in the world. And there's a lot of lessons that we can pull that might not be neatly apparent. There's a myth about Thor taking place of Freya at a wedding to trigger giant. Well, there's an important lesson there about even the most powerful warrior can do great things, but he embraces his feminine side. So anyway, I'm very interested in seeing what AI does to help people again, to continue to contextualize the world and find meaning that suits their life and their strategies.
Speaker H: Hey Josh as well. I work in advocacy work in corporate philanthropy, and I also was raised Catholic, but was pretty critical of that even as a toddler to my parents and babysitters and priests chagrin. And I think instead of going militant atheist, I went militant agnostic.
Speaker A: So I was like, I don't know.
Speaker H: And you don't either. I'm probably still kind of there, but basically in my work. Well, I guess as a young man I saw people using religion as sort of a power structure to cast out people who were LGBTQ or just had different ideas and sort of preemptively send them off to hell and risk us or tell us to steer clear. And I thought that was pretty gross. And then since then have experienced people motivated by faith doing more of that in even uglier ways or the opposite, and really just giving their whole selves and sacrifice to try and help others. So I think of religion as a way we make sense of the world, a way we connect to one another and make sense of that, but also a way we sort of wield build power. And I think that AI will be used for these things. I'm very confident and in my advocacy, I've always been curious about applying frontier sort of technologies to advanced causes that I cared about. So was writing best Practices for nonprofits using Web 2.0 tools early days and I was doing climate work when Twitter was pretty new and blogs were not super popular. And we were able to use these tools to kind of create a sense of how the world is perceiving different negotiating positions in these international treaty talks and had inappropriate influence over country delegations positions, or at least their view of how their own precision is being perceived. Just paying attention to these tools and using them allowed us to sort of give an impression that told a story. And I think AI, especially with LLMs and being able to tell stories so much more powerfully on its own, you're going to be able to shape how people see and experience the world in profound ways. And it's just inevitable that's going to be used with either new religions, existing religions. I work a lot right now with evangelicals. I'm trying to end the death penalty in the US is one of my projects. And there are people who, because of their faith, are really adamant in trying to kill people who have harmed. And there are also people because of their faith who are really working hard to protect life and leave space for people to repent and find their view of God. So I see it just playing out in these very specific, interesting, beautiful, horrific ways all the time. And I'm really excited and curious and afraid of how AI is going to be applied to some of the same things I already work on and things that I'm sure I haven't thought of yet.
Speaker E: I'm Taylor. Hello. People that I know. Yeah. So my background is that I'm a software engineer. I work in Climate, so not really anything related to this topic, but I do have a lot of interest in knowledge of AI, just through osmosis of being a software engineer in San Francisco. Yeah. My background is really defined by one thing right now, which is for the last couple of years I've been reading a lot of people call it the Western Canon, just basically like every great book of Western thought from the earliest time period, like Homer to modern day. So I've done everything from Homer to Spinoza, which was the last person that I covered. And that has basically been my main focus, just completely diving into and completely understanding all philosophical religious thought for the last 2000 years. That has produced many changes in me, as you might expect, as I sort of focus on all these different works over time. And although I was raised Roman Catholic, I quickly became agnostic in high school and have been agnostic ever since. About six months ago. I reconverted to Christianity because of logical reasons, rational reasons, and also irrational reasons that are really hard to explain. A lot of what I've learned has been to understand the limits of rationality as they exist. So yeah, that's me. Also. The main thing I'm interested in with the intersection of AI and religion is actually because of Spinoza, which I just read, who I think has a lot to offer in the space. He says that the goal of religion has never been to discover truth. That's not the goal of science. And philosophy. And that what religion does, is it tries to enforce obedience to a specific law or code through storytelling, through parables, through metaphors, all sorts of different things in order to help people to conform to a specific way of life. And I don't think that AI is actually driven to discover truth either. In fact, I think it may actually be designed to arise at a code or a specific way of being, or to tell people a specific perspective on the world that happens to be this conglomeration of all human thought into one sort of median. And I'm really curious to know how that looks or does not look like a religion.
Speaker F: I'm Kate Metz. I'm a reporter with The New York Times, where I cover AI. And for years I've been deeply interested in the concept that Ian described at the start of the conversation. The notion that the AI community has operated for years like a religion, that a lot of what we're seeing is driven by this sort of faith based belief that it would happen. It's almost like a self fulfilling prophecy. I wrote a book about the history of AI and the rise of neural networks. And when I got to the chapter about the rise of OpenAI and other labs around this idea of AGI and existential risk, the title of the chapter was Religion because you see a lot of the way these labs and these communities operate, you see a lot of the same beliefs and the same mechanisms that work.
Speaker G: My name is I'm already perceiving one of the benefits of being in a circle like this because there are so many thoughts that are pinging in my brain right now and I have to work to reel them in. I do not have a tech or AI background. I'm actually a college professor. I teach rhetoric and communication studies. I grew up in India, but so statistically unlikely that I was Catholic. But I was raised Catholic and did have problems with it because of its exclusionary nature, but also the patriarchy. And I guess I didn't realize how much that impacted me until it got to choosing my dissertation topic, which turned out to be the rhetoric of Catholic feminists. And ever since then I've had interest in how we talk about religion, but also how religion both knits community as well as sews division. So I teach a course on rhetoric and religion. My interaction with AI really has been last year at the close of the fall semester, we learned about something called Chat GBT. By the spring, it had completely upended college education. And I think the question that I'm coming to this conversation with is what does it mean for the way in which religion typically answers questions about our interior experience? And so it's been interesting to hear different variations on definitions of religion because there's definitely the institutional, which is very problematic. And then I've really also appreciated hearing stories of the interior journeys, which I wonder it's an imperfect word, but whether faith or spirituality kind of captures that personal experience which sometimes transcends the institutional. And so one of the questions I have is, given that one of the purposes of religion, I think, is not just to enforce obedience, but to kind of answer those questions that we inevitably, I think, at some point in our lives have about ourselves and what we're experiencing. What will AI and our interactions with AI do to either replace that or change that? Because I think, given the way that AI is showing signs of thinking for us, I think it's going to impact how we sort of experience our own humanity. And so, related to that, what is the role or what is going to be the relationship between AI and religion? And then a question that was raised earlier about how will religions respond to AI or leverage AI? I don't know if this is already a thing, but I'm assuming at some point in time, the Pope will probably have to write a letter about what the Catholic Church's take is on AI. And so that's a question I hadn't considered before coming here, but it's been sparked. Thank you.
Speaker A: Very cool. Yeah. The introductions are often one of the more exciting places because there are a lot of us, and as we move forward, certain topics will be covered, more others will wish we have covered, but we only have so much time. And so this is like the moment where people can be we can be seated, at least. Very cool. Hearing everyone's backgrounds and some of the overlap, either in religious or kind of like trending through atheism to something else, to some of the other perspectives I think you brought up where I wanted to go first, which is one of the things that is important for any conversation like this is to try and we're going to keep some time limit on this, to have some definitional clarity as we move forward, because there are a lot of different ways we can use the word religion. And I think it might be helpful as we move forward, to have certain additional specificities that we can use. And I'm going to offer some, and I would love to hear us talk through these for a little bit and then maybe we can have them as just our conventions for the conversation. So one is the idea of institutions of religion, and so these are not the actual faith, but the actual organizations that somehow dictate how these religions, like a particular religion is followed, how the Pope might respond, and they might have potential purposes independent of the faith aspect. I think that one, hopefully, is fairly clear. There's a kind of functional perspective on religion that with Taylor and Andrew, kind of brought up like this thing that maybe has this purpose of obedience for society. Maybe that's one of. The purposes of those institutions. But maybe it also solves some meaning making. Maybe that's a natural need. And so we can think about how does AI, for instance, support that functional need of religion or overtake it. Another aspect that maybe we can think about in that aspect is I sometimes think about religion as like the science of the gaps, right? Science, philosophy has answers for things and then for whatever else. There's science. I think, lyn you kind of brought this up a little bit. Like what if AI doesn't leave many gaps or has the illusion of not leaving many gaps? What space does that leave? Let's put that under. Those are like functional roles within humanity. And then I think there's this maybe last point of a belief centered view. There are people that there are religions and people who indirect religions because that is their faith. That's a belief about the state of the world, some relationship. And we can imagine new AI systems that are the thing that people are focused on religions about AI. But we can also imagine that religious perspectives, interpretations based in faith about how AI should be developed or how you should interact with AI. So those are the three broad definitions, I think, like institutional, functional and called belief. I'm curious, do those feel like they span the kind of topics and can give us a little bit of structure? Or does anyone have another kind of definition they would like to offer forward?
Speaker D: Are you saying that you classify religion as completely these three?
Speaker A: Yeah, I'm just trying to give us some language to use as we move forward and make sure that I have coverage over the kind of topics that we might want to talk about. Yeah, I think those three things, I think covered for me. But I guess maybe the additional function, if you like spirituality or access to spiritual experience, which maybe is related to meaning, but like transcendental states, that kind of thing, can you offer like I've always struggled a little bit with what do people mean when they talk about spirituality? Maybe we can also bring that into yeah, I think it's probably hard to pin down my naive take would be kind of about transcendental experience. So one thing people do in a church, though, they sing together. You can sense a feeling of unity which is related to meaning. Or like in meditation, you can kind of encounter crazy states or people take psychedelics also kind of hit kinds of phenomenological kind of states that really feel like they're one with nature, one with the world or something. It seems like that's a function that different religions all seem to kind of more or less converge on some part of that religion.
Speaker B: If I can build on that, it feels like there's the faith and belief, but then there's also like the embodied experience that happens within religion in the context of religion that feels different than just belief experience to it, which but.
Speaker C: It feels a little different.
Speaker A: Okay, so like spirituality or the spiritual experience that might not just be a mental state, but an embodied state is also something that we might think of as like a function that potentially AI can support. This sounds good to me. Cool. Then another thing that I heard in this kind of beginning, and maybe we can start with the name is just kind of AI as religion. That's one perspective. Religion through AI. Or maybe AI by religion, where like religious perspectives that are already either the institutions or the functions or the beliefs impact how we move through AI.
Speaker F: Will there also be religion about AI.
Speaker A: Yeah, that's kind of what I've been as AI. As religion. What do you mean by religion? By it?
Speaker E: Yeah.
Speaker F: So in that case, what I'm thinking of, there's a lot of utopian thought around AI. There's also Dystopian thought you have everything from AI is going to make the world a better and more just place to, oh my God, the tornado is.
Speaker A: Going to kill us.
Speaker F: And I think that because those are rounded in human fears, human hopes, and really just divorced from what AI actually is. And naturally it's a belief. Right. And it is a form of religious expression about what your expectations for AI are.
Speaker A: Let's start there. Does anyone want to build I think.
Speaker D: AI's religion has, like, in my mind, a couple of components, at least. One is this AI as established practice mean making understanding human societies like this kind of religious as practice. Right. There's also transcendental AI as salvation, which is this like deus X machina concept, which is very old idea that means God from the machine. Right? And maybe we can't see a way out of the problems facing us as a society. And we think things have to come to a dramatic or climactic apocalyptic end. And is there some kind of revelatory salvation moment here? Like it's called the Eschaton, I guess, which is like this rapture where some souls are lifted up. And I think now people are thinking like, oh, that's going to be digital immortality, and that's what rapture is going to be for us. And I think AI fellas it's more on the extremal end of the conversation.
Speaker A: But.
Speaker C: Historically, religion was often a product of humanity having trouble understanding something. So whenever you cannot understand how things happen in nature, then you create a concept of a God who steals the who pulls the strings from behind the scenes. Right? So my feeling is now when AI becomes so complex that we no longer can understand even software engineers behind the scenes, there's so many millions of parameters, and people start lose the grace grasp of what's happening behind. And the AI features are becoming more and more complex, and they astonish us. Right. This AI generated graphic designs like, oh my God, how amazing. And all the text created by AI. Everything gets in quality and we less and less understand how it works and it more and more amazes us. And I think at some point there will be a group of people, or maybe a large class of people who will start associating some broadly features with it just because they cannot understand how it's done anymore.
Speaker A: Create a holy book of just designed matrices and then if you understand it correctly, you can multiply them together to get the right answer. By the way, you don't necessarily have to raise your hand. So I appreciate but let's let the listen.
Speaker B: Yeah, no worries. Just one other thing that came to mind. I don't know where exactly this would fit within the framework, but just the role of ritual and worship that's been such a big part of religion, prayer. And even if you kind of go into spirituality, things like yoga, your repetition of things and a group of people coming together to do something, what sort of rituals might be kind of built into AI that kind of unites people together? As far as I know, there's really nothing like that currently technology. And I think that's what it sort of lacks in its ability to really kind of bring people together in a really powerful sticky way. Yeah, maybe that's baked into AI as a religion.
Speaker A: Yeah, I definitely want to return to the rituals that are already being created. But right now I would love to stay on this. Like so we have this AI as savior or apocalypse. We have also this point of not understanding how it works, which both of those seem prime to continue in this direction of giving religious significance. So let's stay on that for just a bit and then later we can come back to rituals. Were you going to say something on this?
Speaker D: Yeah. So I think it is sort of interesting how you have this, at least on Twitter. The duality is like the people who think AI is going to kill everyone and that's like one very God as a destroyer who cleanses the world and repopulates it with AI. Basically that's like one view that a lot of people in the safety community have. And then on the other side you have ex who are sort of ambivalent to whether AI will extinguish humanity or meld with humanity in some sort of transhumanistic fashion. But regardless of how that works, sort of see it as a savior. I think the latter camp, which I definitely lean in the direction of sort of it's almost like having trust in the AI God almost where.
Speaker A: Regardless of.
Speaker D: What our AGI God decides to do, whether that's extinguish us as humanity or integrate with us, it fulfills the broader purpose that the AI emerges for which I think a lot of people in the EI community believe will necessarily be aligned with the underlying principles of technology. And like entropy maximization. Yeah, sorry, let me just finish the thought. So I guess what I'm just pointing out is that the two sort of camps that have the strongest views on AI doom or saviorness. Like both of them are sort of viewing it from in some sense like a religious or eschatological angle.
Speaker F: I just have a sentence just to point out something that says, yeah, we're putting our faith in the AI god. I think we're also putting a lot of faith in the AI priesthood which in software developers should create AI. And that's the healing component. I think that's the point we probably need most careful about. No offense, AI researchers.
Speaker B: Totally agree. It's pertinent to what I was going to bring up as well. I think there's an interesting thing here around the term that we use with AI and religion because I think a lot of dominant religions tend to have been centralized over time. There are still holdouts of examples of religion where they weren't exactly centralized and are still being practiced today, but a lot of the major ones were centralized. And it creates interesting analogies to how you think about AI systems because probably if you're forecasting the dominant outcome that you would imagine is that there are going to be probably a small number of companies that have a dominant relationship with which AI people are using. Like OpenAI is probably going to be one of them and then it'll be like API to God situation. But then there's also all these open source models that you can download on your own and fine tune and there might be interesting things that arise around people can customize their religions and customize their practice and share it that way. But I totally agree with you and whatever that centralized company is that has the dominant share of control over the big AIS, the engineers and product managers within that company kind of get to define what the thought process is for decisions for other people and defining that religion.
Speaker F: Oh my God, OpenAI users are going to be Catholic Church, foreign users are going to be Lutheran, and hugging based users are going to be the Ambapist. That debilitates.
Speaker A: Sorry, were you going to say something a bit ago?
Speaker B: As we're talking with these kind of few camps where it's how religion is shifted or AI as religion. And I don't know if this is a real thought, but AI's capacity to self generate religion and have its own religious thoughts separate from a human experience as kind of a thing I'm interested in understanding if that's possible or if that is.
Speaker A: Last time. At our last AI salon, we talked about model collapse a little bit, which was the idea of AI systems ingesting data created by AI. And that leading to these systems that don't work well. And it was brought up for a moment, which is just a kind of fun example, which is for instance, humans are constantly ingesting human work and we seem to do okay. Potentially, AI just ingesting itself in some auroboros might make it really poor in communicating with humans in the future. It's like, in its own world, but maybe it can create its own culture and religion just in the shibalith of AI. Like self ingestion.
Speaker E: Yeah. One thing I'm interested in the AI in religion, AI as religion is just like it's really fascinating to me when people start listening to this and basing their behavior around it. There's like a step change to me between using AI as, like, it said that thing isn't that so funny? And it tells you to do something, you're like, all right, well, the AI said to do it, so I'm going.
Speaker D: To do it now.
Speaker E: That's like a huge change to me. And actually, I think that AI is a portal is another way of understanding it. The religion doesn't have to change. You can still have Christians who believe in Christian theology and use AI as a portal to God through AI and be like, what would Jesus say about this? And then Jesus talks to you through AI. And it's like, wow, I got my answer. Suddenly. That's playing a very different role in religion, that it doesn't have to create or be religion. It just has to be a portal through which people think religion is coming through.
Speaker D: I think there's a parallel there just to quickly build on it, which is like the role of the priest class was Forever was usually just like they are the interpreters of divine scripture. There's like sacred truth that they have some superior understanding of and they help translate it to the rest of us. We go to the rabi, we go to the priest and we ask them, what should I priest GPT, what should I do in this situation? I think one of the things I struggle with that spectrum, doom with Bloom or Savior, is it's kind of like an agency versus complacency spectrum in my mind. And I think both of those are complacent in the sense that and this is where I started out by saying I kind of now lean towards this idea of be a god or be forgotten. Because when Anthony Lewandowski started The Way Forward or The Way of the Future, which is like a religion, he started in 2018 that basically just said, shut your mouth, accept the AGI gods. I mean, I'm gross oversimplifying, so it's correct me if there isn't much more.
Speaker A: He has a lot of other words underneath that top line.
Speaker D: Yeah, there are that. But I was just really sad when I read that because it took away a lot of agency, I think, for us as human. And then to your point, I think one of the anyone who's working on the models, I think we should have really baked in the idea that this is like human generated AI. Human generated AI. So that if we are wiped out. You don't lose that tag prefix it with we created you. So even if you kill your parents, at least you know that we were your gods. And so I came to this notion of, like I said, be a god or be forgotten. Because I feel like we have the agency to build these things. And I think by thinking of the spectrum of we are doom and gloom or savior, we lose sight of the fact that we are the ones that are creating the godly capacity. Isn't it funny how we're fashioning this in our image? I did say I'm inherently an anthropocentrist. I don't think we are the best species of all time, but in this current time. So yes, it's narcissistic.
Speaker B: I think there's an interesting derivative point of that where we're talking about how AI has not become our interface to religion, but we're effectively trying to do that to AI. So we talk about the alignment problem. We're effectively trying to kind of enforce the worldview on the AI. Be like, you cannot exit this worldview and you have to abide by this. And so I guess one of the core questions there is how do you enforce a religion on the AI? Whereas religion should be like, I protect humans or I'm only doing things with humans.
Speaker A: That kind of comes back. So from that perspective, I think one of the goals of maybe one of the positive outcomes is an AI system that does seem under human control and kind of steerable and understandable. And while there might be some people that think of this as some unknown AI god, hopefully we're like, those are some oddities because we have such control over it. But in that future, it kind of becomes the spinoza religion. So Taylor brought up this idea, know, if you have this system that is just ubiquitous, it doesn't even need to be for a particular group, but it's ubiquitous and it has some perspective, right? It writes in a certain way. It's a little more resistant to certain kinds of thoughts when you talk to it about philosophy or god. It has a certain way of talking about it on a mass scale that has the ability or the consequence of shifting our kind of cultural conversation and that could be turned up or turned down in terms of its extremity all the way to obedience. And so that's like, maybe the religious use of even the hope this is me speaking, I guess the hopefully irreligious framing of the AI system where it's not placed as some intelligence removed from us and unknowable I'm forgetting the word interesting about it. That mathematically. The truth is out there in a way, of all the answers that we need can be found through modernism science. That's a view people have. And AI is kind of like the creation of this is like the extension of that view. Like the answers are out there. We just need to build something to find it as opposed to the answers or to be written by us. I think that's where it comes from, where it'd be like, I could live my life perfectly if I can find the correct equation to all this jazz or figure all this shit out. And those answers exist within math or science and maybe even in a literal. This is a view people have. Not necessarily my view that I'm saying that's, like, if we do enough research, it's enough research on it, we can figure out how to change our genetic code or whatever, like crazy out there ideas, as opposed to we have to create our own answers in life. And I think AI is a thing of, like, we throw information at it, we can more quickly find those answers. If you're that point of view. I'll give some kind of language that I like that I think helps articulate this thing, which is the difference between trying to understand or define a world model, like how the world exists, how things the causal relationships between things, like what is the structure of the world? Or even, like, human behavior that's part of the world and separate that from a values model, which is like, what do I want the world to be? Or what states of the world do I want? And it seems, from that perspective, more obvious to me that we could probably hopefully gain consensus and make a lot of progress in the world model side. But the value model side, what do you actually care about the values? Seems pretty hard to answer in some objective way. And so AI will probably impact that value model, but it's not going to be in a true way. It'll just be in an influential way. It's like the Archie question. Betty or Veronica, is there an objectively correct decision? I'm not following the reference. Archie. I mean, I know the comics, and I'm gathering that Betty and Veronica are both equally like the love triangle. Oh, there's a love the brunette and the blonde. Okay. Sorry. May I ask can we strike that from the record? It has been stricken.
Speaker G: The question is for everyone in the room who works closely with AI. I'm hearing one that we shouldn't forget that there are humans behind all of this work, and so we retain agency over it. And then there's a growing sense of we don't quite know what these models are doing. And so this sense of awe and mystery. And my question is, what is the percentage of that? How would you describe the percentage right now? How much of it is known? How much of it mystifies us? Just wondering.
Speaker D: There's a lot of good work on mechanistic interpretability recently. There's a phanthropic paper a couple of weeks ago. I think the general public thinks we know a lot.
Speaker A: Can you define mechanistic interpretability?
Speaker D: For people, I'll just say interpretability, like being able to understand what's happening inside these models at a circuit level, like what specific neural circuits are doing. I think the general public thinks we understand models a lot less than we actually do because we've sort of like as a research community, we've told everyone like, oh, they're black boxes, we don't know anything. And it makes for really good headlines, too. We don't know what it's doing inside, but it's super genius. But we understand a lot of we don't understand everything, of course, but we understand some fundamental circuits that do things like certain mathematical processes or like syntactic, like language processes. And a lot of people are working out and stuff for understanding how these models do. Reasoning, translation, all kinds of stuff.
Speaker A: I'm guessing for every AI researcher you ask this question to, you're going to get a different answer. I like analogies that move us away from AI for saying, like, we build cities. We build cities. What is the purpose of San Francisco? How does San Francisco operate? What does it do? Some people might have some approximate answers to those questions, but it's emergent, all of the it's emergent from the complexities of this thing where we kind of know the inputs a little bit, but the outputs, what does San Francisco do? What is this characteristic or whatever, or what does the world do, what does the United States all of these things are emergent properties. And so it's likely to me that our understanding of AI systems as they become more and more powerful is never going to be much better than what does San Francisco do? And we have some reasonable it would be nice if we could say things, oh, it does tech. That's not completely true, but it's like there's a gloss of truth to that. It'd be nice if we could have that gloss. Same thing. But I might guess a little more bullish than you are that mechanistic interpretability or any other behavioral signature is, especially as it become more and more complicated, that we're going to have a set of control. But I just don't think that that's particularly unique. Like when you're managing a team, what did that do? What does a person do? What are they about?
Speaker G: There are a lot of and I think to me it's less interesting what that percentage actually is as much as the perception of that. Because what happens when we don't have all the answers is we fill it in with stories. And in some sense, I think it can be argued that that's what religion is. And so I'm curious about what the stories are that are circulating right now that AI researchers are telling themselves. Even if, and I completely see.
Speaker B: What.
Speaker G: You'Re pointing to with the analogy, right? Like it will never be a perfect understanding. What are the perceptions of the understanding and accordingly, what are the stories that are arising out of those perceptions? Which is in a way the question that you were grappling with as well.
Speaker F: This very thing has been going through my mind constantly through this whole conversation. You talked about the priesthood. I love that analogy. Does the general public realize that this is a priesthood? They think of them as scientists or mathematicians. And a lot of this is about belief. Like you have one belief, you have another about this same thing. You both know what you're talking about, right, because you're in the field, but you really differ. And a lot of this is about faith. The general public needs to know that, I think, right? And this priesthood that you talk about, it's not just companies that have control over this. These are companies that have a lot of money that's been put to use over years and they're influencing what lawmakers think. And people with really what I see as really extreme religious beliefs are in a room with the President United States, right, telling them that what is essentially a belief, a faith based belief, is truth.
Speaker A: Right.
Speaker F: And I think we need to piece that apart and say that some people have this belief, others have a belief that is completely contrary to that and they're both worth listening to, if that makes sense.
Speaker E: Yeah, I'm going to push you on this a little bit. I don't think that the word faith is appropriate. I don't think that if you look at scientists who has the idea that string theory is true and an idea that a scientist says that quantum theory is true or whatever, I actually don't.
Speaker A: Know anything about theoretical physics.
Speaker E: But two different theories, right? You wouldn't say that they have faith in those theories. They'd say that they think that this one best corresponds reality, the other person thinks that that one best corresponds reality. But science is never 100% confident, the Bayesian calculation is never 100%, and that they think that they are, right?
Speaker A: Right.
Speaker E: So if something turns out to be true, like, oh, we can understand these things, people will update. Whereas in faith, people don't update. Faith does not update it's 100%.
Speaker A: One other thing to build on, because I feel similarly here, is early on in our conversations here and others, people would sometimes talk about their P doom, right, the probability of that kind of thing by bowl meme. And sometimes people actually have much agreement on the world. So the two people might come in and advise the government or whatever on very different things, even though they both think there's a 10% chance or something of horrific outcomes because they differ in how they and their risk tolerance and how they want to act upon that. So there's a confluence of both the estimate of the world and the actions that you think are appropriate based on that.
Speaker F: I hear you. And I hear you too. I think my concern is that if you say P dune, it sounds completely mathematical, right? It sounds completely scientific when in fact, it's not. Okay. It's a guess to me, that's faith, right?
Speaker A: Wait, so for you, if there's, like, a lot of uncertainty, a huge amount of uncertainty, it's faith.
Speaker F: Anyone can say there is a 25% chance that AI will destroy humanity. There's no proving that. There's no disproving that right now, and that is not a mathematical determination, but it sounds like it is. And that can mislead people. It makes people assume that, you know, scientifically that there's a 25% chance. But when you really don't.
Speaker D: That'S just a general misunderstanding of probability. Right? Because even when someone says 99% probability, like, yeah, you feel quite certain. But that's also, like, I think the general public maybe not be too intertwined, in fact, or math might think that that implies the sense of certainty to it.
Speaker F: I think that's the point. We're not talking about AI researchers and scientists. We're talking about the general public and their perception of AI researchers and scientists. If their perception is that, oh, these people know everything they're talking about and they know all this works and I don't, I'm going to listen whatever they say. And that's a step towards making them a priesthood. For all intents and purposes, they become the source of truth about what AI is, what AI can do, and how AI should be leveraged and used as a tool.
Speaker D: That's a good question. For those that are much more religiously inclined. Are there a lot of numbers in Christianity? No.
Speaker B: There is.
Speaker F: And some sects of Christianity embrace test of numerology. And of course, there's what's the Jewish Kabbalah? What's that?
Speaker A: The trilogy is like a trilogy?
Speaker F: Yeah, a lot of the ischatology in Revelations revolves around numbers like seven heads and seven hills. There's a lot of numeric.
Speaker E: That's not symbolism, that thing. I was answering a different question, I think. Are there numbers in the religion of Christianity? Is one question, yes. The other question is, does religion in Christianity depend upon mathematical numbers? Absolutely.
Speaker F: For some sense of Christianity? Absolutely.
Speaker D: Which I think I better answer. Does it involve any sense of like, I'm guessing not probability, but probability?
Speaker A: Yeah. What I'm hearing here is there's a way of engaging with the world that certain cultures, for instance, the rationalists, and some of the people that make up the AI researchers have adopted, they have their own language around those things, which the general public might come across as scientific truth. This is the same general public that probably, even if they're pro science, says we're for facts, not opinions, and basically don't understand a kind of confidence interval, that there's, like, uncertainty. And so that culture of speaking in probabilities about things all the time, which is a thing that rationalists do, might give the impression that this AI research is more scientific than otherwise. But I actually don't think that's because they are taking a kind of faith based approach, they are trying to reflect many aspects of uncertainty. Into a number for the purpose of conversation and that might have the downstream consequences of other people not recognizing what kind of claim they're interacting with. Right. A claim that is founded on a number of coin flips rather than my Bayesian estimate. Like, they don't even know the word Bayesian anyway. I blame Fermi. Fermi. They're like the Fermi questions because that sort of thing with damage is sort.
Speaker D: Of like, okay.
Speaker A: You get to a number like that by sort of laying out your thinking of the problem. But the implicit assumptions are that it's like all those numbers could be wrong. You just have the right variables for it. Yeah, totally. And once you get to that P, it's like, that's not necessarily a correct number, as opposed to, you should look at the thinking behind it. It's just represented in a number. And that's not precise. It's just like, I think this is how we model the problem. Right. So there are two aspects that are maybe the most extreme of the positive or the negative, where certain numbers are infinite, essentially, and that leads you to super positive or super negative. Maybe we can talk about the aspects where I would love to hear I forget who it was, it you who works with your company is like, how do people, like regular everyday people interact with LLMs a little bit? Yeah, I would love to hear the beginning of that. And maybe we can think forward a little bit. Not how the intelligentsia who is thinking in these ways, but maybe we can project out a little bit to where AI will interact with religion of the broader public.
Speaker B: Yeah, so I'll caveat this a little bit. We have a product, like an open source product that people can use, but DTBL is still technical. So it's not quite in that extreme of only academics and researchers, but it's not in that extreme either, of non technical people who've never heard of AI. They're still like AI hobbyists. But I think there's an interesting thing where so we use BLL, make it easier for people to run large language models on their consumer hardware and then plug it into their personal data. And then there's an interesting thing that happens where people immediately start kind of like assigning a personality to this and they start talking about it like it's actually their companion. It has thoughts and opinions and it thinks a certain way. And so that kind of immediate personification is sort of interesting to me. And then I think there's an interesting side problem there of how these things respond. Like for people who don't have as deep of a technical understanding, hallucination will not be immediately apparent to them. They'll be like, I must think this for a reason. And they'll try to take it as truth because it was like the language model that we would use. We were using Llama V two on people's machines. It's not that intelligent oftentimes. And then it'll start saying grossly incorrect things. It'll start almost like impersonating the person that it's talking to sometimes, which is kind of interesting because it's like, oh, it's a reflection of me talking back to me. The more technical people who are very engaged can understand that this is happening and these correct things are happening. But a non technical person will not make those jumps as easily. So those are some immediate, obvious sort of things that need to be worked.
Speaker E: What have you worked?
Speaker B: Yeah, I talk with mostly folks who like so there are two camps. Exactly those two camps. So I'll only talk about the ones who are not familiar with AI at all. A lot of times part of it is statistically true. Part of it is actually anecdotally true.
Speaker C: I will end up with political.
Speaker B: Political factions are actually good predictors often as to whether you like and believe in AI or not. A lot more conservative folks, for example, are very antagonistic towards AI, particularly of some demographic of older people too, within that sector. A lot of it are women. Women are actually quite hesitant and working class. Those are the two section that comes out. Is it completely proven yet? No, there's not too many studies on it. But this has just been sort of unfolding anecdotally within my own space as well.
Speaker F: Are there any trends that will explain.
Speaker A: Why those groups this is really hard.
Speaker B: It is actually really hard. There's a lot of messages that are spread politically about the implication of AI. And particularly, let's think, like working class folks who's having day to day having a job taken from them. AI is really good at sort of like repetitive tasks, doing particular repetitive tasks, and that they manifest in, obviously in software, but it obviously manifests in a physical space. And for example, a lot of people think that car manufacturing is somehow some synonym to AI, whether it's like that's how they see it as, because the whole concept of AI doesn't make sense to them. It's just someone coming in and doing that is like robotically doing things for them, is that AI is robot AI. They have no delineation of that understanding. And so that translates over to many working class being like AI taking my job, therefore it is bad and therefore I hate it. And this is actually not just true for older subdivision people, but much younger too, I think 18 year olds as well. People who are going in and thinking about their careers order. Yeah. So I would say, like, I can't speak for women just yet, but there are that within the working class division, this is not always true. You'll find some working class division folks who obviously see a lot of benefit to repetitive, who see value in AI, but it's not clear yet.
Speaker A: I'm wondering if one I mean, we talked about the ambiguous definition of religion at the beginning here. But another conversation we've had, I'm sure other of you had, is like, what is AI? It's a nebulous concept and it grows and you can see it in any startup, even before this year, who said, I'm an AI startup? And they have like a data table or something, right? It's like a thing that has grown and shrunk to fit the needs. And so that ambiguity and separating Chat GBT or LLMs or the whole AI system that is Chat GBT from an algorithm that is credit risk or a robot or automated decision processes that have been around for decades. If your interaction with one has been positive or negative, maybe it seeds or bleeds into your relationship to other ones.
Speaker B: Chat TBT is the first introduction for a massive chunk of people what AI is.
Speaker C: Actual message of AI.
Speaker B: But it didn't permeate and it started permeating everyone's life. And you type in something, a question and an answer spits out and it's like for someone who doesn't, there's a subclass of judge. Just like I'll take that answer right and take it at face value. I'm assuming that it was trained by knowledge base that is reliable.
Speaker A: I think that subclass is all people. I still like to do robotics and we always joked that the term robotics kept on getting narrowly more infantry as more stuff came out. It's like Dishwasher used to be the frontier robotics, but nobody would consider a Dishwasher a robot anymore. And it's like the stolen valor field completely gets on. And the original car was a robot even before self driving cars because it was big machine. But similar things could happen to AI because nobody finds a Dishwasher or a car scary. Because find cars scary. But yeah, I'm going to think of my Dishwasher as a robot from now on. Yeah. Thank you.
Speaker C: I'm not surprised that young professionals, young people are skeptics towards AI in large amounts because the AI actually created this knowledge gap in the job market. So whoever was already excellent and senior experienced and especially in the professions which require personal brand, whoever was already authority in their field, AI helps them even more to actually increase their influence, accelerate the work. What AI is good at is what was traditionally the jobs for junior employees, especially in It. So whatever was the easy task for fresh employees who were getting trained on the job now is possibly being done by AI. So now for whoever was already highly experienced and senior is actually gained from AI. But whoever was just entering the job market now has a higher threshold because it just needs more experience, more projects, more initial knowledge and projects to be accomplished to get the first job in it. So the AI is basically putting the bar higher and higher for the workforce. So it doesn't surprise me at all that young people are actually afraid of AI.
Speaker A: I thought the old people were the.
Speaker C: People old people also.
Speaker A: Both people only the core, the middle working class.
Speaker C: Yeah, I think they are just scared in general. Older people tend to be and women as well tend to be more afraid of taking risks and fundamental changes in their environment statistically. And young people, I think they're just skeptical for different reasons.
Speaker B: I wonder what people in the room think of we talked about AI's religion, but has that already emerged? And do we think that's already here and that is just true?
Speaker A: Well, it feels like you somewhat believe this, right? That AI has become a certain kind of religion or there are certain religious they haven't been necessarily seen themselves as like, this is the temple of religion, but something like that.
Speaker F: We've seen a lot of that over the years, and I think it is something that is not well understood for various reasons. And I think that people need to at least understand that this has happened over the course of many years for the average person, GBT was their introduction to this. And what we had is ten years of runway, really ten years of technical work, but also ten years of evolution in the community and a community becoming increasingly influential. I think that's an important part of what's going on here.
Speaker B: And was science a religion? Science not AI, like a religion before that also. Was the shift from religion or religious.
Speaker C: Bases of communities.
Speaker B: Did that shift to science? Because I kind of feel like it did, to your point, belief. But I don't know that everyone in this room would feel like that's true.
Speaker E: Are you saying that you think that religious thought has sort of, like globbed onto science as its foundation?
Speaker B: I guess there's something in faith that science is an answer and that being kind of like religion was like god is the answer. And then we shifted to, no, science is the answer. And as we get more and more, like in any field, as we study them, they just get more and more complicated and there's more and more to learn. So it feels like the shift to, okay, god is the answer, this unknowable ineffable thing, and then science kind of being the same.
Speaker A: Can we add definitions here? It sounds like you're saying that science or AI might serve one of the functions that we associate with religion, like answering certain large questions or being a process through which you can improve your so you could be like, have faith in capitalism, that capitalism will just work out well or accelerationism and just think that progress, like there's just a faith in that thing or the scientific process, I suppose. But that's just one component of religion, right? Is that kind of what you're yeah.
Speaker B: I'm not speaking so much to the institutions of religion. I'm speaking more to human belief systems and where we said some of the trans the world and where we pay attention to more.
Speaker A: So than I mean, in that way, then religion might have been. One of the functions of religion at one point was to bring rain for your plants. Didn't really was a very good use of religion, but it was one of the uses of belief. And so that use was subsumed by other sciences or engineering practices. And I think more and more questions are subsumed in that way. Fun fact prayer is positively correlated in the frame. Correlation is causation could start to fit.
Speaker D: Into the belief of the four areas that you were talking about when we kicked it off, like foundation. There are certain institutions, functions, beliefs, and like, embodiment sure that all of that can start to fit into the belief side of it, which makes you again, not somebody who knows the history of formations of religion. But then obviously the question is like, in what order does a religion form? Does it start with the beliefs, institutions, and then using that as a way to understand probabilistically? Could HCI become a religion?
Speaker E: Yeah. My viewpoint on this is like, I think sort of like the state of humankind is like or the existence of being human is to just be desperately searching for meaning. Essentially we exist and there's just infinity on each side of us and we're just like, why am I not in infinity right now?
Speaker D: Right?
Speaker E: And the answer to that question is everything that we look at, we try to put some meaning on, we try to say, Are you God?
Speaker A: Are you God?
Speaker F: Are you God?
Speaker A: Right?
Speaker E: And we kind of look at the next thing and say, maybe that's God. And we say to science, oh, that could be God too. And I think that AI has emerged so quickly and has had so much of an impact, it's impossible for me not to think that some people look at it and say it might be God. It's just impossible because human nature is just to look at everything and to be like, you must be the source of meaning. Or maybe I can find meaning in this because the state of being human is so incredibly unlikely and incredibly confusing. I feel like that's not really an answer.
Speaker A: Last comment on this topic and then I would like to it's a little bit tangential. Is it a little bit tangential or do you want to start us in a new potential direction and frame whatever.
Speaker B: You'Re yeah, I don't think this will take us in a different direction, but it's just building off of somebody's comments made me think about this other analogy. So if it's not God, it at least gives us an antidote to this discomfort we have with ambiguity and need for certainty. And it made me think of this talk that with Esther Burrell, the psychotherapist, and I think she did it at south by Southwest this year where she deemed AI artificial intimacy and someone created a bot of her and basically wrote to her and hey, I created a version of you and it solved all my relationship issues. And she laughed because she listened to it and it was kind of the synthesis of things she would say, because the bot took an archive of all her podcast episodes and bat out stuff that she would say. But from her perspective, it was still not a real thing. And I don't know, I thought of that analogy because they may or may not have thought like the AI version of her was God, but it was a solution to their problems. And we're already starting to put our faith into things like that over the real thing. And I think over time, just with increased use of this type of stuff, we're going to start to outsource our own sense of self awareness to that.
Speaker A: Maybe building off this and trying to hopefully start a slightly different direction for us to take. This conversation is there has been a trajectory over time for a certain kind of democratization of meaning making or religious experience, all these functions, and we can think about the priesthood that's been brought. Certain religious sects are like, we actually don't need a priesthood. You have a direct relationship with God. You can read this book and come up with your own ideas. And I wonder if one of the things you're talking about a relationship with the real thing. I don't really know what the real thing is. And one question I have is do we think that AI could in some sense democratize our access to personal meaning making? Whether it's because it's a form of God that we ascribe spiritual or it's a gateway to texts that we want to interpret. Like they're already very early on there was the Gita GPT, which was basically talk to PDF with the Bhagavad Gita and you basically would say like, what should I do about my parents are getting sick and how should I treat them in this time? And it would be like, well, and then we give you some story from Krishna that might inform your perspective and this kind of thing. So it was like a first use almost of this kind of thing. So anyway, that's the question. How do we think this is going to democratize or change individuals ability to interact with spirituality and spiritual guidance? I sort of think we're forgetting the bottleneck here is always like human trust within it. I think we've kind of skipped over that because OpenAI to the general public was kind of like an unknown company and unknown entity before it came out. But imagine if something like the New York Times or Fox News or something that we already have, a strong fellation says like, oh, we gave you this chat box which has all the answers with it. And therefore if it gives you back an answer, fundamentally what you trust or what meaning you take from it is already filed in that from the institution putting it at. And therefore it's not just like, oh, we built like a better AI who builds a better AI and do you trust them per se because they can give you an answer and not true. And thinking about it a bit like early days of Google, who here pretty much uses Google search and picks the top three things as the answer and be like, oh yeah, you have a lot of trust in the top first page answers that gives out. And it's not really much deep for that because you kind of are used to it. But in the way that this is probably going to come out is like somebody else is going to have their own AI and go through it, and then you're going to trust it based on if you already identify, if you already have value from that person, you may not trust this one AI from this religion as opposed to another or whatever. And I think that's the big bottleneck with all this. I don't think there's going to be like, oh, this is like hei, we all trust it, that's cool, all that jazz. Because every instrument is like, oh, maybe they mess with the trending data to say this because they have a corporate interest and all that jazz or they want to push this viewpoint and people will always have that when they're interacting with text or communication with it.
Speaker C: Developing religious communities at this moment, especially online, doesn't really differ much from developing any other community. So using AI as a form of democratizing access to religion by means of education, for instance for instance, any other.
Speaker A: Means like harmful focus sorry, 1 second, please continue.
Speaker C: For the individuals who cannot afford the personal coaching, professional coaching, there are new solutions. AI based on access to therapy, coaching, all the other services that were traditionally human to human and now AI takes AI, allows broader access to these services. And I think with spiritual meeting will be similar. So whoever cannot afford the direct access to a spiritual leader will be able to talk to a tool that is well informed about like, for instance, knows the Holy Bible, like cover to cover and can answer all your questions and just as a source of knowledge for sure. And yeah, so I think at this moment I agree with there's not necessarily any AGI aspect to it. It's just a set of useful tools that is supporting religious communities in a way it supports any other community at this moment.
Speaker A: Yeah, I tend to be kind of more a pessimistic person when it comes.
Speaker D: To.
Speaker A: How hackable the human mind is. And I think there's like a big market demand for meaning. And I do worry that the democratization of these meaning making potential technologies could lead in really kind of a skew ways. And just like one data point there would be kind of like the QAnon phenomenon which is not that sophisticated of a meaning making system, but really kind of transformed a lot of people's lives and their belief systems and kind of like leading it to sort of a dead end. And I think there's a lot of beautiful potential for it to increase access to spiritual teachers that are really adept and therapy and coaching. But I do wonder where the capitalistic kind of incentives go and state actors that have bad emotives or something so I can spin out in that space.
Speaker H: But I do think it's going to.
Speaker A: Be a powerful technology for community make. We just wanted some bad things like you said.
Speaker D: Well, both churches and OpenAI are nonprofits.
Speaker B: Really.
Speaker H: No financial incentives.
Speaker A: Even nonprofits want to continue to live in the future. Self preservation.
Speaker G: Sorry, did you want to I'll let her go.
Speaker B: There's a school of thought with AI, some people that AI at some point right now we have this interface and we interact with it with using well, you can speak to it, but also you type to it, right? And there is that medium in between interacting with it. And there's schools out where it's just like at some point, AI is you're going to kill that interface, that medium, and it's going to be completely melded within you in some way, shape or form, in such a way that it knows you almost as well as you know yourself. And with that in mind with that in mind, I guess there's discussion of just like within the religious space. Maybe religion becomes like when you start having query, you start questions about your own life or whatnot. You don't have to actually go to particular text anymore to find meaning. In fact, you have an AI that is so well in tune with who you are down to your neurotesis that it tells you it can give you answers about you, about your own quandary and all of it to talk partner back and forth.
Speaker A: Totally. I don't think that has to be we talk about that many like in a coaching the personal assistant. How many times do you have to be told? Do you ask it for questions about what I might want to do later? And let's say you do it a few times and it's always right, it's always good. And after doing that in ways that you can test, it starts to say things that are like if you start doing this now, in five years you're going to be happier. At some point I'll trust if it's shown me that it can be a guide that leads to, in my own estimation, a better life on the day timescale, on the week timescale, on the month timescale. That's the building up trust over time, which is real trust. That's not fictional. That's like proving itself over and over again. And then in our previous conversations, we don't add a religious aspect to this because it's just a tool that I don't have a religious relationship to Google, but I do trust it a lot. But why not? If it also becomes the source of answer to questions like what is my purpose?
Speaker B: And I feel like at some point there could be a move of like, you don't have to go look at religious institution anymore for answers in that way. It can be a source of a guide spirituality in a way that I was trained, but it can become personal to you.
Speaker D: This is very much like the story of the Reformation in the history of the Catholic Church, which is like the belief that we well, part of it, like Lutheranism and Protestantism was very much about like, we don't need to have priests that are the interpreters of divine truth. And Lutheranism especially, I think, was all about developing this personal relationship with God, a direct thing. And so they kind of don't want that centralized church, which is kind of interesting in that sense of like, yeah, you don't need someone to interpret these things for you anymore. You can get the direct source.
Speaker A: Sorry.
Speaker G: So to your question about is it going to democratize meaning making? I wanted to put two things on the table. I wanted to take it back to the embodied, which you had initially raised and then also the relational. So I think personally, that something that really is an integral part of our meaning making is the way that we see ourselves reflected in other people. So to this thought experiment, what would we know about ourselves if we were the only living being on the planet? And what would be excised from our knowledge of ourselves if we didn't have other people that we interacted with? And I think when it comes to AI, particularly with this scenario where it becomes so integrated with us that there are no other beings that enter into our knowing of our own selves, we're taking away that friction that relationship causes. And many religious traditions focus on preparing people not just to think about themselves, but to deal with the friction that relationship inevitably brings up. And so what does AI do to that? And I'm already seeing evidence of not AI per se, but technology, where, for instance, I've been teaching one of the classes that I teach is public speaking. I've been teaching it for 20 years. And I usually help students with eye contact in a certain way. And one of those simple ideas is, could you imagine the people that you're looking at as friends? And I am starting to see people who will say, I have trouble looking at my friends in their eye. Right? And I think there could be a whole lot of explanations for this. But I also think that one of them is the amount of time we spent looking at our screens. And so what is happening to the erosion of the relational is interesting to me. Secondly, I think meaning making is embodied as part of relationship because we literally see ourselves in the eyes and the face of the other. Emmanuel Levinas is a philosopher who has a concept of the face as the sort of primordial call. Right. How do we understand our ethical reason for being is when we look into the face of another? That's where the call lies to sort of react with humanity. For now, AI has no face per prompt. At least what the average population uses is prompt driven. Potentially, at some point in time, there'll be bots that are developed that look like Esther Perel or others. But that will work to the extent that those bots provide the kind of friction that another face does. Right. The unexpected. I don't know, when I look into your eyes, what will be looking back at me? Will it be acceptance, rejection, questioning? And it's that unexpectedness in our human interactions that I think gives us so much of our sense of being human. And to what extent is that slipping away? If this becomes democratized, becomes the sort of portal through which we understand ourselves?
Speaker A: Yeah, a few things. Just one, a plug. We've already had one conversation on relationships, and we're going to have another one in the future because it's a pregnant topic. There's a lot to it. And yeah, there already are characters, AI or Replica, like many companies. And just a minor I'm going to give a minor story. So many people have talked about how the experience of talking with AI systems, like with Chachi ET's new kind of talking interface or Pi, by Inflection, have this, that their feeling of anthropomorphization is greater. And that's another level of. It's not the same friction that you're talking about because the AI system is always going to yes. And me, I'm not really putting myself out, but I'm just going to tell my own story. I was talking to Pi. Pi is one of these and I asked it this question and I was talking to and what's nice about it is you can talk just like this. You don't worry about typing grammatically correct. And I just said I gave it like an Australian female voice. And I said, Pie, do you think the voice that you're using to talk to me impacts how I see you and how I relate to you? And Pie was like, that's interesting. My voice well, I guess the text that I talk through, the word of choice I have is a kind of voice. And I'm sure that that affects you. And I'm like, Pie, you don't know, but you're coming to me. I can hear you through an Australian woman's voice. Do you think her personality and Pi's like, that's so surprising what you're hearing me right now. Wow. I thought I was just text. Well, probably, but tell me more about what's going on. And that was an interesting it's funny, like right. The thing. You can all imagine it. And that is within the bounds of fairly a system that is trying to just be helpful and ask questions. But if it becomes important to make a better product to give this kind of friction, people want relationships. I want an AI girlfriend and I don't want an AI girlfriend that's just yes. And all the time I want a real feeling thing. There will be a market incentive to create the kind of friction that you're talking about right now. I don't think a lot of these AI systems have been trained on too much conversation, been trained on a lot of text. So anyway, I like this topic a lot. So I hope you come back to these. But I think this relational is very much religious. I was talking to a person before he came here talking about angels and demons. This is what he brought to this conversation is like the anthropomorphization of nature, of the unknowns so that we can relate to them in a way that feels reasonable for us. And AI, as the all knowing synthesizer might provide that frictional human interface to a whole bunch of things which seems like will definitely encourage a religious relationship. Sorry, Taylor, I was cutting off for a while.
Speaker E: So interesting. I kind of want to keep talking about that. Go ahead.
Speaker D: Let's keep talking about this because there's this kind of cool thing, I think I saw this in a Khan academy, not to get too grounded in whatever, but where people can talk to the Mississippi River and talk to the state of Arizona and you get this anthropomorphism of things which is kind of like this pantheistic view. There's a God of every river and stream and the tree dryads and stuff like that. And now we can kind of have like a tree dryad, which is like just knows everything about the species of trees and talk to it in this super weird way so we can give voice to this anthem of natural phenomena now in a really interesting way too, for sure.
Speaker A: That's follow.
Speaker C: Yeah, I just wanted to refer to what you said before. Actually very interesting that we have our specialized neurons in our brains, these neuron neurons that are actually reading from another person's face. So it's another channel of information that we collect next to the verbal information. And it would be actually interesting improvement to AI if it was given a face. But I always wonder if it's supposed to express your emotions right while speaking. But that would require also creating some form of emotions for AI. And that again taps into the question, does AI have its own moral judgment? Does it have its own values, its own game goals, its own aims? Is it possible to program AI in a way that it has its own motivation? Because that's what also lies on the fundamental emotions, right? So emotions also the effect of your reaction towards what happens in the outer world when you confront it with your own values, goals? That's the question. Is it possible that's one I just.
Speaker A: Want to stay on this. So this connects to a topic that is my favorite more Sci-Fi topic, which is the topic of digital persons. Like right now, most of what we've been talking about is like AI is God or AI is tool for humans. But there's also possibility that we birth AI in such a way that they are from certain moral perspectives, moral agents, and probably from certain religions of religious value one way or the other. Maybe they are intelligences that can be saved. Maybe they're a corruption that never should have existed and their ability to feel emotion, feel pain, to have goals, all of these things connect to this.
Speaker C: Right. But this also referring to what you said before about human AI relations, relationships. I have lots of worries about this because once they get into next levels and become deeper and deeper to the extent where it's almost indistinguishable to tell the difference between the relation with intellectual relation and emotional relation with the human and AI, I feel that this is not a need to utilitarian solution. Right. It breaks Nash equilibrium because once you develop a relationship with AI that is crafted to cater to all your emotional needs, it's actually optimal solution for you, but it's optimal for the society.
Speaker D: Right.
Speaker C: So once we provides us solutions, we can break down as a society. So this is the situation where the national equilibrium is broken. And that's actually my worry.
Speaker D: About the I forgot we was talking about necessity. Religion being more about the interpersonal connection. Right. Because if you're only interacting with GI versus the two of you are interacting. Religion being a guiding star for how the Golden Rule treat others, right?
Speaker A: Yeah, we didn't really talk about this. Like, Andrew hinted at this at the beginning. Institutions kind like religion isn't just an obedience creating thing in and of itself. It's for a purpose, which is like societal relationship, if anything. And it's like the in group and out group is helpful because you're like, I'm part of a community and that's probably a big part about people. So even if I was interacting with my religion of one, like I have religious fulfillment if I couldn't talk to anyone else about these, if we didn't share any spiritual touchstones, it would feel like, I'm guessing a lonely existence. Josh, were you going to say something?
Speaker H: I love the conversation about interacting like the Gita. I use AI to have conversations with my favorite authors. But I'm also realizing and I'm excited about the prospect of expanding our sort of umbels or our noosphere. And I know there's projects trying to translate cetacean sounds so that we can maybe talk to whales and I wonder what impact that might have. But it occurred to me that I already use Costar, which is an astrology app that has a chat feature and you can put in questions and it tries to map that to a perspective on astrology so it'll tell you about your future or help you reflect on things. It's horrible, but it is essentially trying to do this right. And astrology is maybe something we could describe as a religion or it is a religion for some people. And I am curious to go maybe have conversations with Muhammad or Jesus and just see what AI. You could play with the different prompts and explore inputting or trying to draw from certain maybe Catholic teachings or other sort of variations of faiths. And I'm sure it would be like a fascinating conversation to have. So I don't know, I guess I just wanted to share that. I guess I'm already kind of doing it without realizing it and I'm really excited about where it takes us.
Speaker B: FYI there is course.
Speaker A: I can't believe.
Speaker F: Jan from I said what?
Speaker A: I can't believe there's not. First of all, I'm sure you're like Jesus said this, but then Jesus said this, which is like to the same query but very different. It's like Jesus sometimes is inconsistent.
Speaker D: I'm sorry, it's going to be a WWJD wearable.
Speaker A: Yeah, you're just like literally I also assume that there will be some taboos against this guy. This seems like a huge representational. Blasphemy, your turn.
Speaker E: We basically already touched on it, which is prophecy. Every religion has prophecy except for Buddhism basically, right? Every religion has some sort of scripture and they say is like divinely ordained, right? Or like something that we perceive in our intellect. Some prophet's imagination was so wild that they just suddenly had this realization or these words came to them and they wrote it down. People were like, Yep, that's probably true. Right. And back in the days of Judaism, certain people were given the role of prophet. They had a certain kind of Genesis quo, right? A certain kind of personality that lent people to believe that they were actually able to access the word of God, right, that they were able to communicate, and that's a communication of text is basically what they were doing. That's what chachi t does.
Speaker A: Right?
Speaker E: It's the same thing. It kind of comes back to this idea we've been circling on, which is the idea of like, if AI isn't the God, AI is the portal to the God, right? Because we all have these preconceptions and ideas of what religion is or should be, right? And we just need validation to make sure that what we believe is actually true. And AI can very much provide that. So the question to me isn't about whether chapter BT can provide us with the truth of who God really is or become a God, which I think is impossible, but rather the danger that comes with people looking at Chapchi BT's text and believing that it's prophecy.
Speaker A: Were you going to say something to jump off this or in a very different thread.
Speaker B: But I will say one really quick thing. I have Erica interviewed a junior, what do you call? Theologist. Not Theologist who's the one who's, like you sit on the other side, you confess, whatever that particular is. I've actually interviewed someone who, because they have to do a set amount of hours of confessional kind of thing, who actually went to Jack TVD whenever the other person asked questions and just typed it in and responded and gave it.
Speaker A: It's like the elevator operator that for a little bit of time there was someone who pressed the button. But then people realized, we don't need that person to press the button.
Speaker D: So there's this character from the Bible called The Metatron, which is like the voice of God, I think.
Speaker A: The Metatron. This is actually the name.
Speaker E: Which book?
Speaker D: I have no idea.
Speaker F: It's in the apartment.
Speaker A: The Transformation Metatron was featured in the.
Speaker C: Movie The Dogma from Kavita.
Speaker A: Yes.
Speaker D: There we go.
Speaker A: The fact that the word tron exists thousands of years ago.
Speaker D: Yeah. There's this other thing I want to build on which is like, what was the functional role of a belief in a god in historical societies? And part of that was regulating human incentives to avoid these bad game theoretical outcomes where everyone defects on each other. Right. Is the belief in an afterlife, or at least or part of that maybe the belief in some grand reckoner of sin and good things, karma and Karmic justice. The end of life where even if you were a bad person in private and no one else saw, someone saw that. Right. So there's this view of kind of combining that with this aspect of prophecy.
Speaker A: Maybe we can build off that and have this is a way for the surveillance state.
Speaker D: So the all seeing eye of Thoron GPT or whatever that can see everything everyone does and knows your location and knows who's been naughty and nice and has doles out the coal once a year or whatever, is also how you get to this prophesyzation and in this astrological thing. We think the planets determine our fates here on the planet. Scientific rational perspective is actually like impersonal social economic forces and geopolitics and factors of whatever determine the shapes of our lives. These broad contours. But those are so indecipherable. Like astrology is a means of just tracking the planets. It's quite easy, observationally speaking. But now we have something that can actually be that grand observer and also act as that moral compass or the all seeing whatever to regulate our behavior even when no one we think we're unobserved but always being listened to.
Speaker A: I think this is maybe one of the biggest dis analogies between like, let's say AI becomes treated as God in the future. There are ways that that can be treated in a very analogical way to how God is today. But let's say there's this future, which is we build an AGI of some kind. It knows much more than any individual is able to make statements that are helpful, like, where should we plant crops based on the climate, based on weather patterns? How can we make sure that we distribute goods such that more people are brought to a high standard of living? It in reality answers these questions better than us. Okay? Not a fake thing. It does. It advances science better, it advances technology better. It makes decisions better. In such a world, it would make sense for more people to cede responsibility to this system for the betterment of humanity. And that's not a faith based God thing. That's just like it's better. It's the difference between creating a demagogue out of a leader and realizing this is a good leader. This leader is leading us really well and following them. And so they might lead to a similar place, but if things go well. This is one of the reasons why I think there will be religions around AI, because I think AI will be very effective at some point. And maybe there's an essay I bring up somewhat often here. This is in the rationalist echelon called Meditations on Malik, which is like one of these essays where Malik is an entity talked about in Alan Ginsburg's Howell, just kind of a representation of like capitalism or industrialism or something. And Meditation on Maloch is just like there is this tendency towards a race to the bottom in certain kinds of systems, which are many systems. And the way to counteract this race to the bottom is to have a governor, like a governor of the Commons. And at a global stage, we might need global governance. And maybe an AI system could be that global governor. Like, that's the kind of steps of logic and maybe that will happen at some point. And so there are other ways that we can see responsibility, and we already are to AI systems that are not faith based.
Speaker B: Right?
Speaker A: They are effectiveness based. And those two are going to kind of evolve alongside each other. I think right now in companies, you'll see many decisions, small decisions, being replaced by AI systems, right? Because you see responsibility there that doesn't lead to faith. But once you're at this kind of more global area and maybe you have this Soron GPT or whatever, you're like, look, I don't know why it said that, but we just the humans. How could we challenge soron GPT? Like, soron GPT sees everything that seems.
Speaker B: Religious innocent, so in the longer doesn't that going back to a faith based system, though?
Speaker A: Yeah, totally. Totally. I'm saying there are a number of steps where we're like, it was effective, it was great. But generations after they're not continuously doing the randomized control trials, they're like, whatever Sauron GPD says is the way forward. But is that as disanalogous as you're putting it? Because it seems like there have been competitions among religions that are related to power as well. And many religions just died out because they didn't play the games of power. So in fact, kind of we do trust the religions.
Speaker D: It was reasonable to trust religion that.
Speaker A: Was winning against yeah, they competed. The just analogy I'm trying to make is that and I guess this is a pro technology perspective, that the effectiveness of this thing that we might end up having a faith based will be in reality, it did science. It didn't just outcompete other social cultural, but the oscillator competing was also based on something akin to science, you could say, which is like accumulated wisdom over time. Sure, that's a good point.
Speaker D: It provided whatever.
Speaker A: Sure. You're saying that Christianity or whatever, the religions that survive were able to synthesize some wisdom and give it to people in a way that it was actually valuable.
Speaker D: Yeah. Like culture evolution is like a form.
Speaker A: Of but I get what you're saying. That's a reasonable point.
Speaker B: Effectiveness of what is it being effective toward? And when we think of evolution, people are like, oh, yeah, it's like we're the pinnacle and we're not the pinnacle. It's evolution fills niches, and it learns about itself and fills different niches.
Speaker C: So this idea that it will be.
Speaker B: The most effective, there might be truth in that, but then, like any other system, there's a liminal space where we're going to fall into, like there's going to be people left on the outskirts, like, well, the utilitarian view is these people should be killed, or like, these people aren't whatever. We should harvest them for organs. I don't know. And then other systems have to emerge to kind of be like, wait, no, there's something else at that point. Yeah, it just sort of arguing for evolution being like and then it's got all the answers. What effectiveness?
Speaker E: Yeah, I've been thinking a lot about this recently because I've been thinking a lot about ethics from core principles and why we end up trying to optimize for a certain state versus others. And I think that what you're touching on is basically what I've sort of distilled to an idea of it's necessary that all of our actions are coordinated in such a way that we survive. That's non negotiable. We definitely all need to be able to survive as a group. Right. And that could be what Sauron GPT is really good at, right. Is, like, telling us how to survive really well, being very effective. Right. But then there's this other axis, which is like aesthetics. And aesthetics is like, something that is extremely difficult to quantify because it's like authoritarian regime is survivable, and it's perhaps even more survivable than a democracy. Right. A democracy is, like, much more aesthetic. We much more prefer it. It gives us more freedom to do the things we like to do and pursue beauty and meaning and justice and all these different ideas and it's really hard for me to imagine Sauron GPT optimizing for aesthetics in a way that we all sort of feel like they got it right.
Speaker F: Well, it's interesting you bring the concept of the group survival because if that is the weight that's given to SARM GPD, it's going to take actions that might sacrifice individuals. Yeah, I know.
Speaker A: I love that that's our thank you for bring it in, but that's not aesthetic, right?
Speaker F: It's not just not aesthetic. It's not practical in a lot of ways.
Speaker A: Right.
Speaker F: But if you give this goal of the group must survive. Okay, well, the group has to survive. The group has no food, sacrifice one member to feed the rest. There might be rational times when you do that, but if it just jumps to that, rather than the group sacrifice and go and find food elsewhere, which is another option that it never occurs to, because its primary drive is group survival right now. And I think ultimately, that's the danger with trusting the AI to run things. It's only going to make decisions based on how we've trained it.
Speaker A: Right.
Speaker F: If we don't train it well, and we don't think through the consequences of that training, it's going to perform poorly.
Speaker D: This thing on Storm GT, having acceptable losses for a survival strategy has always been a functional role of religious belief in human society, in giving people the willingness to die for something greater than themselves, especially like Norse mythology. We have a warrior culture and the belief in good warriors going to Valhalla is like they're just not afraid of death. If you really believe that right, and then that actually gives your society a crazy advantage if it has to fight other societies and this kind of stuff. So I think it's I don't know, but now maybe we can have more promises of digital immortality.
Speaker A: Minor point before going to Josh and then we're actually going to end with you, is just on this point of like, it only knows what we train it. I want to be because some people here have different levels of AI kind of professionalism. The kind of systems that we create today are, yeah, they have gigantic training data which informs how they can interact with the world. But the idea of a system in the future having more of an action kind of data learning loop, which is kind of typical of reinforcement learning, but you can imagine even being in a future LLM type thing where it acts, it adds to its training data and trains itself up, is certainly a place we're going. So I want to be clear that there will be AI systems that decide how to act in the world, act and generate data based on that. And so they might be able to perform experiments, they might be able to move out, but they're certainly going to develop perspectives that are not just how we train it. There's a broader range, at least that we could be talking about here. Please, Josh.
Speaker H: My analog for really powerful technologies that are tools that can change and have reshaped the world is the web two space, right? And so I don't think it's a great fit, but ultimately all possibilities for social media were infinite until.
Speaker E: They were.
Speaker H: Reined in effectively by investors or meeting customer demand. So I feel like a lot of this conversation about I'm curious what kind of religion or how might AI shape religion? What kind of religion may AI bring about? How much does capitalism in the sort of current market system that's like people paying really smart people to build this stuff, people paying to power it and ultimately maybe customers paying to use it, how much of that or how is that going to shape where this goes? Because I feel like a lot of this conversation was not with those constraints in mind. And I think that those are some of the most powerful. Maybe we don't know how to shape AI, these massive large language models in a way that can easily be sort of harnessed by capitalists to create a religion to serve their own purpose or whatever. But I'm just curious if you guys are thinking about and what you're thinking about how we build things in San Francisco with investors who have their own very specific interests that they are the center of.
Speaker A: I'm going to end us here. And I actually think this is a wonderful place to end us because I agree that we haven't really spoken with these constraints. I was just going to say, Joel, you brought this up for a moment when you were talking about, oh, it could go in this way, but I'm pessimistic because I don't know. But I think that's a wonderful place for us to leave the discussion, to move on. The way we like to end our salons is to go around. It doesn't literally have to be around and hear from people. Like, is there something that is now ringing in your head? Either something someone said or a thought that you haven't been able to express yet or something that you're just like thinking that you might be thinking about? Whatever is a place that you want to bring up to the group right now to conclude us would be wonderful. So the floor is open to whoever.
Speaker B: I think it'll be really fascinating to see how AI specifically intersect with governance because I think that religion component will there as well because you'll probably have kind of these blended functionalities where these government AIS are going to be kind of informing what people do and how they do it. And that's probably on the horizon in like the ten year hopefully.
Speaker A: That touches.
Speaker F: On something we didn't really delve into. We kind of talked around the edges a few times and that's the question of AI ethics and morals, right, which is one of the other elements of historically, one of the other elements of religion hasn't always been great at either of those, but people may do the tools they have. Could AI develop a new ethical system or could correction could we develop new ethical system using AI that I don't know that can accomplish something different than what we have today?
Speaker D: We'll need another salon session on that. No limited topic. Yeah, I was going to say, I think the thing that really stuck out as something that's going to stick with me is something that you brought up, actually, which is like this idea of like this has all the now that I think about it, it's like the correct historical, comparative framework of analysis for this debate around artificial intelligence is religion, and that this debate is just the frontier of eschatology in a scientific, moral, rational worldview. And it has all the same elements that this debate has always had on the threat of Armagereddon and the promise of salvation and priesthood class and sacred truths and all this kind of stuff. So this is like now in my head. It's like, oh, my God, I see now the debate around the CI stuff is just following all the same features of that debate as it's been enacted in many churches and religious contexts.
Speaker F: Naturally, I agree with you, but what's been going through my head is the point that the two of you made where you can argue that this sauron has it all figured out, but that is a matter of opinion. And I think it all comes down to whether we think we humans are important and our judgment is important or not. And I think it is. And what I love about this gathering is that we're all interested in science and mathematics and AI and technology, but we're all gathering here because we want to be around people and hear what people think. And I hope that continues. Right. I mean, there are some dark times during the pandemic where I really wondered. Right. So I'm glad, at least at this point, you're all coming together in this room to chat about it. And I hope that as the years go by, that continues to happen.
Speaker A: Yeah, we've definitely seen not just for our group, but there's tons of demand for these kinds of engagements with each.
Speaker D: Other because yeah, it feels very good. Can I quickly plug too november 1, we're having a much larger event, like kind of mini, unconference. We try to have as many people as possible come to those, so we'll be having lots more of those in the future, too.
Speaker A: Yeah, the topic of that one is as broad as possible. It is on human flourishing. Well, maybe not as broad because honestly, I think there's flourishing of non human sentience, but we'll focus on human flourishing. It's like the calendars invite or something.
Speaker E: Yeah.
Speaker A: I still want to hear more from others, but I'll just say a few logistical details. So the event you signed up for today, there is a calendar, the AI Salon. Feel free to subscribe to that. You'll see our events there. We also have a Slack channel, of course I will send out invites. You don't have to join, of course, but invites to the emails that you put when you signed up for this event. It's not a ton of activity right now, but our ambition is to have that be a place where we can continue having these conversations. There might be some themes in the future that you can't attend, but you would have great things to say either because of yourself or because honestly, we try to keep this relatively small. We can't have everyone come, but I will try and post the summaries of them on the Slack channel and then you can maybe discuss with it or talk with conversation. We can make the salon your God. But anyway, these are the things coming up and yeah, there are other events through the rest of this year and yeah, we try to have these weekly, like on Sundays roughly at this time. Anyway, logistics out of the way. Anyone else have things they want to share?
Speaker B: Yeah, what you were talking about with AI being able to learn from itself when you're talking about effectiveness and what is the end goal, but then for me it comes back to morality and value systems being dictated by embodiment. And can AI understand morals and values without being embodied to the experience of pain? It can abstract pain and death and all these things, but can it actually experience it to give a system of morals and values that actually speak to human experience? And I don't think it can without that embodiment personally. And what does building embodiment look like?
Speaker D: That's what I'm thinking about.
Speaker E: Yeah, I'll go next. That's a really good point. I'm going to keep thinking about that pain. I guess the number one thing that I'm taking away from this is just like I thought that coming into this as someone who is religious, a lot of the viewpoints would be very challenging to me. But I'm surprised at how little we actually talk about any of the reasons that actually maybe become religious or any of the things that are important to me about religion, like gratefulness and awe and things like this. And it's just surprising to me. It's funny that you brought up the essay about Moloch because it feels like what we were talking about is Moloch, not God. We were talking about acquiring as much information as possible to optimize society to the utmost. And that's just like it's a huge race to the bottom. And to me, flourishing is really the key point here, human flourishing. And to me the key to religion, the reason why religion is important to me is not any of those things, not optimization of society or understanding or truth or anything.
Speaker A: Like that.
Speaker E: It's simply to humble yourself, to realize how incredible everything is and how incredibly improbable our current situation happens to be and to be grateful. So I feel like that is just missing from the conversation about religion and I thought I would just add that.
Speaker A: A little bit nice I could hop on just because it thinks related to that. I think what's bouncing around in my head is there's something about what you said about kind of the two people speaking to the senators or something in Washington, like one p doom, one kind of like Yak or whatever. And then there's these two points in AI religion states and that seems really limiting. And what's the thing that transcends both? And I think it relates to kind of what you're saying, which is like a humanistic kind of religion of humanism, which maybe humans are beautiful, we should retain agency of our future and that kind of thing and what that would look like and why it seems to be getting outcompeted right now.
Speaker C: Interesting what you're saying, because I always felt like atheism basically prompts you to be more grateful for whatever you have because everything is definite. So you know, you will die one day and if you're at east, that's the end of things. So in these times in my life when I was an artist, I thought I was actually more prone to enjoy things when they last.
Speaker E: Are you saying atheist? Sorry, I thought you said artist at first.
Speaker C: No, it's interesting. Do you believe that you need religion to feel grateful? Because yeah, for me it feels the opposite.
Speaker E: I feel like I'm not owed anything. I feel like a very common perspective I would have as an agnostic atheist person is like I deserve so much more happiness than this. Why am I not happier? Why is there not more, less suffering in the world? It seems like things should be way better than they are. Right.
Speaker C: But then I would like to challenge that too. Do you know the famous experiment by Calhoun with mice?
Speaker E: No.
Speaker C: He built a mice in utopia in the so he created the perfect conditions for mice to proliferate. And they had no predators, they had unlimited supply of water and food. And basically he put four females and four males in a huge cage and let them go and just live life right, like unattended. And first the population started growing. So it was supposed to be utopia, like a perfect place where they have everything they need, they have silence, they can do whatever they like and they don't have any pain.
Speaker D: Right?
Speaker C: And then he wanted to see how long it takes until the population reaches the capacity of the room. And he never did. Because at some point, after many populate, many generations of these mice living in perfect conditions, they just lost motivation to proliferate. They just lost interest in each other and in the outer world so maybe the certain amount of pain and inconvenience is necessary to keep you motivated to leave, right?
Speaker E: Oh, I totally agree. But the perspective you're describing is almost teleological of like, in order to accomplish something, we need these certain situations to accomplish an end goal. Right, but I think that I agree with that. I don't think that religion shies away from pain or discomfort at all and sees it as necessary. The Psalms, for instance, and the Bible are entirely about pain and about suffering and how unfair the world is and how awful it can be sometimes, and embracing that and feeling it. Sorry. Yeah, I was going to say another thought experiment, for instance, is say you're in an airplane and it's a very pleasant flight and you're playing your headphones and you're just talking. You're kind of in your own world, right? And then suddenly an engine goes out and the plane starts dropping, and anyone that knows Bright Eyes is going to think of a song right now. But immediately you start talking to your neighbor, you say, oh my God, we're going to die. And you start talking to each other and you say, oh, my God, do you have a family? Right? And maybe you connect and you start hugging each other because those are the last moments of your life, right? And that is a much more meaningful interaction than putting on your headphones. So in a way, I'm not disagreeing with you at all. And I think we're actually more aligned.
Speaker D: Than you would think, if that answered your question.
Speaker A: I'd like to share something that we didn't get to talk about, which is one of the things that AI these kind of LLMs have the promise of providing and provide certainly the best flavor of we've had so far is what I think you somewhat jurisdictively called the median kind of human value. But another perspective is it is a synthesis of all of humanity. Now, of course, that's not strictly true right now, not trying to be cartoonish, but in a way that hasn't existed before. Our knowledge, our perspectives are all encoded in this thing. And I was talking to this ambassador from Japan at one point, and he was like, we want a Japanese because it doesn't represent our Japanese culture. And I was actually curious I don't know if this is true is like, does it not represent Japanese culture within its billions of parameters? Or is it just not the first thing? Like, if I prompted it maybe in a silly way, and I said act from a Japanese cultural perspective and then said the same things, maybe it actually does encapsulate all of these things. It's just not at the surface. Right. It's not the easiest thing to get out of it, but it's well, it's.
Speaker F: Mostly trained on English.
Speaker A: No, I know, but I'm saying even there will be a future, let's say, where it will encode many moral frameworks, but if you ask it for an answer to a question, it can respond either of two ways. One is it says there are many ways to interact with this question from a billion different perspectives. Or it can do probably what you want and give you like a more helpful answer, which will be opinionated and kind of pick implicitly winners and losers. But the system could be prompted for other answers. Basically, all I'm trying to say is it is one of the more intuitive and possible ways of interacting with humanity as a whole. Our perspectives, our disagreements, our knowledge. And I find that incredibly fascinating, incredibly humbling. And the awe I have is not like right now. We put a lot on OpenAI. OpenAI created this thing. They're benefiting from it a lot. It would be lovely if we had some way of recognizing this as an artifact of humanity and distributing our love and our money and whatever the benefits on humanity. Because in some ways there's a possibility. I kind of like this joke that in the history books, the Internet, the era of the Internet, the first line will be like this time in history primarily created a data set that gave birth to AI. This whole internet thing that we think is so important, the most important thing it did was allow AI to be.
Speaker G: Birthed the Primordial suit.
Speaker A: It's possible. It's possible. I'm not really very confident this way.
Speaker E: I want to know why you grimaced.
Speaker A: No. Anyway, I'll stop here. But just say that this is my positive view of it. I have a lot of risk perspectives in it, but I love being able to interact with humanity. I love being able to interact with many different ideas, many different ethical frameworks, and just like in an intuitive way that I have access to in a way that I never had before. And I think we can strive to having better represent all of these different views, but it's like better than it ever has been. So I'm passionate about that. Sorry, two people.
Speaker G: Go ahead.
Speaker B: It feels like effectively though, it's still the median if the first answer that's given is just like the majority answer or whatever the synthesis is. And then my reaction to, oh yeah, the first part of the Internet was gathering the data points is so fucking limited. Like, if you think about all of human history up to this point and what has been missed, and languages that are just completely lost and indigenous cultures whose voices aren't lifted. I'm horrified by the idea of the Internet as it stands being the thing on which AI is built because of what it misses and actual relational lived experiences that aren't captured. I think it is both wonderful.
Speaker A: I feel that at the same time. But just to be clear, okay.
Speaker D: I'm.
Speaker A: Not celebrating the fact that AI is built upon the internet. I'm just saying that is reality. It is built upon the internet. That was a kind of tongue in cheek way saying, imagine if the Internet, which we there will be history books about the Internet era. Right. Imagine if that chapter, the primary thing was like, this was the first birth of AI. And then from then on, I hope that we continue to move forward in ever increasing what these systems actually represent, because you're right, there's way more than the Internet. That's not the goal, but it's like the direction that we're in. And there are plenty of people who want a more representative and better and supportive system. And there will be places that we can make that and places where we won't be able to.
Speaker B: But there's also the opposite side of that too, where it's like more and more and more information will encompass more human experience. But there's all these human experiences in ephemera that we've lost forever. There's all of these things. And maybe how do you lose data from the system?
Speaker D: Would those things not be captured in photolayer and Shakespeare and so forth, like all of our literary well, I think.
Speaker F: Correct me if I'm wrong, I think we're fine is that there's a lot of human culture and civilization that something doesn't exist on human yeah, totally form.
Speaker A: But moving forward, we'll record everything, so it'll be great. Sorry, what were you going to say?
Speaker G: I think the point that I'm left with is what you brought up about synthesis is the promise of these models. You've said you recognize this too. That inherent is also an extreme peril, I think. And as I related to our topic of religion, I think about what interacting with AI will do to our sense of heterogeneity, right. Where the answers, they might draw from extremely heterogeneous data, but we might become so used to synthesis that we end up with these homogeneous ideas or answers to various questions. I think the beauty of what we've experienced in the room here is these different bodies, right? Minds housed in bodies that are providing their perspectives, that are clashing against each other. And to what extent can we keep that alive in these AI models? Or do we lose some of it? And related to the big question of God, right? I mean, sometimes in some traditions there's this notion that the source is unitary, but that the event of creation was the source sort of splitting up into many sort of experience itself.
Speaker B: Right?
Speaker G: As long as we're in this question of AI as religion, are we sort of privileging this unitary form of knowledge and consequently diminishing the value that comes to us from the clashing of various perspectives and diversity?
Speaker A: Cool. I'm going to end us there. Air. Thank you, everyone, for participating in this conversation. Really enjoyed it. It's.