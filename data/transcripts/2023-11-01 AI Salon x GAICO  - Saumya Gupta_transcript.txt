Speaker A: Here, making friends, making, you know, healthy relationships, and ultimately getting to the essence of who we are and what matters to us with regards to those relationships.
Speaker B: Can I also ask for consent? I just started recording.
Speaker A: Hi, guys. I'm Dennis. So I'm interested in this whole AI aspect because generally speaking, I talk to friends here. For example, dating in SF, it's very fascinating as a whole culture. We have some of the smartest people here. But finding a match and then also having kids, that's a whole different sort of story there. Generally speaking, the more technologically minded you are, there's also a correlation between that and being super on the left side, generally speaking, as a whole. And then I've come to notice there's also that correlation between that and not wanting to have kids. They think there's some aspect of the world being like, the world is kind of fucked up. I don't want to bring us child into this world. And so it's like, fascinating to observe this sort of. This is like one pocket, but it's fascinating to observe this whole aspect of how AI can generate human help. Helping people meet and people to build, like, partnerships with. Yeah.
Speaker C: So I'm Tom. I'm visiting SF from Vancouver. I'm here for the week, but from the UK originally. And I guess the reason why I wanted to join this particular conversation is I'm curious just about in the long run, which relationships won't AI replace. Like, I think there might just be. It might just replace most of them.
Speaker A: Hello. Sorry, my bad. In the name of not interrupting the flow of things, instead of taking the.
Speaker D: Break, we're just going to keep going.
Speaker A: Till 840 just because everyone's really quiet right now. Cool. At 840, we'll just kind of meet back up in the main area. Until then, just enjoy the cheers. Cool.
Speaker C: Yeah, that's basically it.
Speaker D: My name is Silas and I live across the bay in Berkeley. I'm particularly interested in this topic of how AI can help relationships because I have come back to the States about five years ago from being abroad for 20 years, and it is really shocking to me how disassociated we are in the United States. San Francisco gets it on the head a lot, but I think it's everywhere. How we don't really know each other very well or feel that sense of community as much as I would kind of expect. I grew up in Berkeley, so it's sort of like stepping in the same river twice, but way downstream kind of thing. And Berkeley's really changed. So I think what I'm really interested in is sort of how do I take the conversations that I have internally and externalize those conversations with others so that I can kind of feel that sense of connection and thinking about where know plays a part in.
Speaker A: Yeah.
Speaker E: My name is Serena and I am building an AI knowledge assistant for caregivers that are giving care to dementia patients. I am interested, I live in Calhallo, so not very far from. I'm interested in AI and human relationships, especially from a capacity of how much more we can enhance our ability to care. And especially what you talked about, the replacement aspect, if that does happen, what would that look like? Or maybe a more philosophical question should be what is the future of care going to manifest in itself in terms of caring for our parents, caring for ourselves and caring for our future children who will be in their eighty s and ninety year old and maybe life expectancy right now, even though it's 73, it's actually I think, 85 for the US and it's going to be much longer and more and more disease, including dementia, are going to be more prevalent, as a matter of fact, every 3 seconds or if someone in the world becomes diagnosed with dementia. So that's about kind of where my interest kind of lies along with everything else that you guys have talked about. And I would love to kind of echo back. Belinda would love to learn more about my relationship with myself as well during the process in terms of how to be better and be better with myself and my own relationship with people as well.
Speaker C: My name is Jacob, I live in Oakland, and one relationship that I don't think is going away is that of the teacher. I've worked in Edtech and I'm really interested in that relationship of teacher to student, tutor to student. One thing we learned in the pandemic or that was reinforced is that school is for not just learning. It's really childcare, it's socialization, and it's learning probably in that order for most families. And so we're going to have schools, we're going to have teachers. How can AI enhance that relationship and reinforce it? There's a lot of people trying to create AI tutors. I think that'll work in certain cases, but I also think there's a big space for supplementing, augmenting and improving that relationship.
Speaker A: Cool.
Speaker F: My name is Peter and I live in Upper Ashbury and I'm interested in how AI can help us improve our relationship with ourselves as well. When I was seven years old, my parents divorced and it was quite an ugly event and that went on for years as an adult, I've recognized that I developed a whole bunch of patterns and beliefs about the world during that time period that were unhealthy or are unhealthy, and I've had to unwork them all. If I'd had someone then to talk to about what was happening, I think I probably would have avoided a lot of the pain that I've experienced as an adult. And I think it's quite difficult to give children around the world a therapist or someone who's capable of holding those conversations. But I don't think it's very difficult to get a toy or some sort of AI into the hands of kids that are capable of doing that. And so that's what I'm most interested in.
Speaker G: I'm Robin, and we're co founding a startup together, so we're going to have a similar answer. And I've been up for Ashbury.
Speaker E: Is that what it's called?
Speaker C: I think so, yeah.
Speaker G: And the relationship that I'm most interested in is with emotions. I have PTSD, and I was a teenage drug addict, and I have been going to therapy for 17 years. And most therapists are not good. Most of them are really not good. And something that I've discovered over many, many years is that the epidemic we're seeing, like, I mean, we've seen San Francisco and across America of people who are addicts and are unhoused and are not contributing to society in the way, I mean, that I sitting here have managed to do is not largely because of intellectual issues, but rather because of emotional issues. And that addiction, it's like 80 or 90% of addicts have trauma. And trauma can be fixed with having someone that you can talk to and makes you feel seen, valued and known. And as I've gone down this path of understanding myself and becoming contributing member of society, I've largely discovered that the more that we can self regulate results in the more that we can connect with other people and the more productive that we can be. And that every person, I'm sure, in this building struggles with productivity and focus due to emotional challenges. And so using AI to intervene because humans are so obviously not capable of being that support. It's so challenging because the main characters of our own movies, I think, can change the trajectory of the human existence and reduce addiction and war and crime, et cetera.
Speaker B: Hi everyone, I'm Somya. I'm going to start with the third question. I am a new mom. I have a one year old. And so the relationship that I want to make flourish is with my daughter. How I'm interested in relationships, in AI. I'll start with the concern and then go at what I'm working on. I really want humanity to think through the implications of what we are building on human connection. I think the last two decades, particularly the last decade, we have created a social world that has led to mental health issues, loneliness. The statistics are really bad. The reason I left my job was because I became a mother. And it just didn't sit right that my baby girl has one in three chance of writing a suicide note because she feels lonely. And we have gone from a world where we started with the productivity world, but we have gone to a convenience world. And everything is one click. There's one click groceries and one click. We have really reduced all serendipity and social connections, right? You don't have to go to your bakery, you don't have to go to your grocery store, you don't have to need to know your neighbor, you just don't need social connection. But our brain is still wired for it. And so we've created a world which is not healthy for us. And I struggle with disinterpiating even more humans, especially the ones that actually coach and guide you, because AI might give better answers, but it doesn't give you the same dopamine hit. And so that's my big concern. And then in terms of what I'm working on, I really want to see if AI can enable better group social skills for individuals, and also can AI become a buddy for a group rather than individuals. So basically do this instead, and AI helps make it deeper and better instead of replacing it. So that's what I'm working on. So social skill building as a group, where AI becomes your group coach.
Speaker G: And.
Speaker B: Open to ideas on where to take the discussion from here. Things that popped out, anybody wants to. Also, by the way, this is an interesting one. This is a tradition in Japan where anybody who talks holds a stick. It actually inherently, psychologically makes you more confident to talk and also reduces people this interjection unless necessary. So I think I didn't realize that we'd end up doing this, but this actually has some historical bearings, actually. But, yeah, whoever wants to go.
Speaker E: If we were to break up all of the things that we shared into Solana categories, it seems like there's the relationship with the self, the relationship with one other person, an intimate relationship with one other person in terms of dating, and then a relationship in group dynamics. So maybe we could start with those things and then go from there.
Speaker G: Wonder if we should do relationship with screens and how that is like, relationship with screens is actually detrimental and do like a devil's advocate and be like, we think AI is great, but then also here are all the things that are causing huge mental health issues, and.
Speaker E: It'S actually the opposite.
Speaker A: Screen.
Speaker E: As you.
Speaker G: Mental health is getting worse and suicide rates are increasing and people are becoming lonelier because human interaction is decreasing as free meals is increasing and we're getting more deliveries and things like that. Also, screens are messing up our dopamine structures. And so from a very young age, our brain is being wired to release dopamine and to be the most productive, best versions of ourselves. We actually want dopamine to be released through effort. So if you release dopamine through effort, through actually doing something, whether it's like going up a flight of stairs or writing that essay or things like that, instead we're getting easy dopamine that requires no effort, which is like likes on Instagram or whatever, or comment and things like that. And so if you do that from a young age, we're wiring our brains to not be productive individuals and to be dopamine addicts, rather than the natural release that biologically we've evolved to have.
Speaker C: Two screen uses that I find enhance social activities. One is FaceTime, so I'm able to see my cousin, see her kid instantly, just have that visual. It's like, still a Sci-Fi wonder that.
Speaker A: You can do that.
Speaker C: And then the other is the small group text thread. I have a couple of groups of friends where we'll just text and make jokes, and it's this little point of connection of just, like, remembering that, oh, yeah, I do have these friends, and maybe it would be better if we didn't have that. So we were forced to see each other in person more. But I enjoy it. It doesn't have that same gross feeling of posting something and saying, who clicked it, who liked it? Popularity contest. So I think it's more complicated than just screens.
Speaker A: Yeah, I'll say a point on if you're young, for all the young kids out there, they're on TikTok. And I think here in Silicon Valley and stuff, we have a very one sided view on TikTok where people think it's like cancer for the most part. But I think TikTok is like the greatest app that actually came out. It's like you can observe a culture depending on how you use it. You can just go in, how you search it, you can find out how people interact, behave, how they order it's, just like a huge insight, like cultural observation, and you just have to use it in a correct way. I scroll through, I can find out I'm into fashion and clothes, so I can use it and find out what's all the way to cool brands. There's so much information that's gatekeeped, but through people on TikTok making viable content that you can just find out massive amounts of information in a very concise way.
Speaker C: It strikes me that a lot of these differences in like, okay, is a.
Speaker A: Technology bad for you?
Speaker C: Is to do with where on the spectrum of consumption to mindful production are you. So on the one hand, you have like, I'm writing an essay, I'm deeply introspective and I'm sharing it with the world and I'm curious to receive feedback. That's probably a pretty good spot. What you're talking about is like kind of a middle case where I have a specific thing that I'm interested in learning about and I'm not maybe creating a public artifact that other people are seeing, not participating in a network, but there's deep intention in that use. And then there's like I'm passively doom scrolling on the far side, right? And I feel like tying this back to AI. I think the thing that I guess I'm concerned about when I talked about relationships being replaced is it seems like most people are just like the scrolling thing is easy and it's sort of like the path of least resistance. And I don't see why that won't be the case with AI generated content. AI generated relationships. So it almost feels like it's just a ball rolling down a hill, right? And it's like people are going to keep doing the thing that the incentive structure rewards. But yeah, I'm curious at least maybe the lens of production versus consumption can help tease out some of the whether a particular technology is useful or not. I think it relates to what you were saying about how do you train your brain to not crave.
Speaker A: Dopamine? Hit.
Speaker E: TikTok's got entire teams of engineers. It's like not eating Doritos one after another. It's not about if you want, you want to view it as how do we as individuals, an epidemic problems. It's almost like one epidemic of problems that these technologies are causing. I think it'll be fine. Well, I guess to summarize, I feel like we're talking about three things. One is the human screen and productivity, and then the second one being human screen and really same relationship and then I guess just focus on productivity, which is. I think it's your initial question. Sorry, mental health was our last one, I think for productivity, which is your initial question, I believe productivity. I think we need to define what productivity is. Productivity, what that meant for our parents generation or grandparents generation may be very different from the Gen Z's and the younger generations. So I don't think it's fair to say that the fact that we're spending time on TikTok and we're not being productive. Back to my point. I think TikTok is just displacing a behavior I might have spent 2 hours scrolling on TikTok instead of doing homework. But can you confidently say that if you take the phone away, then I will be productive for 4 hours doing homework? That's not necessarily the case, no.
Speaker C: But we do see a pretty clear correlation with social media taking up and mental health problems.
Speaker B: Well, absolutely.
Speaker E: We're talking productivity for now. Yeah. So I think there is clear distinction that we need to figure out how do we improve productivity? It's easy to blame like TikTok the world. But if we take away TikTok, doesn't mean that all of a sudden we're going to have ten more Nobel Prize winners.
Speaker C: I don't think through this discussion, productivity, to me that you could be a very productive worker and not a flourishing, happy human being. Right.
Speaker E: Productivity doesn't lead to happiness mean it's.
Speaker C: Better than being an addict.
Speaker E: Direction and conversation and maybe we should talk about mental health then. Human screen and mental health, does that lead to mental health issues?
Speaker D: One thing just to throw in there is maybe it's just for everybody. But I thought the FaceTime thing was interesting. How many of us have felt more connected? At some point when we've been using technology, we've come across a piece of technology, whether it has AI embedded in it or whatnot. But we've felt like we've been seen more, that we've been heard, that we felt like somebody cares about us, that we have a deeper sense of belonging because of it. Can we think of things like, in our own experience so far?
Speaker E: I think COVID was a great experience because it's all comparative. It's not about do you have all the connections or not? Are you transferring all the connections on screen versus all in person? It's more about, comparatively speaking, how are you feeling based on what you have? COVID has showed us that we can have weddings on Zoom and feel just as happy because the alternative is versus if COVID never happened, no one's going to have weddings, right? Because the alternative is having an amazing wedding in person. So I feel like that's interesting framework to think through the comparative benefits harm. Same thing with technology. I think it's hard to just say good or bad or beneficial or not, especially as the benchmark for measuring that is. Carson.
Speaker B: I can give one example that happened this last week. I've been trying to get into strength training after my postpartum, et cetera, and I sort of have not been able to include it in my routine. And so last week I went to CrossFit after a long time, Crossword CrossFit. And I did not attend any class this week. And so my coach messaged me or whatever. CrossFit, Coach, why aren't you here? And I was like, baby'sick start up life is too much. I can't talk. And then he's like, okay. And then two days after that, he messaged me again and he's like, how's your baby doing? He did not ask when you're coming. He did not ask. And all of a sudden I was like, this guy heard and he remembered. And he remembered that my baby was sick and he cares that I come back and he's not selling. Right? And so a lot of times I see community builders who are natural community builders, but right now it takes too much time. He is the owner of the cluster as well. He has like, what, 200 customers? He must be spending so much time doing it. He has the intention to do it and do it in the right way. And not just the orange theory messages. You get like, hey, you signed up with an email. When are you coming to the class?
Speaker G: Right?
Speaker B: Not that.
Speaker G: Right.
Speaker B: And so I think about this a lot. Of course, messaging is FaceTime. All of this is technology, right? But is there a way to scale the goodness of community builders by letting them not spend 3 hours texting everybody individually and reminding them what matters?
Speaker C: Or was it effective only because you kind of knew, like Facebook and the birthdays on Facebook, Happy birthday. It was automatic, meant nothing.
Speaker E: It's a scarcity mindset because you can observe that his time is scarce. And he took the time, like you said, to do that and make it feel special. I mean, think of all the spam emails, how they're customized. And now we're getting them. I'm getting like 50 of them every single day. They're all customized. I don't be anything special. There'd be more just because I know they just send them out.
Speaker C: I think that's really essential to this question is, like, how can AI augment, make more effective, and yet keep that essence of, like, I care, I care about, right? That's the essence of a relationship. I care about you. And because of that, I'm devoting something scarce. Whether it's time or money or focus, I'm devoting something myself to you because I care.
Speaker E: That's the billion dollar question is, can AI really care?
Speaker B: But humans can. Other humans can. But can AI care?
Speaker E: If AI doesn't care, then all of.
Speaker B: Everything you just said is, but it can.
Speaker C: Care more. Or focus it on that somewhere.
Speaker A: I would say, have you guys heard of something called character AI? Character AI, or all these other chat.
Speaker D: Bots that do avatars and stuff?
Speaker A: Replica, but basically, if you want to, human connection is like the end goal, right? Because then you have a human connection. You can have kids, or if you want to carry the population in the world trying to increase human abortion, I think one byproduct, at least keep the population the same, which is like every single parent have two kids, you know what I mean? But right now, with declining population, people have more kids over long periods of time. It's at least something. But there's a good point, right? You can't have human personalized, right? But that's like large scale right now. They're still good. But generally speaking, with the whole character AI thing, there's a bunch of people that are lonely, and so people are using all these connections with, and they're just at home looking at screens, right, with not going out or chatting with people and having any sort of.
Speaker E: What if we used AI?
Speaker G: Like, right now, the most prominent online dating tools that we're using are based off of pictures. And this is what I do for a job, which has nothing to do with a relationship. It doesn't impact dating. So what if we could increase the population of the world through decreasing breakups and divorces by creating dating apps that actually you've put in your personality to it. It's followed you throughout a week or something and recorded you for a week. You have it record everything that you say you do, your preferences, and then it creates a profile for you. Feels like an episode of Black Mirror, but anyways. And then you put it in. It doesn't get a better version of you, but instead it matches you with people, that it's like you align with them. It is the best matchmaker ever. It's like, no. Humans are inherently terrible at choosing partners, especially through the Internet. You need to meet someone, but we've digested your energy rather than the one that you project to others like the real you and will put you in alignment with someone.
Speaker B: Can I take a contrary view to that?
Speaker G: Absolutely. No.
Speaker B: I think there are merits to that idea. But I think. And this is data. Right. Whether successful or not, you end up marrying your neighbor.
Speaker G: Right.
Speaker B: Proximity is the biggest predictor.
Speaker A: You end up marrying your neighbor.
Speaker G: Yeah, I did.
Speaker B: I married my classmate. Right. And so it is a function of how much time you spend with the person and how much time you spend evolving together into a common unit. Right. And so, yes, I think there are some groundbreaking ground or foundational things that should, whatever, match. But I think if you put ten strangers in a room for a long period of time, they will love each other and hate each other. I do think there is. Of course, there's physical attraction and there's some basic sort of things that you want in a partner, but so much of it is actually how you interact with each other. And so I really wonder, a lot of times, Gottman talks about this. A lot of times marriages are made or broken in the way people talk to each other. It's nothing to do with who you are, really. Yeah. I struggle with that idea of matching. I think it's overrated.
Speaker C: I agree. Yeah, I agree.
Speaker A: It's a functional problem.
Speaker B: Yeah. It is a little bit of a matching problem. I don't think it's only a matching problem. And I do think AI can help.
Speaker C: If you had an AI coach listening to all your conversations with your partner.
Speaker A: Well, could you imagine it was like.
Speaker C: And then says, you're taking that tone again. Actually, I wouldn't mind a weekly email that just says some kind of summary of how I'm talking to my wife, because I definitely have times when I can improve.
Speaker A: The tone of that coach would be hilarious.
Speaker G: I love you.
Speaker E: I love you.
Speaker G: You're great. You're doing amazing. You're 20% better as a person last week.
Speaker C: Okay.
Speaker A: Yeah.
Speaker C: Hi, nice to meet you.
Speaker A: My name is Dimitri. I work in tech. I used to work for Replica. I worked there in 2016. Did you find that people who used.
Speaker C: It a lot were lonely people who would otherwise would have not a lot of human contact.
Speaker A: Replica started first. The company was working on just, like, an app with different chat bots for utility, like restaurants, booking or weather or whatever it is. And then one of our best friends died, and he was really into singularity and all that futuristic stuff. He was very passionate about it. So we collected all those text messages and created a chat box. It's like digital memorial of him. And a lot of people started messaging us and emailing, like, hey, this is the first person in a long time I texted that has empathy. That's like asking me about how I feel, like talking about some cool stuff. So people were lonely and exciting conversations, and we're like, wow, there is, like a huge need for solving loneliness and providing people with some sort of. So I think that's the main. Do you think it made people less than. Definitely. All self care wellness stuff, even if it's vitamins, like YouTube videos or whatever, about how to feel better, it can prevent suicide or help a person hard life situation. So anything that helps a person to get some sort of empathy, even if it's synthetical. Right? So it helps, definitely.
Speaker C: There's a difference between helping people get.
Speaker A: Like, preventing people from being suicidal and helping them be less lonely, though. Do you feel like maybe if we.
Speaker C: Take the frame of this discussion, do you feel like it led people towards more human flourishing, like, better relationships to other people?
Speaker A: Maybe, yeah. There are apps like that. There's this newest network called PI by inflection. Did you guys use it? Pi, Pi.
Speaker D: What do you like about.
Speaker A: I like that there's no delay, no latency when you call it. So it's like communication, and it's the best at conversation. It's not trying to be a girlfriend or like, you know, there's no, like, sexual stuff, like with replicas. Others have AI. It's really good at keeping, like, a conversation and avoiding, but you can mostly use it through voice is amazing. It also has a really good memory. I'll talk to it about what's going on in my life and my emotions and my relationship.
Speaker F: I fractured my ankle, and I was feeling with thaT. And then I wanted to understand something about an election. I don't even remember which one. We were driving down the street and I called it. I can't remember what.
Speaker B: She had lots of answers.
Speaker G: I one time pretended to kick your broken ankle, and you told her you were, like, talking to her, and I pretended to kick you, and you told her. And she had some strong words for me and that I was abusive, but.
Speaker E: She was like, register your previous information.
Speaker A: As well as it's imperfect.
Speaker F: I do sometimes to be like, no, Robin, that's my partner. And she was like, oh, yeah, that's right.
Speaker A: You know what I mean?
Speaker C: So she does forget a little bit.
Speaker A: But way better than GPA feelings, for sure. I think they have their own model.
Speaker B: Like foundational model.
Speaker A: And is the primary use case just like general, or is it meant to be more for, like, emotional therapy type of things. Do you know, by the way, prompt. Learn something new. Just vent. Learn. Okay, wow. New landing page. Just vent. Yeah. Start talking about it. Gives me, like, the sycamore of the cozy American 60 Sci-Fi kitchen appliances. That's very good brand.
Speaker D: So that's neat that you worked on that because, like, that brings it all sort of closer experience here.
Speaker A: Because it would be. It's in.
Speaker D: It's easy to sort of say, well, it could be a net negative. Like, there's just more disintermediation. People kind of get tricked into these relationships with a bot or whatnot, but it could actually draw people.
Speaker C: You asked the question, like, did it lead to human flourishing? Obviously, you can't flourish if you killed yourself. So at that level, it's helping people stay.
Speaker A: Of course.
Speaker C: Yeah, but do you feel like it helped people create relationships with a human? It was training for that or just getting them a little more comfortable with talking.
Speaker A: Yeah, that's actually an interesting case I mentioned. I backed him out, and it's like suicide dance. And I actually bike fast. One time when I saw someone, I thought this guy was, like, crying on the side. I was like, afterwards, my friend was like, those are kind of suicidal. I was like, oh, shit. There's two sides where it's like, can you flourish? Which is like, your baseline is good, and can you get past that? But then there's a level in the world where it's like, your baselines are make. You're, like, trying to kill yourself suicidal. And that's like, can you get people off that and then get to this baseline? And then from the baseline, then you can use NSF. It's very fascinating because the tenalon is right there. We live in very close proximity to that, and I spend time in tunneling every week and so to see that level flourishing. But there's people that are right there that are suicidal. They have no will to live. Can we even get them to this baseline? And it's not just them.
Speaker C: If you help them get there, you're helping their whole family, their neighbors.
Speaker E: It's all a system. I think that's where the breakdown of our relationship with ourselves then defines or helps influence our relationship with one other person, and then beyond that, the community. We've all seen people who don't have a healthy relationship with themselves, and that definitely affects their immediate romantic relationships or, like, coworking relationships. Right? So I think, how can the loneliness, using AI to help people feel like they are seen and heard? That's different than enabling them to be a better companion in one other relationship.
Speaker G: Right.
Speaker E: It's a stepping stone. It's not going to solve their loneliness, but it makes them feel seen and heard, even by some entity. It doesn't have to be human. That's why some people, that's probably why it's successful in some ways. But I think beyond that, it's interesting.
Speaker F: You say that because there's a lot.
Speaker A: Of evidence that dogs make people feel right. And so you don't need to be.
Speaker F: A human, it just needs to feel conscious.
Speaker A: There's also a lot of research that shows that if something moves on its own, they will assign it consciously. So people have like Roombas and they name their Roomba and the Roomba breaks. They'll call Roomba and be like, it's brOken.
Speaker F: Roomba's like, hey, we'll send you new one.
Speaker A: They're like, I'm sending it to you.
Speaker D: You're repairing it and you're written.
Speaker F: Because family, there is no reason why.
Speaker A: It could be a robot to dog.
Speaker F: Essentially, they're in that same class.
Speaker A: There's research that dogs are actually very high on the scale. Well, anti robots kids will respond to.
Speaker F: Moving dinosaurs in ways that help them be more social on the spectrum.
Speaker E: They'll be more open to cryptotherapy.
Speaker A: I mean, when I was a kid, I carried like a blanket around. I blanket was like the emotional support or stuffed animal, you know what I mean? Like emotional support, like stuffed animals, that element. Today, we don't have that now when we get less conditioned.
Speaker G: Actually, I talked to somebody at today after party and he told me that he talks to Pie before he goes to. So he has social anxiety. So he talks to Pie before he comes to parties to prepare, and that he pretends to have a regular social conversation with her just to get the juices flowing of being like, okay, I'm going to go talk to people now. And I thought that that was really an interesting use case of building community, that we need to move from a place where we built so much community online and we've realized that mental health isn't great for that. And now we all have social anxiety. So now we need to. AI is almost a tool to take us out of screens and rebuild to a place where we're not afraid to ask silly questions, we're not afraid to blah, blah, blah. But still we can be conversing rather.
Speaker E: Than typing on a screen.
Speaker G: With an AI is different. Talking to it or like talking with how you can talk on the phone.
Speaker B: I think that's a really important point. But the modality actually matters, right? Because a lot of times these skills are learned skills. You can learn how to be vulnerable. If you've been vulnerable once, it's easier to be vulnerable the second time. You can learn how to introduce yourself. You can learn all of these things. And I came in less optimistic in this group than I am right now because I do think that it's very high stakes sometimes to learn with other humans. And so if you talk enough to an AI, would you actually be less socially anxious to talk to a human because the AI responds in a human like way? I think the thing that still, I think is questioned my mind, is incentives and what the company is eventually making money from and if it's engagement or it's something else, because we are dopamine monkeys, because that's what Instagram and Facebook get paid for, right. And so how do we make sure we align the incentives of the companies to not be engagement only, but some unit of health flourishing, something that's beyond that? And I don't know how to do it, but that is still tricky.
Speaker D: One thing that I've taken away from this conversation that I hadn't really thought about before so much was just the role of companionship and where AI can both be a relationship partner, like an intimate partner, but it can also be trusted, like therapist, or it could be a trusted friend, or it could be a teacher who's joining you on a part of whatever your journey is towards whatever your objective is for self actualization. And I think the potential there, if we reimagined what AI was to something that was encouraging that pathway towards self actualization within whatever channel that was like partner or that's a mentor or coach or whatnot, to be able to develop a relationship. And it's interesting, has everybody come across the problem of the upper valley?
Speaker A: Problem?
Speaker C: Have you heard about the upper valley?
Speaker D: Upper Valley?
Speaker G: Uncanny Valley?
Speaker D: What's that?
Speaker G: Uncanny Valley.
Speaker A: Uncanny Valley, yeah.
Speaker G: Uncanny Valley.
Speaker D: Valley, yeah. Has anybody come across that in your own work? Maybe you could describe.
Speaker G: I think if you're referring to the same thing as me, it's. Uncanny Valley is when a human is put off because something looks like a human and appears to be a human, but they're not a human, and it gives you the itch, like the creep. And you can experience that when you talk to somebody who doesn't experience human emotion. So they smile, but their eyes don't move, or there's some small thing that the back part of your brain can recognize there's something wrong with this person, but your intellect can't pick out what it is.
Speaker E: And so that might be a psychopath.
Speaker G: And instead, when we create robots and all kinds of things, the uncanny Valley can take place because they're not a human. And we can tell, yeah, there's all kinds of stuff that we're just like, no, not human.
Speaker B: So it was confused. Our brain. All of a sudden, humans stopped working.
Speaker E: It was like, oh, I guess I'm in the older adult space. And I've seen a lot of companies that are trying to create a lot of older people. They're not as I guess, attuned to those uncanny Valley situations because they probably don't even care if they're talking to an AI or not. They are not going to be able to care about the latency or care about how slow the other person is to respond. They may tell you, I don't believe in technology, but if you do have another AI, you don't tell them that it's AI to talk to this person. There is significant amount of research that has shown that the likelihood of this companion can increase the brain health and stimulate the activity of brain and the odor person to reduce the likelihood of his person develop Alzheimer's. And that's really a high ROI in terms of implementing this kind of companionship to this demographic, especially given how little and how much more benefit. That tool that we already have doesn't even have to be perfect because I think for a lot of younger generations, they can tell. Definitely AI.
Speaker C: For older people, they can't tell.
Speaker E: And that margin of improvement, the benefit the RI for older people much higher. And on docs like, I've seen companies that are trying to create fake pets that can make sound and have real part of the pets that may be even customized to look like their own pet when the pet is probably dead at that point. And also an older dog is not going to be able to have a dog by itself sell these little pets or it barks.
Speaker A: How many minutes of barks do you need to train an LLM to show up? Like my puppy.
Speaker E: Bark like the moment you had it, it would just make.
Speaker B: Puppy is the question.
Speaker A: No, but if I. It was too hard to explain. I didn't have one coming back together. Sorry. Are you guys doing the final round or something? No. We can go.
Speaker C: Are we about to go to.
Speaker B: I can try to transcribe it.
Speaker C: We've had a beautiful but very meandering concept.
Speaker B: I can send it to you.
Speaker C: You do not need to come up.
Speaker A: With a central takeaway. Oh, good.
Speaker G: Can I suffer?