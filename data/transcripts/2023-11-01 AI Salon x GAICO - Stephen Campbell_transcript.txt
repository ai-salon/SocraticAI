Speaker A: Yeah, we got a voice memo going. All right, we're live. Let's do it.
Speaker B: I wanted to bring up a point that I thought was interesting. So when I think of education, I like to classify in two different kinds of education. There's some that you can learn from experiences and some that you learn from reading resources or using other resources to learn information. So how is AI going to affect the learning of experience? Because that's often harder to obtain and learn. That's like an interesting. Can I ask you a question? Do you not feel great teaching is an experience. Great teaching is an experience. I think it is. But I think it's often said that the world is also the best teacher. There's some things that another human can't really teach.
Speaker A: I'm going to ask you to speak a little louder. We're having trouble hearing you over here. Cool. If we, like Hemi, circle the chairs. I'm a little bit behind him. I think the distinction you're trying to make is between attachment skills and things you learn. So there's things that you learn by doing, for example, direct response marketing.
Speaker C: No professor is going to teach you doing that.
Speaker A: Whereas if you actually launch Facebook ads like you're learning yourself, so they learn from tacit skills. How does AI impact that?
Speaker C: And then.
Speaker A: Yeah, I'm also curious about the two signal problem, which is like one on one tutoring. Way better for education compared to classroom education. So I think both.
Speaker D: This one's really interesting.
Speaker A: I have nothing to add.
Speaker C: Yeah, thank you for clarifying.
Speaker A: Can I say, I work in hardware and I'm terrified that, well, obviously there's been a bunch of papers done the past couple of years where you can see through walls with WiFi signals, but machines can natively see in extra spectral range right there. It can see an infrared and ultraviolet. And this is not the spectrum that we can interpret signal in. So I would love to know. We might be learning from AI, but there's so much that it can ingest that we can't. That I don't know. I know might be the wrong discussion, but There has to be some, not just safeguard, because that's a different topic. But I'm very concerned about that. So, like, safeguards between the kind of AI tutor people relationship, because the topic is creativity, innovation and learning. And I think we can learn a lot from it, but I'm just concerned that we cannot out innovate AI and for it to have extra human sensory perception.
Speaker D: An interesting way to approach this by intentionally developing AI that is human, that doesn't go beyond being human. And in some ways, that AI can be a better partner for certain tasks than a superhuman AI. Like, for example, replacing human beings in behavioral studies or surveys for doing consumer research or policy research, trying to predict the ways that human beings will vote. But I think that there are other implications towards that kind of thing as well, which is what I personally work on, and I also do artwork. So I'm worried about what you brought up in the field of art world as well, because so much of art is based on archaic memory, thinking about what it means to be human, assigning meaning in our existence. And I think replacing that with an AI that, as you said, it takes in things that we cannot take in and can be potentially harmful. So thinking of how to develop AI to be human versus superhuman is not practical in every context, but an interesting way to think about.
Speaker A: Definitely. So, like, humanity playing an aspect in innovation is something that you kind of mold over. Where do you see that?
Speaker D: AI startup too? That's what we're creating to create an AI that has the same biases.
Speaker A: Interesting. Does anyone else have ideas on biases in AI and creativity? I think that's a really interesting kind of thread there.
Speaker C: I think one larger question I'm asking is, what's worth learning in the age of generative AI?
Speaker A: So before, if you had to get.
Speaker C: A PhD in, let's say, plasma physics to contribute to a fusion generator, you'd.
Speaker A: Be a twelve year old.
Speaker C: Just like talking to different agents, trained on physics textbooks or curriculum, or even just having multimodal data to give you feedback as you build this thing. So with the idea of infinite knowledge on demand, or even ability, what's worth learning? And also what's worth doing from the creativity side or from the learning side?
Speaker A: Interesting.
Speaker C: I think that's a really interesting point. So this guy I met back at university never coded in his life. He coded like a little bit. And I've been coding since I was twelve, so I've become like a really good coder. In the space of three months, using Chat GPT, this guy was writing better programs that I've ever written by just prompting GPT really, really well and making this meticulously crafted prompt. And so I realized, like, oh my God, I spent like, what, the past 20 years of my life? Sorry, ten years of my life. Let's go. And this guy just outpaced me just in three months to chat GPD. I do think programming is one of the things that'll be out the window, but then what does that prove more generally, that what's methodical skill to learn? Not any concrete skill. Coding, for that example. Was it like the meta learning?
Speaker A: Was he able to scope down problems where he outpaced you at creating different.
Speaker C: Functions or parts of the algorithm? Or was it like architecting? There's a larger meta. Honestly, I think it's like a bit of like a pride thing. I think a lot of programmers, you take a lot of pride in your code and you never want to look up how to do something. You want to code it all yourself. Whereas when you're using Chad GBC, you wouldn't mind just every single bit. Bang. GBC writes out, bang. GPS writes about, read the doctors, write it, write it. And just quickly going much faster, they just move at a much quicker pace. And I think the skill that I think is worth learning, at least at this point in time, is learning how to work with COVID because then you are super. I think I would want to teach.
Speaker B: My child would be how to work.
Speaker C: With these COVID.
Speaker D: Can I ask you a question? Would you think that the same dynamic applies as painting or photography?
Speaker A: Did you guys see that in the back? Okay, can you repeat the question for.
Speaker D: The group says, that dynamic that they just described, would you think that applies to painting, photography, music?
Speaker C: Right? So not yet. So with the vision chat GPT, vision coming out, and some of these larger multimodal models, imagine chat GPT, but on your camera. So you ask yourself, hey, I'm in a room. I want to capture the most captivating, dynamic moment of these humans. And now with chat guiding your hardware, you could capture the moment. So right now you could manually send that to chat. You could take a photo and be like, hey, I took a photography, give me some feedback, change your angle, but eventually you'll be able to have that on device guidance. So from a photographer standpoint, if part of getting a skill is getting repetition, which is like number of photos taken and then number of photos shared, eventually that can be condensed into just like.
Speaker D: The moment, because I don't, maybe this is just very specific, but when I'm painting and I like what turned out, I am completely shut off from technology. And even like my ancient laws, it just doesn't. So I struggle to think about how I could be interacting with the AI.
Speaker A: And also it depends on the feedback, right?
Speaker C: Like, if you're trying to build a.
Speaker A: Skill set, feedback is insanely valuable because you get that way to figure out.
Speaker C: If you're doing the right thing on the wrong day. But if you already have the skill.
Speaker A: Set and you're just applying it different things.
Speaker D: So if you go to art school, right, you do a bunch of drawings over and over and over again. And then sometimes you hang all of your drawings on the wall. The other art students and your teacher critique it, but you get, like, a bunch of human feedback on it, so people have different perspectives on it, so one person might really like it. I totally see how having AI that, at least that is not a very intentionally human AI doing that will result in the same creative influence.
Speaker A: Don't have a rebuttal so you can.
Speaker C: Start breaking down personalities of what the AI is.
Speaker D: Right.
Speaker C: So in one area, that was an assistant, in one area, you could give it a critique personality, which is like, instead of being one art professor who's trained on ten years of hundreds of samples and hundreds of students, imagine an art critic who's trained on every single artist portfolio ever made visibility around your area of your medium or whatever genre. And then you could start giving it, like, an objective function. Like, hey, I want to present my work at a professional gallery. And so what your art teacher critic would be doing, you're actually doing it with a larger data set.
Speaker D: So that's exactly what we're building. Synthetic response at my company, because this is exactly what we're building. It's just not close to your question.
Speaker C: Like, how to imagine that the whole AI plays.
Speaker A: I'm curious.
Speaker C: That seems pretty clear. Like a virtual critic.
Speaker D: Yeah. I think more philosophical debate that we have at where I work and I have with other artists sometimes, is, does AI have to be able to build a nation to be truly human, or to even be like, a superhuman AI? Like, there are so many ethical considerations around intentionally creating an AI that, because I feel like a missing piece of the puzzle when you think about AI and art is the emotional reaction to an art piece is so integral to what we're doing.
Speaker B: So is AI going to have the.
Speaker C: Emotion break into two groups, but based on the timing, everything just keep going.
Speaker A: One discussion. You need to take a break at any point.
Speaker C: Get that, or whatever, just do that. But we're just a long time.
Speaker A: Would it be beneficial to separate into.
Speaker C: Two smaller groups of five or six?
Speaker A: Yeah, that works better. Yeah, we could also take, like, an intermission at some point too, I'm sure. Because if it's 30 minutes and 50 minutes, but perhaps that's a great point. We have enough chairs here. We could form these chairs on a group. Yeah, we could just divide it in the middle. Do we want. So we'd probably want someone to record this separate conversation I think AJ.
Speaker C: Likes.
Speaker A: Well, there you Go. Cool. Okay, let's break for a couple we do have back. Yeah, we do have enough space. We have enough space over here. Let's migrate over here. All right, you come with us. You come with us. Yep, we can.
Speaker C: It's.
Speaker A: It's acoustically not the most optimized room. It's fairly unacoustically optimized.
Speaker D: Sorry.
Speaker A: Like, shut up. Wait, who was. Who was the one recording?
Speaker C: Is it UC?
Speaker A: Yeah, I'm still recording. Here we go. Let me get this signed.
Speaker C: There you go.
Speaker A: Nine A and nine B. All right.
Speaker C: Nice thing, by the way. It's similar, the icebreaker, being outdoors. I climbed up a hill today. It was really.
Speaker A: Did you mission up in mission?
Speaker C: Yeah.
Speaker A: Nice. Mission Peak.
Speaker C: It may have been Mission peak. We're down in 24 speed mission in the city.
Speaker A: Should we do a little round of introduction? I was going to say I showed.
Speaker C: Up a little late here, by the way.
Speaker A: Oh, my goodness.
Speaker C: Isn't it wonderful?
Speaker A: That is just incredible.
Speaker C: Yeah. Really, really good. Never seen anything like it before. Nice.
Speaker A: Well, yeah, let's do, like, a quick round of intros and then get back into it. You want to start us off, Brandon?
Speaker C: Hey, guys, I'm Brandon. Nice to meet you. I'm staying at 24th Street Mission. I'm only here for three months on Esther, my co founder, and I were trying to raise out here. And if that goes well, then we'll get a visa. We'll stay here for long. We're working on trying to make the world's best teacher to turn your kids into the generation's next.
Speaker A: And you and Sherry are.
Speaker B: Sherry?
Speaker D: Yes, Sherry. I'm a photographer, actually. Photographer. So creative aspect of it. And talking about the sky earlier, the great view of Jeff was magnificent, wasn't it?
Speaker C: Yes.
Speaker D: Amazing Jeff, definitely.
Speaker C: Magical.
Speaker D: Creative world is going to go so I can follow it and roll with it instead of not important.
Speaker C: I'm Joshua. I'm here studying engineering management. Has a background, computer engineering. Generally interested in the hardware, but here with AI kind of connects to. Since I kind of continue to use it for ever more things in my day to day, I'm kind of wondering on also talking with the photography where to balance basically being authentic and human and building real results and kind of. I'm much more sympathizing with the view of seeing AI as a tool. Contrary to kind of completely merging it and striking the balance between fine tuning, let's say, language models, but still kind of where is. How do we navigate being authentic human while leveraging the powers of AI. And using that power.
Speaker A: Real quick, where did you say you were?
Speaker C: Southea Itu University.
Speaker A: Nice. Cool.
Speaker D: Hi, everyone.
Speaker B: My name is Devanshu Brahmbat. I'm doing my master's in University of Texas, but I'm also doing my thesis in the Lawrence Berkeley National Lab. So I'm staying in Berkeley, and I'm doing my thesis there.
Speaker A: What's your thesis on?
Speaker B: My thesis is on the data storage and visualization platform for quantum computers. I'm into that. And recently I founded a company called PaperToCL, where we are aiming to explain research paper using AI power generate explanation. So our goal is to anyone on the planet Earth, you can easily find the research, understand the research, and apply the research in the real world. And that's the thing I'm doing.
Speaker A: Hey, everyone, I'm Pierce. I am co founder of the Gen AI Collective. And outside of that, I'm in a restaurant, FPV, from something like Series A, Series B. Do a lot of AI? My whole life revolves around AI.
Speaker B: It's awesome.
Speaker A: And I would say my interests lie. I guess that's kind of what we're talking about. My interests really lie in. You were talking about how AI is going to augment the skills of people. I'm very interested in the exponentially more complex system that we can build being augmented by AI. So whether that's software using code generation, right. I see code generation as that next iteration on high level programming languages, or whether it's drug discovery or social connection, every complex system that we've built over the past society, right. Has the potential to exponentially improve with AI. So that's what really dominates me all. I'm Stephen here with the collective as well. When I'm not doing work with the collective, I have a startup. It's called revamp, and we do marketing automation using AI. And then in terms of interests with AI, I think it really varies. I don't know. It's been interesting to see how quickly people can learn things. Like a lot of our friends have learned how to code and taken up new skills through AI. So really interested to see where that'll go from here. And then we have one more. Yes.
Speaker B: I'm Susanna.
Speaker D: I'm the co founder of a startup called Subconscious, where we create both, like, well designed experiments and synthetic respondents who represent human beings. Not superhuman, like I was explaining earlier a bit. They can do surveys. They can also tell their political opinions. So you can predict the voting preferences of the portion of the population that does not vote. For example, there are a lot of applications for it that I can go to if you're an issue. And I'm also an artist at their company, Lucid Dreamwalls. You can see in the names, which was not intentional, actually, I joined subconscious after it was already named. A little tip there. So I find the intersection of AI and art very interesting. I'm a traditional oil painter in my art.
Speaker A: Have you played around a lot with like mid journey?
Speaker D: Not a lot.
Speaker C: Actually.
Speaker D: Some of my best friends do AI art and are like, art and technologies. And my art, ironically, is not traditional in terms of what it depicts, but it's traditional in terms of the media.
Speaker A: Yeah. Okay, well, we can kind of continue on the thread that we had in that whole group, or we can break off and do kind of go off of a thread that interests us more. It's totally up to the group.
Speaker B: I was continuously listening all the ideas that were discussing there. And I think you also mentioned that what at Max, the AI can go. I think one of the best thing about the human mind is the imagination. And I think the imagination and the creativity is tightly coupled. That's what I believe. And I think AI is the great tool for learning, for sure. Like end of sentence, perioD. But I also believe, or what I felt is like, it is slightly restrictions on my imagination, the creativity, because I can get everything literally instantaneously. Like if I want to write a poem, I can ask GPD and I can get the poem instantly, so that it's like a kind of breaking to my creativity, so to my imagination, and that's kind of thing I'm concerning. Or know what? Can we leverage AI to help us to increase our imagination rather than restrict our imagination?
Speaker D: I have some friends, to be honest, maybe this is like a little narcissistic. I was very irritated about this in the beginning, but I have some friends that were not artists at all, but were using AI since they're like, I'm an artist now.
Speaker B: Okay.
Speaker D: It took me like years and years and years.
Speaker C: They really put themselves in artists.
Speaker D: Yeah. But then I reevaluated because they were spending a lot of time contributing to the arts community, trying to put on shades, like getting more people involved. It is good on balance that everyone is more creative, even though it might hurt my pride a little bit.
Speaker A: Well, I would say every time there's like a major technological shift, like barriers to entry fall. Right. And that ultimately it's OD in the beginning and you kind of see exactly what you said. Some people just don't really know what they're doing. When it comes to art, if they've never done art before, but in the long run, it always ends up they're learning to look at, right? Yeah, exactly.
Speaker D: I mean, their art has improved, but.
Speaker C: Are they an artist or are they just a prompt engineer?
Speaker A: It's a good question. Well, okay.
Speaker C: Programming and such programming about this is.
Speaker D: That with this particular context, I am more comfortable calling them an artist, not necessarily because of the quality of their own art, but because they've used it as a reason to put their resources into putting on shows, getting more people involved in the art world. I think that the shows they put on are incredibly well done, and that is kind of their artwork, but their wedge, better word to get into that was feeling empowered by that, the AI art stuff. So that doesn't apply to everyone. But I think lowering the barriers to entry to things is always, and I could see instances where someone never had the opportunity to do art. AI made it really easy for them to do. It turns out like they're a growth artist. Artist personally. That's another.
Speaker A: I'm curious what you think. I mean, you're all about finding hidden talent and stuff like that. That was kind of part of what I took away from your guys pitch.
Speaker C: Yeah, no, I think in the office scene, a bit weird, because obviously I'm not an artist, so I can't say too much, but I do feel like, take, like, paintings, for example. Right? You need not paint in a modern day. You could use a tablet, you could do it just fine. But people still paint, and there's a lot of value in painting. So it's like. I don't know. I mean, I want to say that part of what makes art good is that you spend a long time on it, and I know that's not true, and people say that's wrong.
Speaker D: I don't disagree with that. I think another related thing that makes art good is that you put so much information into it and it could be very personal, like an AI. This art piece relates to this thing that happened in my family, like, ten years ago that still really disturbs me because we don't have that experience. Maybe one day they will, but that would also create a whole other. Every now complications is not the biggest interesting right now. Everything. 3D things. I love paintings. After I study seeing, like, Van Gogh, it's like, yes, they're nice to see in the art book. And then you go there in person and you can practically feel the thick brushstrokes and you can feel the emotion in it. Thickness to the paint. Picture him there something that, like, AI might recreate something that's really cool? Oh, great movement, but just get in.
Speaker C: Person.
Speaker D: And they have an extra feeling. Yeah. There's actually a study that showed that when people see the texture in a painting in their heads, what they're doing is they're recreatiNg, like, a video of the painter making. Really? Okay. And then that generates emotional reactions. I did not know this until a few days ago when I met a woman who started an AI company where she's also an artist. But the AI company uses robots, like, very specifically trained robots to.
Speaker C: What's the name?
Speaker D: Acrylic. Acrylic robotics create, like, large scale paintings using the ray bots from painters works in collaboration with the painters, so that more people can afford to have large scale, semi original works in their homes. I thought that was an awesome chance of incorporating AI and art because it retains the human element, which is the art instrument, and it also retains the things that create emotional Morales, like the textures, which you can't get in. I talked to her for forever when I was supposed to be, like, a printout at this point. Wow. That's right.
Speaker B: The robot is basically mimicking the paint job.
Speaker D: Right, right. I'm going to do it. I want to try it out as an artist.
Speaker B: Oh, I see.
Speaker D: So that when you're technical, like, you have to put in. Okay, all the down.
Speaker A: Yeah, it's a good question.
Speaker D: I was talking to her. She was like, right now we use Adobe InDesign, and you can do it on a tablet and it'll mimic you. There's another one that's coming up next where we'll have cameras so you're not constrained to that particular medium. Right now, they just use acrylic as the medium for it. But if you want to do other things, they'll probably be a lot more complicated. If that's oil painting, I'm definitely going to try doing.
Speaker C: What I feel like with art photography, kind of to navigate the event, delivering something authentic. I feel like that's most helpful, probably that you had a long journey learning the skill of painting and with oil, certainly a lot of nuance and. Yeah, it. It takes a lot of experience, and I feel like in early stages of learning these skills, there's a lot of kind of tricks, like with perspective and things that if you don't have guidance, that take a lot of trial and error. And I feel like that's something that can be fast paced through technology, through tools, and not in a way where it kind of just gets generated and replicates the style, but you can actually learn the skill better. I guess that's also kind of connecting to your theme, but in the end, it's still a medium if you want to keep authentic and navigating it. I also kind of wanted to apply this tool and guidance and how can we use that to actually train us to be better?
Speaker D: I think someone was talking about.
Speaker C: We welcomed that.
Speaker D: Interesting learning more. I think something that is interesting to me is in some situations, for me at least, it was all learning, all art learning. I just happened in like a group setting with other artists, and you would learn almost as much from the other artist because for a number of reasons, just having like, I mean, I had art teachers that were like, by extreme art teacher that influenced me, but that didn't happen in isolation.
Speaker C: I feel like you could argue that maybe I'm wrong to say this because I feel like it might be a little bit different with just knowledge based things. With art, there isn't really a right or wrong. And I'm not going to say there is a right or wrong, but there is some wrongs inside, for example. And so in that, it's like there seems to be of value. Like, for example, let's say you have a room of kids that have one tutor who knows something, and he's trying to get kids to learn modular ripetic, but he's trying to do it in a Socratic way. He wants the kids to discover modular ripetic. He's trying to drop these hints. If one of the brighter kids quickly is like, oh, this is how mod three works and explains it. He spoke it for the other kids because the other kid wasn't able to understand it and discover it in himself. And there seems to be a lot of value when you discover something on your own and you figure it out. You just make that intuition. It's a lot stronger in you than when you just hear someone else say it and you just, okay, now I know it. I think in that sense it's slightly different. AnD I say, yeah, because there's like a right or wrong in that sense, with that.
Speaker A: How did we get on that?
Speaker C: Sorry, we're talking about art. She's basically saying how, like, you know, if you have, like a one on one AI tutor with art, it's really valuable. And you see, you learn just as much from the others as you learn from your tutor. Yeah, whereas I argue that that's true. But when it comes to science and other things, with right or wrong answer, it's more viable just to have you and the tutor, otherwise people spoil the answer for you.
Speaker A: Interesting. Do you think this applies to other fields as well?
Speaker D: An interesting placement of a diagram between art and science would be political fault. Where there's not necessarily always right answer and people debating.
Speaker C: Physical faults. Yeah, I don't like politics. They always seem to be like a massive mess.
Speaker D: No, but I would like to make when you growing up, like you learn about history and politics. I'm not trying to get into a political discussion here at the moment.
Speaker C: No, I'm just taking it as an example.
Speaker A: There's nothing stopping you.
Speaker D: My point is that might be somewhere.
Speaker C: That'S a little bit between.
Speaker A: Thoughts from this couch.
Speaker B: Yeah, I think the new education has to be AI compatible. That's what I believe. Like at this certain age, how many proportion of the machine learning you should be exposed with. I mean, that's going to be a very determining factor. As he explained, like if somebody is a smarter student and they can give me all the answer which I'm looking for, then I will never see, apart from that question, I can only see something. It's like I'm directly finding I can't see other thing and I do some heat and trial, I get the experience and then I learn the techniques, how to find answers if somebody's not there to help me. So I think it's like the education system has to be very compatible with the AI and if the age advances, you can do more expose to the. Yeah, that's what I believe.
Speaker D: Nothing about lawyer, but I find the concept really interesting. How can you be creative with it? In a sense that I think that anyway, creativity often involves not like arguing with someone and prove it. Saying that I'm right. If you're just in isolation talking to an animal. Yes, there are right and wrong answers in science, but sometimes you make discoveries by just being like that seems a little off and I can't describe why, but it's just intuitively off. So let's think about this in an outside the box way. And if you said that to some AIs, or at least AIs that I know of that exist today, maybe other fascinating topics, but no, that's incorrect. But maybe if you call it a rabbit hole, you would discover something. Because I think there's a place for creativity and science.
Speaker C: You just need like a better prompt, you need just a prompt that's like. Because the standard GPT is super clinical, we've all experienced it. It would be like, firstly, I'm an AI language model, I can't give you advice on doctor stuff. You need to go to a doctor. If you ever do medical things really clinical, always suggest no. But if you change his prompt well enough and you're like, never ever sell someone they're right or wrong. Just drop hints and just try and guide them in a certain direction, then it's a lot better and you can be put out these grammar holes.
Speaker D: Do you think? Because this is a little bit. We want AI to be kind of like a co scientist. The AI could collaborate with the person and be like. Even though they still have learned knowledge I'm trained on. Let's go down the trabic hole and see.
Speaker B: So are you saying, can AI be my best friend or like companion?
Speaker D: Kind of. That's not what I'm saying in this context. I'm saying, can they be like my co founder or like a co scientist?
Speaker C: You invest in me like my co founder, CPD, 50% efficacy. Don't worry about it.
Speaker D: Is it really interesting legal?
Speaker A: Steve, honestly, that could be like a.
Speaker D: Really clever way to keep your cat.
Speaker A: Table.
Speaker D: I used to be a lawyer.
Speaker B: Yeah. I mean, the time will come. That's what I believe for sure. And if we go into that conversation that what will happen when the time I think, as in machine, what differentiate between a machine and the human is the human instinct or what I feel or the emotion human instinct and my imagination. There are some areas. So I think once we have that, then it's like in human. So I think then I believe you can have a co founder as the AI will be a co founder. When we got the three things in the machine, it's very fast. That's what I believe.
Speaker C: Secretly, I don't know what you guys are using all the time. I think it's like enough to qualify to co found or GPC. Regards to these complexities that humans can handle. Higher complexities.
Speaker A: I think it's very similar to previous platform ships that we have just at an exponentially greater magnitude of improvement. Right. A lot of people were asking the same questions that we're asking now, 20 years ago during the dawn of the Internet, right? Like, how is this accelerated information exchange going to spur whatever new businesses or whatever new complex systems, right? And no one could have predicted Facebook or Google, right?
Speaker C: TikTok. Yeah, that's a great example. Right?
Speaker A: And it's the same way with take it back even further. Well, actually, a more recent example is mobile. Right around the time when the iPhone came out. Do you think anyone would have predicted Uber or Airbnb? These really weird concepts. I order a taxi in my hand or I do all these things without really having to get up. I think it's very similar with AI. It's not really like the means that is as compelling, because we've seen very similar cycles before, but it's the ends that are really compelling. So, to your point about people that are sitting in prompting mid journey, should they be considered artists? Right. I think it's a fair question, but if you just kind of step back and you don't really care if it was created with mid journey or if it was created on oil and canvas, but you just look at the final product, the overall ecosystem of art is bound to get two to the end times better in the next decade, in the next five years, honestly, because there's so many more people that are just doing producing art at a much higher rate of complexity. Right. And they can do five times as much. They can be five times as productive.
Speaker B: Interesting to me, because.
Speaker D: I fundamentally disagree with that analysis.
Speaker A: Okay, I'm glad you do.
Speaker B: Because I.
Speaker D: Think that increased complexity, in the sense that you think about it in terms of AI, does not make art improve, necessary. Like, are the, is this person that's using AI to create a painting in five minutes? Like, are they sitting there thinking about some random memory of their mother when they were five years old and all the art museums they went to, and coming back to the art piece, just more memory and more movement over time? No, of course not. You can't do that five times. So the eventual ALF piece might technically break, or might have like, a weird amount of complexity that, but it wouldn't have the really great art pieces that you can see from an art piece like 1000 years ago.
Speaker A: So it's the iterative process.
Speaker D: It's moving at a human speed that allows the unlocking of kind of like memory and emotion to come on. Maybe there needs to be a different name for it. I feel like artists who creates their hands is different. Honestly, somebody writes prompts. I think it's a different type of thinking. It's a different type of feeling, maybe a little bit more visual, so maybe you can do something different. And I know artists that are really AI and are like art technologists that still bring me art without that emotion that I'm talking about. So I didn't think that.
Speaker B: But they.
Speaker D: Categorize it this way, intentionally involves some kind of slow hands on process. And their art, even if it's like a computer that's involved in the background for moving pieces, it'll be like fan carved, like pieces of wood connected to a computer mainprint or something like that.
Speaker A: I'm curious, when Photoshop came out and all these digital art creation tools came out, people then were saying, like, people who make art on Photoshop are not real artists. I would guess maybe today they'd be considered artists. I feel like maybe most of us would. I don't know what we think. Like someone who makes art on Photoshop or in Lightroom or something maybe would consider them artists, maybe. And I'm just curious, if people think that is the case, then where do you kind of draw the line between, okay, stable diffusion is not an artist?
Speaker D: To be clear. I'm not saying that.
Speaker A: Got you.
Speaker D: I'm not even saying that AI itself can't be an artist. I think that's fascinating in the sense that humans define art. I think AI would have to feel emotion in some sense to be a human artist. But I don't think that came to happen. But no, I think people can easily journey and be an artist. I just think that it's not the same. Straightforward exponential got you.
Speaker A: Being a better programmer necessarily, that makes sense.
Speaker C: Have you tried kind of replicating your art with kind of stylistic copies and then let pictures in your style or your post paintings kind of generated in your style? Have you done that? And then basically, how do you feel about that? So I use AI and GPT always kind of just in my day to day to increase my productivity. And for example, for emails, writing or reports and kind of just tweaking the things. And I notice the end result is better in a way that, oh yeah, that's a creative phrasing and that's certainly better phrase. And then I always have to give feedback, basically. Okay, no, this is kind of over the top. I want this to be removed and change this and remove all these. Sometimes it's just generic kind of phrases that get in or chat. GPG 3.5 always loaded things way too much. Basically you have this iterative process and with some output. I'm now really happy where, oh wow, this is really great result. I don't know if I would achieve that just on my own, but I certainly reached that point much faster and it was just a very helpful tool. But I also noticed with other aspects that there's kind of things that get innocent where I kind of lack. Would I have even wrote that in that way now? KInd of outgoing some feelings if someone else now reads my things and thinks he didn't write that himself.
Speaker D: I've been reading through a lot of intern applications and it's really easy to tell the ones that.
Speaker C: But nevertheless, I was thinking about that. I do kind of have this feeling that makes my university. We kind of have assignments where we just work with AI assignments around that. So we kind of become literate, which I think makes sense because in the end we do want to have a way where we want to have the positive aspect and not the negative aspect there. But yeah, basically people notice that. And how do you navigate this?
Speaker D: What I think is now, but AI kind of has its own voice in a way that we have our invoices, and everyone using AI makes that voice a bit standardized, like you're taking on a voice that's not yours. And a bit about human flourishing. I think that there is a way to make AI allow us to keep our individual voices, but just understand each other better, speed up our process both in terms of community and in terms of individual whatever we choose to get at common language. So I think that there is like a deeply human dream, people from different backgrounds and languages being able to communicate with each other seamlessly. And I think AI can accelerate that. And I would love. But there's like another vision of that world where AI takes over the languages of a lot of diversity points. So ideally, we allow AI to be more of a conduit for human energy and diversity, as opposed to merging it in a way that doesn't retain wondering. I have a burning question, if I can pivot the conversation for a second. Yeah, please pivot the ethical issue. It's kind of creativity in journalism. There's what's real anymore? Because AI can do anything and create anything and make it look realistic. So what do we believe? Like, what's real? And where do we find that AIs learning from each other? Where's the source of truth? Pictures we're seeing of war that's going on? What's real?
Speaker A: That's a great question.
Speaker D: Is there a Way to ethically?
Speaker B: I think from your question there are like two separate discussion. We can draw from that. The one, what is real? Like we can manipulate the reality using the app. That's the first question. I can change the picture. That's the one in the generalism. And what if the AI is learning from itself, then how far it can go? So I think both are very. Yeah, I think it's like a concerning question, to be honest. The second one is more in my opinion that what if AI started learning from itself, and if we lose the control till the time we have the control, it's fine. But the moment we lost the control over it, and no time, it will surpass the human intelligence. I mean, it's like a very deep philosophical question. Might, it seems, but yeah, it can happen. Then we might have the real problem because we built something which is super evolved than us and he can trick us. We didn't even realize that. So I think the control on the AI should be there for sure. That's what I believe at the initial stage, until we have total knowledge of how far it can go, before that, we should have the control, then we can do whatever we want and for the reality check. So I think for that, then we need to develop a software to identify whether this one is generated by AI. That could be one solution. I think that would have to be done.
Speaker D: Would there be any kind of watermark or what needs to be done legally? Everything created by AI.
Speaker C: OpenAI and a bunch of other guys signed something recently, a couple of months back. Guys seen it. They're talking about making like a digital watermark. Yeah, I know, but is it because secretly a lot of people are saying, okay, we're still wearing good. For example, open AI. For a long time, Sam Altman was always like, guys, we need control over AI. We need big legislation and restriction on the AI.
Speaker D: Yeah. Hell yeah.
Speaker C: None of you guys should be able to make AI. It's really important that we have control of AI. Right?
Speaker D: Yes.
Speaker C: So it's a similar thing with that. So open AI. A lot of people think that Sam, on Purpose, he was like, yeah, GPG is crazy. Before they dropped GP four, he was like, this is going to change the world. And it did be fair, but nonetheless, here's a thing for being like, we're the big dogs. We know what we're doing. We should have patrol this. And there's some people are saying as well, when it comes to the digital watermarking, it's like another way for them to have this control of the whole system. We waterproof everything you do. It's us. We made this.
Speaker D: I was thinking watermark from the creators understand like some kind of.
Speaker B: And I think it's really hard to detect, like a technological perspective. It's really hard to, if we can see to email. So it's really hard to detect, like which one is from the child GPT and which one is the human written. It's like, it's really hard. It's like a technological problem.
Speaker C: She argues the opposite, right. That it's easy to distinguish between human.
Speaker B: So nowadays you can feel like you can't expect the email from a student who is in twelveth grade with the labor. So that person cannot write the email with the expertise English professor possessed in English.
Speaker D: And there are some patterns as well.
Speaker B: In the chat deputy, but eventually there might be not patterns. You can't really find him.
Speaker C: I was just thinking, a friend of mine, she does some language. She put her journal. She basically trained a language model based on her journal to have her authentic writing style. Basically, the much more data you feed it of your previous work, the more authentic your future generation work program.
Speaker D: You can fine tune because it's like email address. They know who you are and they learn from like my songs, they were like, how do you input?
Speaker C: No, I think it was not with chat, with the GPC, with open AI, you can fine tune a model on one of their APIs. But then also a lot of people have their own smaller models that you can fine tune.
Speaker D: Her personal software or something.
Speaker C: Was it like with like llama or whatnot? Because like Facebook has a model that you could run locally. Yes, it must have been like. It may have been a llama model, but that's what Facebook has, right? L-L-A-M-A Flora, you. Laura, based on his sister. Like fine tune the level. And we're trying to think more, though. She fine tunes.
Speaker A: Sorry.
Speaker C: She fine tuned journal to write like.