Speaker A: It's okay. I think we, we have a group here. You all, when you figure it out, let's move in this one, get a little more intimate.
Speaker B: Sustainable development.
Speaker C: I think, like society, just the interest in sustainability is really low.
Speaker A: Oh, right. Now, how many people are with you? Only three people. Let's see how many people we have here.
Speaker C: One, two, three.
Speaker A: You want to go over there? Okay, cool.
Speaker D: Why don't you join?
Speaker A: Are you okay joining us? Well, are you okay joining the sustainable and AI?
Speaker D: You will be one fifth.
Speaker A: You can make that conversation. Okay. Where have all people joined?
Speaker E: I feel like they joined human experience, I think.
Speaker A: The human experience, yes. Certain ones are very general. This is the hardest part, honestly, I haven't yet. Go on and see. They can figure it out. I believe in them. Okay, so cool. Thanks for joining this group. The first thing I'd like to do. So we spent all that time just to get to this point, right. But now we're the group and so I'd like to go around. We can introduce ourselves. You're going to have to forgive me if I don't remember your names. Each name is new to me, but we'll go around and actually, I'm going to close the store.
Speaker C: It is.
Speaker D: That part is particular.
Speaker C: Yeah.
Speaker B: That part is. We can shift back. That part is.
Speaker F: Maybe I'll just shift.
Speaker E: I'm.
Speaker A: We're getting closer. There's a vent. Yeah. Okay. So, okie dokes. So, yeah, let's go around. And what I'd love to hear is who you are, why you were interested in just this broader event on human flourishing, and why you joined this governance and society subset. And so I'll introduce myself again. So my name is Ian, and like I said, I worked as a psychologist and cognitive neuroscientist. And I was at Stanford. Stanford has a lot of AI based things going on. And when I joined, there were two main focus areas for me, at least. There was AI as a model of the human mind, human brain, both kinds of things, which was very inspiring to me for a whole bunch of reasons. And two, there was the reproducibility crisis in psychology, and this was this recognition that psychology findings, and honestly, many social science findings and medical findings, anything that's statistical based, were not reproducing, or at least not reproducing as much as you would like. You would like a more efficient science. And that led me to kind of look at science as a system, right? It's a system filled with people with specific incentives, with different tools that could help them go better or worse. And so, like, different journals prioritized really flashy, exciting findings, and that led to less reproducibility. My reason of bringing that up is just to say it made me aware of the intersection between the technology or the science that we care about and the social structures around it that determine how it will evolve over time. And when I left the protected gardens of academia and moved into kind of industry, as we called it, that was a time of really considering many different things for myself. And I ended up being influenced by a movement called effective altruism, which, amongst its multiple tenets, is like, how can you use your time, your career, to do as much good as possible? And that means, what are the most important problems in the world? And EA was an early kind of focus on AI. This is going to be the most important technology. Making sure that it goes well is probably the most important thing to work on. And so I got inspired by AI ethics and AI safety. I didn't even know the word AI governance, but I learned about that with this company that I joined Credo AI, and started building the tools to support companies, build better AI governance practices, engage with policymakers and researchers about what standards could we create, how can we communicate them, all of these kinds of things. And so AI governance has now been kind of my life for the last kind of two and a half years. And of course, in this last year, not only did Chat GPT come on, but a huge focus on AI safety and AI governance more generally. Right. Other AI systems that aren't llms. And so that's what brought me here and on the governance and society. One of the reasons why I started the AI salon is because I really believe that in line with AI, being the most impactful of technologies means that it is really important that we bring as many people into the conversation as possible. Not just the conversation, but, like, meaningfully impacting how these systems are going to move along. And, for instance, coming here, I don't hear the indian perspective very often in most of my work. And so, even being here right now is a small example of me trying to better understand a broader range of technologists and things that people are going to do. And so, anyway, that's me. Let's move around.
Speaker F: Question you mentioned, do not reveal any names or details or anything. Are we recording this?
Speaker A: We are recording this. And in the transcript, I will scrub names. You shouldn't worry about anonymization right now. I'm just saying, hey, we don't need to do pseudonyms. Chatham House rules is a general kind of approach to just know when leaving here, not to ascribe too much. It gives us the ability to say things that might be a little controversial. All right.
Speaker B: Sorry, one more logistic thing. Can we turn off the background?
Speaker A: Oh, I have no idea.
Speaker B: I can probably help you out.
Speaker D: Thank you.
Speaker C: Let me see if this really cool projector. Yeah, it's a tv, I think. Damn.
Speaker A: I think I'm going to do this, which might be less.
Speaker B: Yeah, you can do the classic thing.
Speaker D: You open presentation or keynote or something and just put a blank.
Speaker A: Yeah, that sounds good.
Speaker C: Or can you keep the bubble that came up for our topic? I don't think that's okay.
Speaker F: This should be fine.
Speaker A: Yeah, perfect.
Speaker E: That's good. Okay.
Speaker G: All right.
Speaker F: Hi, my name is Harshali, I'm originally from Mumbai and I've been living in Bangladesh for the last five years. I am trained as an industrial designer and I started my professional practice as a product designer. I've always been interested in psychology and there's no real title as a design psychology person in tech world. So I've always had a freelance practice as an experienced designer for psychotherapists and psychiatrists and a day job in the tech world. And I've been a product designer, a product manager, and now I'm an early stage founder. My co founders are senior psychiatrists, psychotherapists, and we're working on building data analytics and training tool for the eastern hemisphere for mental health clinicians. So to put it in really simple words, most of mental health work, as you might know, is manual. In the eastern hemisphere, people take a lot of notes and to be able to reproduce a case, even just to explain it to your peers or in clinical supervision is really hard because I have a lot of caseload and it's all physically written, so there's no way to explain all this material without creating errors. And so we're working on something that's a recording tool, a private, secure, anonymized recording tool that will allow for mental health clinical training in the eastern hemisphere. My interest in AI and humans stems from my design education and with a subtext of creativity. So when we actually had to sketch things and you reach a point where your professor tells you to sketch 200 ideas, you run out of ideas and you start replicating the same things that the entire class does. And that was around the time large language models were starting to come out and gan and these things were kind of just in the mainstream discourse. So as a student I was really curious about artificial intelligence versus intelligence augmentation and Doug Engelbart was the inventor of the mouse, thinking about how artificial intelligence can augment creativity. And so that's my personal interest in this topic, which brings me to this conversation today in understanding how people are interested in this subject. What are their personal emotions attached to it? My grandmother still considers this as something that's going to change her life. So what are our interpretations of. This is what I'm most curious about.
Speaker G: Hi, my name is Roli, and we'll have some overlapping things in the sense I'm also a designer. I initially trained as a textile designer, and then I further went into design research, which was, I was working a lot in social impact sector, some of the corporates also trying to. So it's more about trying to figure out human behavior and try to link it back to how it should be designed. And in the last five years, I've shifted towards, I work for a fintech and so I take care of the user experience research with the fintech. It's interesting, I think also for me to sort of the last twelve years as a career from textile design to digital design. One interesting observation is that our careers, our regulations, our society, everything changes with these industrial revolutions or digital revolutions we've had. So I think currently, so far in the app space or a digital experience space. As a designer, your role was a lot around, because fintech is an interesting space where it's like you are sort of doing a bit of behavior design with regulation also coming into picture, right? Because finance is a space heavily regulated, right? So when you're designing, it's not so open. You have to keep in mind of human behaviors, their fears, the corporate sort.
Speaker E: Of.
Speaker G: The corporate sort of objectives, and at the same time the regulations. So these three things I think gave me an interesting perspective that how, say, the finance industry is changing, the regulations are also changing. So then as a designer, you feel a little dissonance in the sense that where you keep the corporate sort of interest and at the same time what is good for the human behavior, right. And with AI coming in, I think that becomes, that I feel becomes even more blurred because I feel like a lot of these AI models will be fueled by information that could be sort of, it depends again on the corporate interests or the government interests rather than the human interest. And then as a designer, where is our role? How do we change that experience? It's an intermix of governance society, at the same time ethical and what's right for the human. Because as designers, it's really unclear how our roles are going to evolve as AI comes in play, especially creating experiences for people that might. It's a big question mark right now, for sure. Yeah. So that's my interest in the space.
Speaker A: Awesome. We're just going around right now. We'll come to you at the end, but no problem. We're having a discussion right now about the relationship between AI and governance in society. And we haven't even really defined exactly what that means yet. But that's the theme.
Speaker G: I'm Kuba. I'm a lawyer by training. In the last decade, I have worked in rightspace organizations in the social impact sector, development sector. My last job was actually I worked from this building at Swast. What I did was during COVID I managed the delivery of oxygenation devices across India. Well, why this is interesting to me is obviously AI. We didn't talk about AI in law school a decade ago, but the things that I learned in law school, the things that I have seen in my work in the last ten years, how those things are relevant and they need to be talked about. Say for example, your AI systems are dependent on data, and it really matters where you gather that data from. If you don't take into account that data would have bias. You would have to make sure that the data you acquire is diverse enough, then it would show a different kind of result. Again, as a lawyer, I want to tell you that law is jurisdiction wise. So what laws we have in India is different from what is there in EU. EU has come up with the new AI act. So, yeah, just thinking through what are the implications for, say, the global south? Because our challenges are pretty know the thing is India is also three different indias. My reality is very different from someone in a remote district in.
Speaker A: So.
Speaker G: But when you are coming up with a lawyer is for everyone. So how do you make sure that their voices are also represented? That's interesting.
Speaker A: Yeah.
Speaker D: Hi, I'm prashank. I'm from. So I've studied something at the intersection of computer science and indian knowledge traditions. So I think I kind of take a leaf out of that when I think about how AI is impacting or AI is bringing that technology. So one of the things that has animated my world is the philosophy, technological determinism. So it is the technology at the end of the day that is going to maybe impact the future much more than anything that happens otherwise, whether it is, who are the kings who come up, what are the dynasties that are created or anything around that. And I think some reasoning around that is people say that it was a gunpowder that was responsible for the expansion of the world about, let's say, 670 years ago. And now it is computer or the telecommunication technology that has been driving what we see in the world. And maybe now it is the time of AI that's going to define what happens in the world from now onwards. I'm specifically interested in the governance bit of it because, as I said so, I have been curious about how society interacts with technology, how the governance structures interact with technology. And I have some experience in that. I worked as an election political consultant for about three and a half years, previously seen a past life. I was also posted here in the Karnataka government and then being able to see some of those things that happened from closed quarters about how people within India, they conduct elections. What is the farce of elections or the governance that goes on actually behind closed door within the political world? I'm also curious from that perspective, how does that reality kind of conflate with what AI can bring in in that same world?
Speaker B: Hey, guys, I'm Shashank. So I'll quickly tell you about what I've done. So, like most of you, I started as an engineer, worked for close to four years, kind of got bored doing technical work. I enjoyed the work and it paid well, but I think there's something missing, right? So at that point, I did a switch, like two more people left. So I did a master's in design and post that I've kind of always been in the intersection of technology and this design world with human centered design, right? So post my masters, I've worked mostly in kind of social kind of things which not development sector per se, but things which kind of are closer to my heart. So one was, I worked in affordable private school. So we were trying to see how can you improve the learning outcome. So we had a digital tablet and another one, we are trying to work.
Speaker C: With the blue collar workers.
Speaker B: So how can you help them find jobs, better jobs, whatever that meant. And being interaction design, I've kind of tried to be on the forefront. So working with the next billion users, working with chatbot. So this is kind of time I spent working on these form statements. And I hit a kind of point where I was kind of evaluating what to work on next. And I kind of took a break and I explored public policy. I did a program with, and because I felt that was a way to kind of understand how public policy is made in India and how does India as a nation work and how does the world work. So I think I was trying to kind of, that was my doorway to understanding things better, how things work. And I also spent time understanding the climate and what are we not doing as humans towards it. And I had a good amount of discussions with a lot of people in this space and my takeaway was there are a lot of these important, necessary problems, but they don't pay well. So I'm kind of leading to life. So at a full time I'm trying to optimize for how can I earn more. And as a part time kind of thing, I'm trying to see kind of spend more time on are we going progressing ahead as a good nation, as humans, I kind of tried to balance both. Right now in my current journey, I'm trying to build, so being a designer and a PM product manager, I'm trying to kind of explore AI and see can I build a tool to assist designers. So trying to be the bad guy, trying to take away jobs.
Speaker A: I'd love to hear what and just for the next introductions, I actually really do love hearing all of the things you've done. I would love to just if we can focus our introductions on just what about governance and society now is top of mind what's most alive for you right now? I would love to hear that.
Speaker B: I think as India, I think we have at least from the, if you've heard of the India Stack, the other UPI and digital public goods as it's called, we have a certain way that they have been released.
Speaker C: Right.
Speaker B: And AI definitely falls into that space and there is some activity going on in it.
Speaker A: Right.
Speaker B: But I think on top of my head, at least for me, the way I look at is people talk about, it's called samasarkar and bazaar. Like the corporates and the government and the society, the three pillars who kind of shape the way things happen, right. And AI is another equally strong technology and who plays a part in the way it materializes in India. And definitely the corporates have a very strong voice. Definitely the government has, in whatever way functions has it. But I think society has always lagged in being able to have its point. Like if you say human centered, this is humans are society, right? Like in this the closest can think of. So I feel humans have always lacked that voice in determining, I mean, the stronger people with stronger voices who get their agenda across. And with the foundation technology like AI, I feel that lack of participation is going to hurt humans a lot. And how do we bring in more agency would be an interesting challenge.
Speaker A: Yeah. Right.
Speaker C: So hi everybody, my name is Mithan. I'm running the networks of one of the banks in Dubai. I've been a techie all my life. It's been 20 plus years. I'm hardcore into networking, never been into software, but I've been obviously watching AI on the sidelines. I learned. I did a course on Tensorflow, and of course from professional curiosity. I'm also a little bit of a futurist, and because of being a Sci-Fi geek, it's stereotypical, right? Engineer liking science fiction. Like, I love Star Trek, I love a lot of these science fiction movies. And I, of course, watched AI and its role in it's both portrayed negatively and positively. Why am I interested in this topic? Is because, again, I've grown up in the Middle east. I've seen another form of government which most people in India don't really see, which is the government that is run by the ruler over there. Basically, they're taking decisions on behalf of not just their own population, but on behalf of expatriates. Now, I don't know if you know this, but in the UAE, Indians are basically 60% of the population. The local population actually is only five to 10% of the actual population. Right. But however, the governance is being run based on their priorities. Right. I'm not saying it's a good or bad, I'm just saying that's the way it is.
Speaker D: And we get to see a different.
Speaker C: Vantage point from the way it's being run in the US, the way it's being run in India. Each and every place has its problems of being run. I am a little bit of a futureist. One of the things I was actually planning on proposing as a suggestion was, what if we actually hand over the reins completely to AI? What if AI does the decision making for human beings? Because it would be free of bias. It would be free of at least as much as we can remove cognitive bias from it. What if it's able to really do qualitative, actual decision making, free of corruption, free of influence, free of meddling from other people who want to try and grab power for themselves. All of that would be missing in AI. The amount of money we spend on the election process itself, the amount of corruption that happens, all of that would be bypassed, at least. I'm being ridiculously optimistic. Some people might call this dystopian cyber communism.
Speaker A: I don't know.
Speaker C: This is just a fun thing to think about. But I've always been on the more positive side about technology in general compared to my peers. So that's what I wanted to talk about. That's why I'm interested in this particular.
Speaker G: Can I just ask, but how do you make a language model or AI? Unbiased question because people assume that technology will be unbiased, and that's a lot of ground that we talk about.
Speaker E: Hi, everyone. My name is Rashi. So I'm quintessentially Bangalore, and I'm as Bangalore as you can get. I've been here for more than two decades. I work in the public technology space. That doesn't keep me in Bangalore anymore, which I'm very happy about because I don't miss the traffic. I worked on issues. I work professionally in the airspace. I just had a report that I co authored with UNESCO on guiding policymakers to help with their AI strategies in the countries, because that's something that's very big. A lot of people want a slice of their pie into understanding how AI can augment different realities or different strategy areas. India has a very bold AI strategy indeed. It's very impressive, but it's just not. One of my complaints would always be that there's just not a lot of documentation around it to show the world and say, hey, we have a very ambitious strategy. I also work a lot around online safety. I work on web accessibility. How can technology be more understandable, robust people with different disabilities? I'm an engineer by training. But yeah, a lot of my issues kind of stem with public interest. One of my current research right now that I'm doing is on how do we combat or look at the influence of synthetic media and the role of Gen AI. So how does it influence elections? How does it influence conversations, the hype that's there around AI? Because even with chat, you've realized that a lot of the information isn't updated. It is till 2021. It has a lot of societal implications. I also come from a background where I've worked a lot on building preventive measures, on kind of looking at offline consequences of a lot of activities, actively working on the online information that has exacerbated genocide, in conflict zones where there's a, for example. And we see that a lot, even in the Genii space, right, with whatever Chad GPT or Grok or bard comes in that comes out and says, hey, you know, this particular allegation and societal impacts it has on this particular person, reputational harm. We had someone who spoke about deepfakes, and deepfakes is a pandemic in itself, especially when it comes to online safety or deepfake pornography, where earlier we had a lot of female politicians or women in the limelight, journalists or public figures who were affected by this. But now, with all the simplistic tools and the access you have without a lot of regulation coming in, how does that impact you? What are the safeguards that are there? And I had seen, I had done some work with online safety in the south asian context, and it was quite jarring that 90% of the cases that come in in the cybercrimes themselves are with defects. So, yeah, that's something that I'm very interested to know about.
Speaker A: Awesome.
Speaker E: Thank you so much.
Speaker C: Just one. Sorry to interrupt. Are there any other discussions going on?
Speaker A: There are many other discussions.
Speaker C: Okay. Actually, I come from the technology and the robotic space.
Speaker A: Yeah, this might not be the best.
Speaker E: Ethics.
Speaker A: I think you might want to go to that one over there.
Speaker C: There's one about cyborgs and all.
Speaker A: Yeah, go ask what the theme is. Yeah, go for it.
Speaker C: So my name is Shobit. I work in Bangalore, and I just moved back from Singapore like, a year and a half ago. I did my masters in machine learning, but they had a really interesting name towards it. They called it masters in knowledge engineering. So it's not how you make machines learn, it's about how you imbibe knowledge into a system. So it did focus a lot on the math of machine learning about something. And my eventual interest was always in robotics. So I did a three year research in Singapore working in soft robotics, and now I'm working with a company that does that makes laparoscopic devices. So, like, we're based out of Bangalore, and we make the entire system stack for fluorescence imaging and eventually going to move into surgical robotics. So that's where I stand. And historically, I've always been more fascinated by the questions that don't like the conversations that don't reach conclusions. For example, in suppose in politics, like, say, politics or ethics and stuff like that, and which is why this has drawn me in. So I've read a lot of foucault, a lot of John Rawls, a lot about how I'm not too much into politics, but I'm really interested in the philosophy of justice. So it's not about making laws. It's about, like, at the end of the day, which set of ethics or which set of laws results in maximizing the justice that your population gets. So that's why I'm a part of this discussion. I have a controversial statement to make. So I feel like when we talk about AI right now, it is known as a fact that what the consumer or what the end user gets is like the runt of the runt of the runt of the runt of the technology. So if you are wowed by this, there are already more powerful stuff. There are way more powerful stuff at play, and you probably won't see that. So for example, IBM had a supercomputer like for 20 years, we didn't do anything. And also the major AI breakthroughs that are happening now are totally very far away from the consumer. Like alpha fold, like the whole talkmark reactor thing by open, by DeepMind, all of that stuff is really shielded away from the end user. And what the end user is always going to get is like a very watered down version which fits a lot of general criteria. So I feel like the whole AI risk is a bit blown out of proportion. But yeah, I am ready to change my controversial opinion today. So let's see.
Speaker A: Cool.
Speaker H: Hi, I'm Ashley. I'm probably the od one out a little bit. I'm a psychiatrist and a psychotherapist. And as someone who is always exposed to human behavior and impact of various things in human behavior, on human behavior, and vice versa, the impact of how we think and how we ideate and how that can lead to different things, I'm very much interested in this AI movement and interested in how, I mean, I'm sitting here, I probably would have been interested in any one of the topics. But also governance is very interesting for me because I do feel probably just like how it is here. Even in the legislative sections, in political sections, behavioral specialists or mental health specialists don't feature much and I don't think our opinion is asked. And we probably end up seeing people when there is a problem rather than when in the preventative space where we could have a lot more to offer. So I know that it's fantastic. I love your futuristic view. I can tell you 100 problems from that straight away. So I think it might be interesting for me, especially ethics is one place which I feel we need to have really think through, but where power lies is in the governance of it. So I feel like in the governance space or in legislative spaces, I think what you said about justice makes a lot of sense, but there does need to be a balanced view on what are we doing now. I like your opinion of it's not as bleak as it is, and I probably agree with that. But I also think that if we don't, it almost feels like we've all taken for granted that it's going to happen, as if it's magically happening. We all can think what needs to happen next, but we don't. And everyone just says, this is going to happen. It's a given. You can't do anything about it. But I think we can. We can think more, we can be more informed and really direct in a way that it can be beneficial and doesn't have to just happen as it's out of our hands. So I'm interested in governance from that point of view.
Speaker A: Cool. So I think I'd like to start the discussion with something like who has power and how does that power proliferate through society. So I forget who brought up that there are three indias, that there are different kind of, that somehow this country needs to develop some rules of the road that if not in the best case, bring up the bottom of the country but certainly don't marginalize. That would be one. You brought up the UAE and a very straightforward kind of power being executed by a small amount of the population and definitely for that small part of the population. And to your point about do we have to just accept AI being an inevitability? This is definitely a question even in San Francisco, but in India, you're outside of the major power creators of AI. Right now, OpenAI feels like an inevitability even in San Francisco to San Franciscans, let alone to people here, where it's like, yeah, AI is being developed and will wash over the world whether you want it or not. And so maybe one of the first things, and we don't have to be AI focused here. So I'd love to hear a lot of people brought up different aspects of money in elections and different components of how society has their voice heard, like the government. It was kind of interesting hearing people talk about people and then the government, as a government is supposed to be, supposed to be a kind of voice for the people. It's not the same as civil society. So I would love to start the conversation, I guess, about how should, in such a multi, we can just focus on India, but honestly, it applies at a global stage, at any stage, how should we try to aggregate information and create rules of the road to deal with the multiple different kinds of stakeholders that we need to when dealing with an all encompassing technology like AI starters.
Speaker C: I'd like to confirm what you would.
Speaker A: Mean by power the people, or I don't even want to say people.
Speaker C: Is it like a force?
Speaker A: It's a force, I think.
Speaker C: What does a force push? Does it push regulation? Does it push a lifestyle of living? Does it push behavior?
Speaker A: I guess where I'm coming from is there's a combination of forces that determine how the future evolves. And regulation is one set of constraints, pretty powerful one, because nation states are very powerful in determining how certain things evolve. But of course, access to technologies and human education, those are all other aspects that push against, because we're in the governance and society, we can think about, maybe focus our conversation on how the regulatory kind of forces intersect with bottom up kind of societal for a fact.
Speaker C: That, say, the SEC or even major regulatory bodies, they are still pushed by a couple of vested interest groups who wield a lot of power. So power in that case means a different thing because it is a much more powerful kind of power. If you are able to shape regulators, like, for example, how opena is trying to do for AI, they want to shape how the regulatory stuff will be framed. And like it or not, if they succeed, then that will be the framework for all regulatory bodies to take a look at and frame their own stuff. So power, in that case, does it mean just technological prowess in the case of OpenAI? So my point over here is that if we have to dissect what the systems are doing wrong, then do we shift the power onto what's happening now, or do we shift the conversation to what we want to happen.
Speaker H: Just in response to what you're saying? I feel like technological prowess may not be enough if it is not popular. So the power might lie more in what becomes like a mass thing.
Speaker D: Even to think of that, while AI can be the mass thing, where it influences society, your everyday life, it is also a defense, or let's say a military technology at the end of the day.
Speaker A: Right.
Speaker D: And then when AI talks about the power, that power can also wield the technology to do other things that probably are not the things that we are talking about.
Speaker A: I guess just to bring it. Like, there are many stakeholders in. Let's just talk about what are the three ndos that went with. What were you mean by what are the three?
Speaker G: Okay. The first could be people like us.
Speaker A: Who.
Speaker G: Super privileged, have traveled abroad and speak in English. Speak in English.
Speaker E: English is.
Speaker G: Yeah, think in English. All of that.
Speaker E: We're also the only ones who pay.
Speaker D: Taxes or the ones who don't pay taxes.
Speaker E: If you're Uber.
Speaker A: I love it.
Speaker G: Yeah. The second would be people who live in tier two, tier three cities, women who are shepherd everywhere where they go. They probably don't even own their own phones. If they do, they would. Yeah, yeah. It would be something like that. The reality is very different. And the third would be, okay, I'll give you an example. Like Karnataka the state we are in, the indicators metanol, mortality, and all those indicators are like some european countries, but there are other states in India, in the north whose these kind of indicators are like sub saharan Africa. So if you go read, I'm not talking about sitting in the capital of those states, but if you say go deep inside a district, in a subdivision, the reality of women, children there is very different. So I wouldn't even be able to.
Speaker A: Identify with them because, yeah, totally within this vast range of different kinds of people, perspectives, goals and abilities. When we talk about governance, there's someone, some entity that will certainly say that they are trying to represent the many stakeholders. That language will always be used, but sometimes maybe they will be. Maybe there's regulatory capture and such that they're essentially a voice for kind of corporate interests. I guess the conversation here is, given the reality that people in villages are not going to be empowered, they are not going to be that meaningful in the evolution of AI. They are going to be affected by it, but not empowered for it. And that happens on many levels. And I was saying, like, India is in some case as a whole country affected by this trajectory that the US is honestly leading in, how do we set up structure to safeguard, or at least make that more of a.
Speaker G: I'll quickly finish. So just as a lawyer, I'm telling you there are some laws in India, so they are remnants of the British. Most of our laws are remnants of the British. So a lot of the stuff that we are talking here probably would also come under Indian Telegraph act, and Indian Telegraph act is from the 1800 something, 1870s or something. A lot of that is still relevant. A lot of the telecommunications that happens is there are new laws, there are new rules, but that is like the parent act. So there are similarly, in every sphere of your life, there are some laws, like the evidence act that we are talking about. The Indian Penal Code is from 1860. So they have stood the test of time. AI will also be regulated, say, under. We now have a data protection act that came out this year, has a lot of laws, is not enough. But there are other things like the IT act from, say, 2000. So we have to make sure that whatever we are coming up with now is dynamic, that stands the test of time, say, 100 years. Like your us constitution, it's been there, doesn't have a lot of amendments. And yeah, it is the most important.
Speaker A: So maybe building off this, and a question is with a technology that is changing incredibly rapidly, where the laws that our choices are either don't regulate, right, just let it evolve or pass laws without much information and see how they go. They're not passing the test time. We're taking a guess. How do you engage in that kind of governance? And how do you get feedback from society that these things are going to pass?
Speaker G: Same as your constitution?
Speaker A: Hold on. I would love to shard. I'll just say maybe at like seven five, we'll tell people to come back here and then try to aggregate here at like, 715. Sound good?
Speaker F: My perspective is that of a product builder. So in this conversation of AI and governance, I'll probably be one of the persons who's building that software product from that vantage point to distill AI as a word a little bit. What it means is quality data sets. And I would be somebody who's responsible to gather those quality data sets for, say, a client who is the government or who's the election body or who's a political party. And when we're talking about power over here, the power lies in the hands of people who commission this project. And the power does not lie in the hands of people who do not have a choice in submitting their data. So I think a big part of power comes from, or like, the conversation around power comes from data literacy. So in the three types of India's, one part of India could probably not consent to this, but the other two parts of India does not understand what consent means and does not understand that. When a government personnel comes to my doorstep and asks me questions about my life, about my income, about my husband, I just answer because I'm just used to it. Because Social Security number Adar, for us, that's the equivalent. For us, it's very notoriously leaked, very often as a large database, and there is no control as a population, we can't do anything about it. So to bring this conversation back to power, where does the power lie? I think the power lies in the hands of native language, data literacy. It lies in the hands of creating words in my mother tongue for what it means to give consent. When someone asks for my data, what am I, what is it? What is that data going to do? Where is it going? Whose intelligence is it contributing to? Just the way it's easy for somebody to imagine a water cycle, right? Like water comes from here, goes up, comes down, or a food cycle. I think there is a data cycle at play here that most people don't even have the words in their languages to describe. And that unless in a country. Sorry, go on.
Speaker A: As just a minor pushback in the US, I feel like people give up their data all the time, and it's not because of data literacy. Maybe to some degree it is, but it's certainly not a linguistic barrier. It's because the benefits are now, and the downsides, if they exist, are in the future. They're aggregate.
Speaker H: They know it when they're giving it up.
Speaker A: No, I'm not taking away the fact that consent is still relevant, for sure. I'm just saying when another community is asked for consent, they consent all the time. They consent constantly. And so maybe you feel morally absolved now. Oh, they're consent.
Speaker E: Have a question. Everyone talks about consent. Your terms and condition documents around 8000 words. We don't consent to everything. We don't have the time to consent to everything. So consent is a very loosely. I feel like it's a very imaginary term.
Speaker A: Yes.
Speaker E: A lot of the regulation in the US, I don't think it should be a gold standard for the world. I mean, if you look at the American Disabilities act, because I work in web accessibility, a lot of the, I would say embellishments or even revisions are very reactionary. If you look at it. If you look at it historically in terms of lawsuits, and these are basic things, right? For example, providing closed captions to airflare entertainment, or giving you closed captions for educational content with Harvard or Princeton or Stanford. So all of them have been. Because there's been very large amounts of lawsuits that have been filed, and that's why you had provisions come in. So I wouldn't say that the US is a beacon of hope when it comes.
Speaker A: I'm not trying to actually say it's a beacon of hope. I'm pointing out that this is kind of with a number of aspects to make consent. I feel like consent is probably not going to be a solution to allow people to participate in a way that advocates for themselves, either because they have linguistic barriers, that whatever solutions have been created have been abused, like in the US, in getting endless things, or because they don't have the time, or it's impossible to truly consent to these kinds of things. It's hard to make these guesses. Maybe we can set up institutions that can advocate on behalf of large numbers of people because they are data trusts and they represent humans. And we recognize that it's relevant to have essentially joint negotiation for a bunch of ignorant people, such that things that I don't have to advocate for my water cleanliness, that is something that I shouldn't have, or that the safety of the flights I take, that is outside of me. And if someone gave me consent, if this plane crashes, blah, blah, that would be ridiculous. That wouldn't be how we would deal with things. So I think agreeing with you that there's too many issues. I was just bringing up this up as just one reason why consent might be necessary, or better data literacy might be necessary to go back to your original point. But I see, like, not sufficient to empower the.
Speaker G: There's also a cultural aspect, like, we talk about consent and privacy, but also the rural India or the other India that we talk about, they don't care so much about privacy because their lives are not so private. Like, yes, maybe through not technology, they are giving away their data. But the way the village lives or way the rural lives are, the data is easily available.
Speaker C: I would go on to one more point. The thing is, they probably don't understand the consequences of giving away their data.
Speaker G: Yeah, that is different. Consequences are different, but they don't care about privacy so much and there's so much struggle in their lives that the ease of access. So today, having. Linking my aadhaar to my mobile number gives me access to ration card or regular ration is way part of my survival than thinking about how this Aadhaar data is going to be used. So that struggle, I think over, or what you call benefit sort of over.
Speaker E: Especially even with very. UPI has kind of revolutionized the micro payments aspect in terms of ease of doing things. But I think it depends on their data online. There's no statistical back to it, but I think a lot of people from those regions are very conservative when it comes to what they do online.
Speaker G: UPI is linked to bank accounts. Women don't have bank accounts, so they won't be able to use UPI.
Speaker A: So we're diving into a specific aspect, which I think is an important one of, like privacy, individuals and individual agency here. When we think about governance in society, it's like individual behavior is just one aspect and is sometimes used as an excuse. So in the US, I don't know how it works here, but for a long time there have been ads that important. It's your responsibility to recycle plastic. And those were actually put forward by plastic, like creating companies, because it makes it an individual problem to be responsible for recycling, not a corporate problem, not a government problem, not a societal problem to deal with recycling. And it's ridiculous because it's not going to be solved on an individual level, because it just isn't plastic is not plastic. It's not a thing that's solved on an individual level, neither is data privacy or what we're talking about more generally, which is stakeholder empowerment, like, how will different individuals be affected? And this is all within the context of a technology that is under human control to begin with, which is, like, not a given for AI. And that's a bigger. A lot of the AI governance is about humans controlling AI versus AI controlling AI. Right now, we're having a more typical kind of technology conversation, which is like, who is responsible? And how is this technology going to change power? And will governance be used, as you pointed out at the beginning, from a regulatory capture place to instantiate power that's existed before, or will it be a destabilizing force that we can hopefully make use of to empower more people?
Speaker D: But can we go towards this humans governing AI, and how does it work?
Speaker A: Yeah. Do you want to move the conversation in that direction?
Speaker G: I just want to put one thought.
Speaker A: Sure.
Speaker G: So, whenever we are coming up with, say, new regulations, we should also dig deep and see that in whose interest it's coming. I just read that the US has come up with some AI directives, and that was drafted by Rand Corporation. And who paid for that to Rand corporation was Dustin Moskowitz. That's Facebook.
Speaker A: So you think he's representing Facebook?
Speaker G: No, I'm not saying anything. You just have to see that all of this writing work, someone has to pay for it. So it's nice to see where the money is coming from, and then you can make the connection. It was kind of like that. So Nandanin Ghani independently developed the technology, then he lobbied for the government to adopt it, and then it became a power, because then the USBI is still.
Speaker E: In charge by private company. So then all your regulatory frameworks and audits are then at courtesy of.
Speaker D: Maybe it's a kind of a framework or something, but then the end of the day, it is governed by.
Speaker A: You're going to have the last. And then I would like to move in the direction that you want.
Speaker H: Yeah, actually, I wanted to start.
Speaker A: One more question. No, sorry.
Speaker B: I have a clarification.
Speaker A: Okay, clarification question.
Speaker B: When you talk about this governance, it's spoken about data and mostly data collection and that, hence privacy. That's what I'm guessing, but it's equally important as the algorithm itself, the model. Like, what happens?
Speaker A: Let's clarify for a second. So when people talk about governance, there are many things that you're talking about. On one end, there's hard law. Like some regulation is set into place that has some enforcement association. So fines can be levied, you might not be allowed to do something, something like that. So the EU AI act is an example of that, where if you have an AI system that is a current kind of thing, a high risk system, you have certain requirements. And if you do not meet those requirements, the EU, whether it's enforced or not, can impose a tax, a fine on you of like 7% of revenue. Hard law. There are standards that are set up, standards are not enforceable necessarily, but end up becoming part of what's called soft law. And so this is the idea that people might have to act in a certain kind of way. There might be a certifier that certifies against it. Again, it's not required by any government, but other companies might require it. I only work with companies that are certified against standard x, and there are organizations internationally and nationally that create these kinds of standards. That's another kind of governance. There's corporate governance, where organizations determine how are they going to act as a company, what are their policies for whatever. And those governance are generally there to deal with risks and compliance needs. And those risks often bear out in financial terms. So they don't want to have a privacy leak, not because they care about privacy necessarily, but because they'll get a pr backlash or something like that. And some companies will create policies that reflect a kind of culture, maybe an ethical culture, ultimately, that probably leans back to a brand that is relevant for financial improvement, but that's not actually how the company acts. The company says, we're an ethical company that will not do x, and they don't revisit that all the time. That's just part of their charter, their governance, and that's how they behave when they move forward. So those are different aspects of how you set up some policies that end up having effects on the incentives of behavior moving forward from very hard ones, you can't do this whatever to softer ones which end up influencing culture. So that's broadly. And what those policies apply to can be data, can be how you release models, whether you have to identify risk before you deploy a system. The world is your oyster in what governance can apply to. And certain areas are more mature than others. Cybersecurity is a more mature part of technology in terms of governance than like AI model governance or stakeholder involvement or something like that.
Speaker E: I think India would be interesting is in their AI strategy, they outlined military, healthcare and education as like the main.
Speaker A: Focus area, focus areas.
Speaker E: So healthcare. And it was very interesting because it was a very participatory method you have intel who's taken over the educational path. They're responsible for building curriculum, and they have something called an AI for all initiative where they're looking at imparting curriculum within schools in the central school system. So we have different education curriculums for the central school system is usually why the. I mean, they have the largest number of schools, and then you have healthcare, which Vadwani AI did a lot of work with. They're a nonprofit working on healthcare data aspects. I don't know too much about the military aspects, but yeah, these are the two ones that were very interesting for me.
Speaker A: I would like. Okay, now, please.
Speaker D: I think a good anchor question that at least seems to me is a good way to think about human governance of AI. And maybe like a vote around the room kind of a question is pick any government of today that you really like or that you really be associated with, whether it could be the EU, it could be the indian government, it could be the US government, it could be the UN. If OpenAI, let's say a company like OpenAI were to achieve what can be called AGI or super intelligence or human like AI, anything that's beyond let's achieve. If they were to achieve it, your favorite government, should it nationalize OpenAI? Should it take over Openi? Should it control that AI?
Speaker C: So you're saying if my favorite country, should my favorite country pick up AI.
Speaker D: If it, should it basically nationalize? So basically open AI, let's say it's going to, let's say productionize that technology, it's going to put it in front of people or whatever it's going to do with it as a corporation, whatever it wants to do?
Speaker A: What is the human oversight governance structure that people here would find like they would want?
Speaker D: Would they be okay with. So the question is, would you be okay if the US government, if OpenAI were to achieve Agi, would you be okay if the US government nationalized OpenAI?
Speaker A: Right? Because right now, the governance controlling that AGI is OpenAI's governance. This corporation, it's the market, it's a.
Speaker D: Bunch of other things. But then the current governance structure is, of course, the government in place.
Speaker A: So I like this question. So think about that for a bit. What kind of governance structure you can make it a country. And one answer could be the free market. You don't want kind of government constraints on it. And you think that evolution with under kind of market innovation is actually the best way to move it forward.
Speaker C: I have a question for the question. So when you say open air is going to relinquish control of its assets to the government? What would be the a risks that the government undertakes upon itself for nationalizing this and having this into their weaponry? And two, what would be their liabilities? So right now you say that the whole market going up and down is something for OpenAI to think about. If it's their product, they will have to think about how to sustain it. But if it becomes a national thing, what power does the government hold over the product? Is just the on off switch or is it technology? Right.
Speaker D: Assume when nuclear energy came up you had npts and you had basically countries.
Speaker C: So it gets like the internal you're.
Speaker H: Asking us to think about. Your question is what is asking us to think? Do you want government, whichever government, do you want them to just relinquish control or have control? Or how would that governance adopt?
Speaker D: Do you want it to be same way that we did for nuclear technology where it was protected, Iran was stopped from developing it. A bunch of countries went there and.
Speaker F: Stopped at the question, go for it. This is like now going into speculative futures.
Speaker G: Love it.
Speaker F: I think I would trust the swiss government.
Speaker C: Yeah, that was my.
Speaker E: I would also trust the singaporean government. It's an easier.
Speaker F: I think, a nation who has had to develop its economy with constraints of very strong geographical factors, which focuses on excellence, craft, resilience. I like these values. And I think if I had to choose between a bunch of powerful people.
Speaker E: I would choose these kind of powerful.
Speaker G: People who make excellent things and believe.
Speaker F: In living a slightly more decent life but also earning money and living well. Yeah, I think the values had to be perpetuated around the world. I imagine this is the kind of.
Speaker E: Speculative future I'd like to live in. I don't want to break your bubble, but a lot of women aren't allowed to vote in. Sad. I know. I'm not like.
Speaker A: Let'S not make this.
Speaker E: It's not a Moranti argument, but that's a very good example.
Speaker G: This is a very diplomatic cycle. I'm sure there are a bunch of loopholes here.
Speaker A: So these are the values you would like to be reflected.
Speaker C: The big problem I'm seeing is that AI currently differs from nuclear weapons in one massive way, which is nuclear weapons were purely destructive. AI is purely capitalistic at this point. Nuclear is not purely destructive.
Speaker B: Yeah.
Speaker C: This was the nuclear weapons. Nuclear is the ip that they have captured. Right. Not nuclear, no.
Speaker D: You can destabilize the country's cyber infrastructure.
Speaker A: Yeah.
Speaker D: Could weaponize it.
Speaker A: Right.
Speaker D: Look at it.
Speaker A: When nuclear first came out the destructive power was focused on. And some people actually bring this up as a warning against regulation of AI, because the focus on risk was so strong that it seems nuclear advocates will point out that we have lost or completely didn't focus on it. And that led to other problems we didn't foresee, for instance, abundant energy that we could get from cheaper nuclear power. So anyway, that's just one aspect of it still being a dual technology.
Speaker E: Even at COP 28 in the UAE, nuclear energy was actually the highly most talked about topic in terms of hansing and providing an actual solution that one could move from and away from fossil fuels, nuclear energy. Is that solution right?
Speaker C: No. My point was that most of the regulation that has been a lot of effort that went into regulation was about the proliferation of nuclear weapons. That was what I meant, because not so much effort has gone into nuclear energy. Only now it has started to become.
Speaker A: Resurgent as an energy source.
Speaker G: But the thing is, only 2% of the.
Speaker C: Exactly at this point, even now, there's as much nuclear research also that goes on because of the unstable nature of the isotopes. So a lot of research has just stopped at the prey.
Speaker A: I'm going to try it yet. I don't know if you've heard there's a term called nerd sniping, where someone puts out a topic and it's just like every. And then you realize I've completely lost them. I'm going to give a different question, which is answer to the question, which is I feel like AI being as powerful and potentially foundational as it is, like the phrase foundation models is because they have the ability to be the undergird infrastructure throughout the world. They're very easy to use and apply in different ways. Has a unique requirement for massive multistakeholder kind of discussion and governance. And I don't think we've actually mean the US has tried to be a democracy and India has tried to be a democracy that represents a huge number of different stakeholders and both are currently limited by different kinds of technology. The US, we probe our population once every four years and only 60% of people vote. And whatever India you have, it sounds like a relatively high amount of participation, but a lot of corruption that ends up influencing how many people vote. Whatever these kinds of things are, I see as actually technological limitations. And I am excited for an AI enabled democracy of the future where more people can understand. We were talking about consent a little bit. What are the relevant kind of components of these technologies? Discussions like this can be had to bring people's voices together. And that information can be somehow. This is my futurist optimist, somehow synthesized into a joint perspective. And my understanding is that in Taiwan, they are one of the most technologically forward countries in their democracy, led by this woman, Audrey Tang, who uses much simpler versions of analysis, like principal components analysis, clustering these classic data science techniques on survey data, to be able to do much more and focus a whole country onto the areas of agreement rather than division. And that's an area that I think is going to be quite a lot.
Speaker E: Of citizen participation consultations during COVID as well.
Speaker A: Very interesting.
Speaker E: Chile is also a very good example of what you're describing. The Chile AI act that was passed also had a lot of citizen participations in different ways. And they had, I think, 67% participations from women and diverse groups and younger people. Covid helped kind of help you moving online, different Zoom consultations. But I know this because one of the people who was behind the peruvian and chilean one, Chile, is a very good example of participatory air governance. The AI acts, even in Rwanda, are following similar suits where they have a lot of public consultations.
Speaker A: This is very cool.
Speaker C: I find a very. Maybe a disturbing undercurrent to the themes of all the countries you've chosen, is that they've gone through like a bad event. A very bad event, actually.
Speaker E: All of them have. There's no country that's Singapore perfect in many ways. I mean, Singapore is. Yes, and Rwanda is kind of following Singapore. So a lot of people who know about Rwanda, Rwanda is kind of looking at the same surveillance style, and they are a smaller population, easier to test things out. So, yeah, Rwanda is kind of following similar.
Speaker A: So as the introduction, I think the.
Speaker D: Way I would compress Ian's answer is, there's this famous sama quote, right? When we get to EJ, I'll ask it to figure out how do we make money? And then I think you're kind of saying something similar, that when we get to EJ, we'll ask Egi to govern.
Speaker A: I'm saying something slightly different, which is that's possible. I'm open to that future as well. But I'm actually open, I think, diffused amongst people. There's a lot of wisdom and also the values that we want to be incorporated into our governance of this very important technology. And what we currently lack is an easy way to bring that information together. Because in the end, we're going to have to make decisions that don't represent. They might represent everyone, but they're not everyone's decisions. Right. As a group, we're like, what restaurant do we want to go to? We've heard everyone, and then we go to a restaurant. We can't go to ten restaurants. And so what is the way that we can bring that information together?
Speaker D: Is that necessarily.
Speaker A: Keep on going? Right.
Speaker D: So one of my favorite shows is best wing, and then I think there's a nice quote from that. I like that. He says, should you have direct democracy, which is kind of what's there in Switzerland, right. Or you should have representative democracy where you've got someone who's, let's say, a bit more well versed with what's going on, and then they're not going to just take your votes and opinions and do what you want.
Speaker A: Yeah. I would like AI to be this intermediary, this representative should be, that is not just deciding, is gaining the information.
Speaker D: And then giving it to the decision.
Speaker A: Makers that are human, which could be an AI or could be human, I don't really know. People are starting to come in. So in the last. I'm sorry to say that there's a limitation on this discussion, but I hope even when I'm not here, you can find other AI salons or equivalents. And if you would like, help in the future, I'll say this to other people, setting up your own. I have resources. I'm happy to support you, but in this last little bit here, many of us, I'm sure, have some last thing, either that we've already taken away from this discussion or something kind of burning that we haven't been able to say yet. I would love to go around. We don't have to literally go around, but if you have something, we're not going to continue the discussion on any topic, so it's just going to stop you. But please bring it forward. Yeah, go for it.
Speaker H: Yeah. I think what you were talking about, should we let AI evolve like anything else is evolving? I feel like the reason why we're having this conversation is because we think that something's going to make our life better and it's working towards making things better. And if you take examples from how someone found penicillin and someone said, oh, that's rubbish, you can't use something that's going to be harmful to humans. But it was studied, and the same way AI can't be just studied as it's going to be beneficial. It needs to be studied with its risks and benefits and use of. Is it going to be good in this population? Is it going to be good in that population. And that is what is happening right now. But what you're asking for is, for me, the worry is always when we say, can we do it faster? Can we do it bigger, can we do it better? And when that becomes a question, we're forgetting that is bigger better, faster, always.
Speaker A: Better, actually better, actually better.
Speaker H: Or should we also be looking at, if it's bigger, what is it causing us harm? And then we can decide, yeah, the harm is there, but it's less. So I think that conversation, I'm thinking from a health chemistry. So that's what we do with medicines, that's what we do with therapies. From the time a person has an idea that I'm going to try this robotic surgery, he also has to think how it's going to be harmful to the person. And I feel like people in AI should be doing that. Just because I develop something and, oh, my God, now I know I can do from five g to four g, or from four g to five g and whatever. Just because it's brilliant doesn't mean that it is going to be brilliant. I think at the same time we need to be thinking, what about all the consequences? And that needs to be part of the conversation. And only then it will be evolving, like how humans evolve. Otherwise it's going to be restricted only in terms of it becoming bigger and better and faster.
Speaker A: Yeah.
Speaker B: Okay, I have two thoughts, two very different thoughts. One is, I think it's probably useful to think of, I think a has become too broad a bucket, and should probably look at use cases. And for each use cases, the way we would govern it would be very different. And that it makes it more tangible to also analyze use case, use case. Because right now it's just too fuzzy and too many things are getting clubbed. And what I mean by AI is different from what each one of us.
Speaker A: Mean by AI, right?
Speaker B: I think that's my use case point of view thinking. I think the second thing, which I would really like, I'm not economists, but try to put on that hat, right? Economics is basically when an actor brings in some value and other people are interacting with that person and they're exchanging value, right? So AA is a system which is bringing in value, whatever that value is. I think try to apply that lens, then think about like, there's a different way of different preferred economic models. So then I think we need to look at that angle as well. For example, which political economic model is preferred? And from that model, we would kind of have a preference to say, AI should behave in this way. So I think that's a whole box to be unraveled and whether it's purely a market driven or market driven press segregation. So I think that needs a deeper thinking, which I would like to.
Speaker A: Yeah, I feel like you probably.
Speaker C: So there's this quote by Susan Sontag about the nature of pictures and media. So she says that when the advent of pictures and media happened, there was this inherent bias in people's minds about an objective truth to whatever media has for a long time. When people say that media can overthrow governments, pictures can overthrow dictatorships, and all this stuff, it's because you associate a sense of truth to the media. And I feel like we are at that phase. Where are doing that for AGI or for AI? We are blindly thinking that whatever is going to give us is going to be the truth, where in fact it's just a distillation of all of human knowledge and.
Speaker H: All, only that managed to reach.
Speaker A: Yeah.
Speaker C: All the documented human knowledge is put into it. And whatever question you ask, it gives you a regurgitated answer.
Speaker A: Sure.
Speaker C: So until maybe like last year, llms were not able to discover new knowledge. So I feel like there is a substantial pinch of salt that you should always ascribe to any output from an AGI or from an AI. And AI has its place. AI is not going to rule over us. I have this one really cool thing which I want to see implemented, is where we don't have the system in India, but in the US, there's a presidential debate. So I want AI to in real time point out logical fallacies and debates like, oh, that was ad hominem. That was like a character assassination. That's a straw man argument in real time. So like that, what it does is it's not something that you can make a proud out of, it's not something that will help someone, but it will filter out your canvas better. So stuff like that. So that's the direction in which I see AI going as like a software abstraction layer between reality and utopia. And I am very, very excited for AI. I'm the opposite of a boomer. So, yeah, that's all I have to say.
Speaker A: We're going to stop here. Okay.
Speaker E: One is that AI is not a magic wand that will solve human problems, cycle problems. We are extensions of that. AI kind of enables that acceptable, that we should have agency over AI. We should never look at AI as, I mean, yeah, AI could be autonomous in certain ways, but then the agency.
Speaker G: Should remain with us.
Speaker E: Second one, the conversations we've been having we need to have more platform accountability, maybe not from big tech. The templates of big tech, of the software development, development kits that are being used that have these practices of surveillance economies or kind of generate their revenue on ads you need to look into. I don't want to say lobbying, but society lobbying through smaller platforms, social platforms that can help you, that practice responsible. Excellent.